{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIhZ2LFhnw9Z"
      },
      "source": [
        "# **WorldQuant University Capstone for MScFE 690 (Group 9184)**\n",
        "\n",
        "## Data Extraction. Data Transformation. Methodology Description. Reinforcement Learning. Traditional Approaches. Model Development. Performance Comparison and Analysis. DynaCAAST Framework.\n",
        "\n",
        "\n",
        "<br><br>\n",
        "\n",
        "\n",
        "|**DynaCAAST framework for RL based trading agents**| |\n",
        "|:---|:---|\n",
        "|**TEAM MEMBER 1** | Farai Masunda  |\n",
        "|**TEAM MEMBER 2**  |      Bhaskar Vedula  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSF6XMWBLcJ2"
      },
      "source": [
        "<hr style='border:4px solid black'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV3If0IF7EbD"
      },
      "source": [
        "## **Section 1: Python library installations and imports**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osEjTLzD7EbD"
      },
      "source": [
        "## Installations\n",
        "\n",
        "For this project, we need several Python libraries that are not a part of Google Colab. These include FinRL, stable-baselines and gym libraries for developing reinforcement learning (RL) agents and environment. yfinance the Yahoo Finance source for our data. ta for allowing us to create technical indicators as our 'states' for RL agent. pyfolio for enabling graphical dispaly of performance and comparison metrics. hmmlearn for regime change detection within our data using Hidden Markov Model. tensorflow for training our LSTM models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWVbYQcvX65D"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
        "!pip install yfinance --upgrade --no-cache-dir\n",
        "!pip install matplotlib\n",
        "!pip install stockstats\n",
        "!pip install gym\n",
        "!pip install stable-baselines3[extra]\n",
        "!pip install tensorflow\n",
        "!pip install ta\n",
        "!pip install git+https://github.com/stefan-jansen/pyfolio-reloaded\n",
        "!pip install PyPortfolioOpt\n",
        "!pip install shimmy\n",
        "!pip install cvxpy\n",
        "!pip install statsmodels\n",
        "!pip install numpy cython\n",
        "!pip install hmmlearn\n",
        "!pip install pandas_market_calendars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPxqTVr0vrO2"
      },
      "source": [
        "## Imports\n",
        "\n",
        "Imports follow the libraries that we have installed above. stable baseline provides us with various RL agents based on a particular algorithm (DDPG, PPO, TD3, SAC and A2C). Other imports are primarily the usual imports required for a financial project like pandas, numpy, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pxnq050vcMzQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "import os\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "import time\n",
        "from time import time\n",
        "import math\n",
        "import copy\n",
        "import random\n",
        "from random import sample\n",
        "from tabulate import tabulate\n",
        "import copy\n",
        "\n",
        "import typing as tt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.preprocessing import normalize, MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib\n",
        "from pathlib import Path\n",
        "import pandas_datareader.data as web\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pylab as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "matplotlib.use('Agg')\n",
        "import seaborn as sns\n",
        "from IPython.display import display, HTML\n",
        "%matplotlib inline\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.collections import LineCollection\n",
        "from matplotlib.colors import Colormap, ListedColormap, BoundaryNorm\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "import yfinance as yf\n",
        "import shimmy\n",
        "import cvxpy as cp\n",
        "from hmmlearn import hmm\n",
        "\n",
        "import statsmodels\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.layers import RepeatVector\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Dropout, BatchNormalization\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Add, GlobalAveragePooling1D\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, GlobalAveragePooling1D\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import ta\n",
        "from ta import add_all_ta_features\n",
        "from ta.utils import dropna\n",
        "\n",
        "from scipy.stats import skewnorm, norm, percentileofscore\n",
        "from scipy import stats as scipy_stats\n",
        "from scipy.linalg import block_diag\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl import config\n",
        "\n",
        "import pyfolio as pf\n",
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "from pypfopt import risk_models\n",
        "from pypfopt import expected_returns\n",
        "from pyfolio import timeseries\n",
        "\n",
        "import gym\n",
        "from gym.utils import seeding\n",
        "from gym import spaces\n",
        "\n",
        "from stable_baselines3 import DDPG\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3 import TD3\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.ppo import MlpPolicy\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.td3.policies import MlpPolicy\n",
        "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AHjCPUiLZBf"
      },
      "source": [
        "<hr style='border:2px solid black'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU95TT4Gh2AR"
      },
      "source": [
        "## **Section 2: Defining functions and classes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B76wtUHFiG7t"
      },
      "source": [
        "In this section, we define functions and classes that are necessary for this capstone project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDD7TAhL2Voq"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKUbsDU_lQqx"
      },
      "source": [
        "The below function is defined to create technical indicators as our states. This function takes close prices, open price, high and low price as inputs and outputs the technical indicators of the chosen stock tickers. The function utilizes ta library to achieve this functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZcBim442dct"
      },
      "outputs": [],
      "source": [
        "# Define a Function for adding technical indicators\n",
        "\n",
        "def create_technical_indicators(df, tech_indicators, ti_abbreviations):\n",
        "    \"\"\"\n",
        "    Function to add technical indicators for features\n",
        "    -Takes in a dataset with Open, High, Low, Close and Volume\n",
        "    -Also takes in a list of the technical indicators to be added\n",
        "     as well as a list of the shortened indicator names\n",
        "    \"\"\"\n",
        "\n",
        "    # list of column names to filter the features\n",
        "    column_names = list(df.columns)\n",
        "    filters      = column_names + tech_indicators\n",
        "    new_columns  = column_names + ti_abbreviations\n",
        "\n",
        "    # Add technical indicators using the ta Library\n",
        "    df = add_all_ta_features(df, open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=\"volume\")\n",
        "\n",
        "    # Filter the Indicators with the required features\n",
        "    df = df[filters]\n",
        "    df.columns = new_columns # rename the columns to use shortened indicator names\n",
        "    df = df.fillna(method='bfill')\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4BaN6cSmwHm"
      },
      "source": [
        "All the below functions are defined primarily to execute denoising algorithm as part of our benchmark techniques. These functions are based on the previous courses completed at WorldQuant University."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpoawexlICP-"
      },
      "outputs": [],
      "source": [
        "def mpPDF(var, q, pts):\n",
        "    eMin, eMax = var*(1-(1./q)**.5)**2, var*(1+(1./q)**.5)**2 # calc lambda_minus, lambda_plus\n",
        "    eVal = np.linspace(eMin, eMax, pts) #Return evenly spaced numbers over a specified interval. eVal='lambda'\n",
        "    pdf = q/(2*np.pi*var*eVal)*((eMax-eVal)*(eVal-eMin))**.5 #np.allclose(np.flip((eMax-eVal)), (eVal-eMin))==True\n",
        "    pdf = pd.Series(pdf, index=eVal)\n",
        "    return pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKC1yDrdICeC"
      },
      "outputs": [],
      "source": [
        "def detoned_corr(corr, eigenvalues, eigenvectors, market_component=1):\n",
        "\n",
        "    # Getting the eigenvalues and eigenvectors related to market component\n",
        "    eigenvalues_mark = eigenvalues[:market_component, :market_component]\n",
        "    eigenvectors_mark = eigenvectors[:, :market_component]\n",
        "\n",
        "    # Calculating the market component correlation\n",
        "    corr_mark = np.dot(eigenvectors_mark, eigenvalues_mark).dot(eigenvectors_mark.T)\n",
        "\n",
        "    # Removing the market component from the de-noised correlation matrix\n",
        "    corr = corr - corr_mark\n",
        "\n",
        "    # Rescaling the correlation matrix to have 1s on the main diagonal\n",
        "    corr = cov2corr(corr)\n",
        "\n",
        "    return corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPkvsNsgICpy"
      },
      "outputs": [],
      "source": [
        "def getRndCov(nCols, nFacts): #nFacts - contains signal out of nCols\n",
        "    w = np.random.normal(size=(nCols, nFacts))\n",
        "    cov = np.dot(w, w.T) #random cov matrix, however not full rank\n",
        "    cov += np.diag(np.random.uniform(size=nCols)) #full rank cov\n",
        "    return cov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1nuTIJUIC31"
      },
      "outputs": [],
      "source": [
        "def fitKDE(obs, bWidth=.15, kernel='gaussian', x=None):\n",
        "    #Fit kernel to a series of obs, and derive the prob of obs\n",
        "    # x is the array of values on which the fit KDE will be evaluated\n",
        "    #print(len(obs.shape) == 1)\n",
        "    if len(obs.shape) == 1: obs = obs.reshape(-1,1)\n",
        "    kde = KernelDensity(kernel = kernel, bandwidth = bWidth).fit(obs)\n",
        "    #print(x is None)\n",
        "    if x is None: x = np.unique(obs).reshape(-1,1)\n",
        "    #print(len(x.shape))\n",
        "    if len(x.shape) == 1: x = x.reshape(-1,1)\n",
        "    logProb = kde.score_samples(x) # log(density)\n",
        "    pdf = pd.Series(np.exp(logProb), index=x.flatten())\n",
        "    return pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuaa9OaRIDFV"
      },
      "outputs": [],
      "source": [
        "def getPCA(matrix):\n",
        "    # Get eVal, eVec from a Hermitian matrix\n",
        "    eVal, eVec = np.linalg.eig(matrix) #complex Hermitian (conjugate symmetric) or a real symmetric matrix.\n",
        "    indices = eVal.argsort()[::-1] #arguments for sorting eval desc\n",
        "    eVal,eVec = eVal[indices],eVec[:,indices]\n",
        "    eVal = np.diagflat(eVal) # identity matrix with eigenvalues as diagonal\n",
        "    return eVal,eVec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xPLeNc3IDS4"
      },
      "outputs": [],
      "source": [
        "def cov2corr(cov):\n",
        "    # Derive the correlation matrix from a covariance matrix\n",
        "    std = np.sqrt(np.diag(cov))\n",
        "    corr = cov/np.outer(std,std)\n",
        "    corr[corr<-1], corr[corr>1] = -1,1 #for numerical errors\n",
        "    return corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AfkHMqdAOAg"
      },
      "outputs": [],
      "source": [
        "def corr2cov(corr, std):\n",
        "    cov = corr * np.outer(std, std)\n",
        "    return cov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UfFCVsAIDfC"
      },
      "outputs": [],
      "source": [
        "def corr2cov(corr, std):\n",
        "    cov = corr * np.outer(std, std)\n",
        "    return cov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byGruXd2IDtL"
      },
      "outputs": [],
      "source": [
        "def errPDFs(var, eVal, q, bWidth, pts=10):\n",
        "    var = var[0]\n",
        "    pdf0 = mpPDF(var, q, pts)\n",
        "    pdf1 = fitKDE(eVal, bWidth, x=pdf0.index.values)\n",
        "    sse = np.sum((pdf1-pdf0)**2)\n",
        "    print(\"sse:\"+str(sse))\n",
        "    return sse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qX7JD2GxID69"
      },
      "outputs": [],
      "source": [
        "def findMaxEval(eVal, q, bWidth):\n",
        "    out = minimize(lambda *x: errPDFs(*x), x0=np.array(0.5), args=(eVal, q, bWidth), bounds=((1E-5, 1-1E-5),))\n",
        "    print(\"found errPDFs\"+str(out['x'][0]))\n",
        "    if out['success']: var = out['x'][0]\n",
        "    else: var=1\n",
        "    eMax = var*(1+(1./q)**.5)**2\n",
        "    return eMax, var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZA2ImSgIEH_"
      },
      "outputs": [],
      "source": [
        "def denoisedCorr(eVal, eVec, nFacts):\n",
        "    eVal_ = np.diag(eVal).copy()\n",
        "    eVal_[nFacts:] = eVal_[nFacts:].sum()/float(eVal_.shape[0] - nFacts)\n",
        "    eVal_ = np.diag(eVal_)\n",
        "\n",
        "    corr1 = np.dot(eVec, eVal_).dot(eVec.T)\n",
        "\n",
        "    return corr1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfJ0dWgMMm1q"
      },
      "outputs": [],
      "source": [
        "def optPort(cov, mu = None):\n",
        "    inv = np.linalg.inv(cov)\n",
        "    ones = np.ones(shape = (inv.shape[0], 1))\n",
        "    if mu is None:\n",
        "        mu = ones\n",
        "    w = np.dot(inv, mu)\n",
        "    w /= np.dot(ones.T, w)\n",
        "\n",
        "    return w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yx_nJl6nZco"
      },
      "source": [
        "The below function is been defined to determine maximum drawdown within a portfolio performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwGUso8e2dtC"
      },
      "outputs": [],
      "source": [
        "def getMaxDrawdown(prices, window):\n",
        "    max_rolling = prices.rolling(min_periods=1, window=window).max()\n",
        "    drawdown = (prices / max_rolling) - 1\n",
        "    max_drawdown = drawdown.rolling(min_periods=1, window=window).min()\n",
        "    return drawdown, max_drawdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tzHToY25lSl"
      },
      "source": [
        "# Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3DofDQ8nrXM"
      },
      "source": [
        "The below classes have been defined for the purpose of embedding functionality to our reinforcement learning (RL) agent and environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yt2ADRMW4lsY"
      },
      "outputs": [],
      "source": [
        "# This class define a reinforcement agent and includes functionality such as getting predictions, training, incorporating a particular algorithm.\n",
        "\n",
        "class DRLAgent:\n",
        "\n",
        "    @staticmethod\n",
        "    def DRL_prediction(model, test_data, test_env, test_obs):\n",
        "        \"\"\"make a prediction\"\"\"\n",
        "        start = time.time()\n",
        "        account_memory = []\n",
        "        actions_memory = []\n",
        "        for i in range(len(test_data.index.unique())):\n",
        "            action, _states = model.predict(test_obs)\n",
        "            test_obs, rewards, dones, info = test_env.step(action)\n",
        "            if i == (len(test_data.index.unique()) - 2):\n",
        "                account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n",
        "                actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n",
        "        end = time.time()\n",
        "        return account_memory[0], actions_memory[0]\n",
        "\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "\n",
        "    def get_model(self, model_name, policy=\"MlpPolicy\", policy_kwargs=None, model_kwargs=None, verbose=1,):\n",
        "        if model_name not in MODELS:\n",
        "            raise NotImplementedError(\"NotImplementedError\")\n",
        "\n",
        "        if model_kwargs is None:\n",
        "            model_kwargs = MODEL_KWARGS[model_name]\n",
        "\n",
        "        if \"action_noise\" in model_kwargs:\n",
        "            n_actions = self.env.action_space.shape[-1]\n",
        "            model_kwargs[\"action_noise\"] = NOISE[model_kwargs[\"action_noise\"]](\n",
        "                mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
        "        print(model_kwargs)\n",
        "        model = MODELS[model_name](policy=policy, env=self.env, verbose=verbose, policy_kwargs=policy_kwargs, **model_kwargs,)\n",
        "        return model\n",
        "\n",
        "    def train_model(self, model, tb_log_name, total_timesteps=50000):\n",
        "        model = model.learn(total_timesteps=total_timesteps, tb_log_name=tb_log_name)\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2zMzBns4lvP"
      },
      "outputs": [],
      "source": [
        "# This class provides environment for our RL agent. The environment steps into a time series data provided to it and provides the\n",
        "# closing prices as of date. It also computes feature engineered state space to be provided to the agent.\n",
        "# It calculates and provides to the agent a reward based on portfolio value reevaluated based on current close prices.\n",
        "# This class has been augmented with methods that fetch certain values required for DynaCAAST framework\n",
        "\n",
        "class StockPortfolioEnv(gym.Env):\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, df, stock_dim, hmax, initial_amount, transaction_cost_pct, reward_scaling, state_space, action_space, tech_indicator_list, initial_weights, turbulence_threshold=None, lookback=252, day = 0):\n",
        "\n",
        "        self.day = day\n",
        "        self.lookback=lookback\n",
        "        self.df = df\n",
        "        self.stock_dim = stock_dim\n",
        "        self.hmax = hmax\n",
        "        self.initial_amount = initial_amount\n",
        "        self.transaction_cost_pct =transaction_cost_pct\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.state_space = state_space\n",
        "        self.action_space = action_space\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "        self.initial_weights = initial_weights\n",
        "        self.action_space = spaces.Box(low = 0, high = 1,shape = (self.action_space,))\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = (len(self.tech_indicator_list),self.state_space))\n",
        "\n",
        "        # load data\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.state =  [self.data[tech].values.tolist() for tech in self.tech_indicator_list ]\n",
        "        self.terminal = False\n",
        "        self.turbulence_threshold = turbulence_threshold\n",
        "        # initalize\n",
        "        self.portfolio_return_ = 0\n",
        "        self.portfolio_value = self.initial_amount\n",
        "        self.portfolio_value_wo_tc = self.initial_amount\n",
        "\n",
        "        # memorize\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[self.initial_weights]\n",
        "        self.last_weights = self.initial_weights\n",
        "        self.weights = self.initial_weights\n",
        "        self.date_memory=[self.data.date.unique()[0]]\n",
        "\n",
        "    def step(self, actions):\n",
        "\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "\n",
        "        if self.terminal:\n",
        "            return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "        else:\n",
        "            weights = self.softmax_normalization(actions)\n",
        "            self.last_weights = self.actions_memory[-1].copy()\n",
        "            self.weights = weights\n",
        "            self.actions_memory.append(weights)\n",
        "            last_day_memory = self.data\n",
        "\n",
        "            #load next state\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day,:]\n",
        "            self.state =  [self.data[tech].values.tolist() for tech in self.tech_indicator_list ]\n",
        "\n",
        "            self.portfolio_return_ = sum(((self.data.close.values / last_day_memory.close.values)-1)*weights)\n",
        "\n",
        "            # update portfolio\n",
        "            new_portfolio_value = self.portfolio_value*(1+self.portfolio_return_)\n",
        "            self.portfolio_value_wo_tc = new_portfolio_value.copy()\n",
        "            transaction_cost = sum(np.absolute((self.data.close.values/last_day_memory.close.values)*(self.last_weights - weights)))*self.transaction_cost_pct\n",
        "            new_portfolio_value = new_portfolio_value - abs(transaction_cost)\n",
        "            portfolio_return = new_portfolio_value/self.portfolio_value -1\n",
        "            self.portfolio_value = new_portfolio_value\n",
        "\n",
        "\n",
        "            # save into memory\n",
        "            self.portfolio_return_memory.append(portfolio_return)\n",
        "            self.date_memory.append(self.data.date.unique()[0])\n",
        "            self.asset_memory.append(new_portfolio_value)\n",
        "            self.reward = new_portfolio_value\n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        # load states\n",
        "        self.state =  [self.data[tech].values.tolist() for tech in self.tech_indicator_list ]\n",
        "        self.portfolio_value = self.initial_amount\n",
        "        self.terminal = False\n",
        "        self.portfolio_return_memory = [0]\n",
        "\n",
        "        self.actions_memory=[self.initial_weights]\n",
        "        self.date_memory=[self.data.date.unique()[0]]\n",
        "        return self.state\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        return self.state\n",
        "\n",
        "    def softmax_normalization(self, actions):\n",
        "        numerator = np.exp(actions)\n",
        "        denominator = np.sum(np.exp(actions))\n",
        "        softmax_output = numerator/denominator\n",
        "        return softmax_output\n",
        "\n",
        "    def getDataCloseValues(self):\n",
        "\n",
        "        return self.data.close.values\n",
        "\n",
        "    def getWeights(self):\n",
        "\n",
        "        return self.weights\n",
        "\n",
        "    def save_asset_memory(self):\n",
        "        date_list = self.date_memory\n",
        "        portfolio_return = self.portfolio_return_memory\n",
        "        df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
        "        return df_account_value\n",
        "\n",
        "    def save_action_memory(self):\n",
        "        date_list = self.date_memory\n",
        "        df_date = pd.DataFrame(date_list)\n",
        "        df_date.columns = ['date']\n",
        "\n",
        "        action_list = self.actions_memory\n",
        "        df_actions = pd.DataFrame(action_list)\n",
        "        df_actions.columns = self.data.tic.values\n",
        "        df_actions.index = df_date.date\n",
        "        return df_actions\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def get_sb_env(self):\n",
        "        e = DummyVecEnv([lambda: self])\n",
        "        obs = e.reset()\n",
        "        return e, obs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK0bZ38FLU-G"
      },
      "source": [
        "<hr style='border:2px solid black'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDhKbkCMZD0A"
      },
      "source": [
        "## **Section 3: Defining 'States' for our Reinforcement Learning Agent**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVb4O5d0ZZxi"
      },
      "source": [
        "In this section, we define states for our reinforcement learning (RL) agent. States are what the RL environment provides to the RL agent in order to make a decision or take an action. For this capstone, we explore four different state repesentations to explore the effectiveness of state definition on RL agent's performance. Below we define the four variants of the states that we use for running for RL algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYfsoPJBZvef"
      },
      "source": [
        "#### **A. Technical Indicators**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhcmnxmKtfZz"
      },
      "outputs": [],
      "source": [
        "# List of Features to add\n",
        "technical_indicators = ['volatility_atr','volatility_bbw','volume_obv', 'trend_macd', 'trend_adx', 'trend_sma_fast', 'trend_ema_fast', 'trend_cci', 'momentum_rsi']\n",
        "\n",
        "# Short names of the features\n",
        "ti_abbreviations     = ['atr', 'bbw','obv','macd', 'adx', 'sma', 'ema', 'cci', 'rsi']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNH-UGakbB-n"
      },
      "source": [
        "#### **B. Various lags of Returns from stock tickers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOEsbjHHbO-z"
      },
      "outputs": [],
      "source": [
        "return_lags = ['ret_1', 'ret_2', 'ret_5', 'ret_10', 'ret_21', 'ret_30']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mL1VtLzbid3"
      },
      "source": [
        "#### **C. LSTM predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8J9ZgKIcDqY"
      },
      "outputs": [],
      "source": [
        "lstm_fcst = ['fcst']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZOud1Q0aBc6"
      },
      "source": [
        "#### **D. Transformer predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaDtlWFOaClH"
      },
      "outputs": [],
      "source": [
        "transformer_fcst = ['fcst']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3hjbejbLTM4"
      },
      "source": [
        "<hr style='border:2px solid black'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl3AoE3lcTFx"
      },
      "source": [
        "## **Section 4: Defining model parameters**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9sFuD9CcddQ"
      },
      "source": [
        "We now define our model parameters for the various RL agents that we propose to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_LZ7XW6cbA_"
      },
      "outputs": [],
      "source": [
        "## Models\n",
        "MODELS = {\"a2c\": A2C, \"ddpg\": DDPG, \"td3\": TD3, \"sac\": SAC, \"ppo\": PPO}\n",
        "\n",
        "## Model Parameters\n",
        "A2C_PARAMS_TI = {\"n_steps\": 500, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
        "PPO_PARAMS_TI = { \"n_steps\": 2048, \"ent_coef\": 0.005, \"learning_rate\": 0.0001, \"batch_size\": 128,}\n",
        "DDPG_PARAMS_TI = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\n",
        "SAC_PARAMS_TI = { \"batch_size\": 128, \"buffer_size\": 100000, \"learning_rate\": 0.0003, \"learning_starts\": 100, \"ent_coef\": \"auto_0.1\",}\n",
        "TD3_PARAMS_TI = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\n",
        "\n",
        "A2C_PARAMS_RET = {\"n_steps\": 500, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
        "PPO_PARAMS_RET = { \"n_steps\": 2048, \"ent_coef\": 0.005, \"learning_rate\": 0.0001, \"batch_size\": 128,}\n",
        "DDPG_PARAMS_RET = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\n",
        "SAC_PARAMS_RET = { \"batch_size\": 128, \"buffer_size\": 100000, \"learning_rate\": 0.0003, \"learning_starts\": 100, \"ent_coef\": \"auto_0.1\",}\n",
        "TD3_PARAMS_RET = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\n",
        "\n",
        "A2C_PARAMS_LSTM = {\"n_steps\": 500, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
        "PPO_PARAMS_LSTM = { \"n_steps\": 2048, \"ent_coef\": 0.005, \"learning_rate\": 0.0001, \"batch_size\": 128,}\n",
        "DDPG_PARAMS_LSTM = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\n",
        "SAC_PARAMS_LSTM = { \"batch_size\": 128, \"buffer_size\": 100000, \"learning_rate\": 0.0003, \"learning_starts\": 100, \"ent_coef\": \"auto_0.1\",}\n",
        "TD3_PARAMS_LSTM = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\n",
        "\n",
        "A2C_PARAMS_TRANSFORMER = {\"n_steps\": 500, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
        "PPO_PARAMS_TRANSFORMER = { \"n_steps\": 2048, \"ent_coef\": 0.005, \"learning_rate\": 0.0001, \"batch_size\": 128,}\n",
        "DDPG_PARAMS_TRANSFORMER = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\n",
        "SAC_PARAMS_TRANSFORMER = { \"batch_size\": 128, \"buffer_size\": 100000, \"learning_rate\": 0.0003, \"learning_starts\": 100, \"ent_coef\": \"auto_0.1\",}\n",
        "TD3_PARAMS_TRANSFORMER = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\n",
        "\n",
        "MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n",
        "\n",
        "NOISE = {\"normal\": NormalActionNoise, \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,}\n",
        "\n",
        "total_timesteps_ = 2500\n",
        "\n",
        "transaction_cost = 0.003\n",
        "\n",
        "DynaCAAST_Env   = dict()\n",
        "DynaCAAST_Model = dict()\n",
        "DynaCAAST_Obs   = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh3pza2KLRhH"
      },
      "source": [
        "<hr style='border:2px solid black'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvoD8MoAoghP"
      },
      "source": [
        "## **Section 5: Creating training, testing and validation data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA5K-3X7pDoj"
      },
      "source": [
        "In this section, we extract and transform our data to be suitable for running our models. In this section, we also define start date, end date, and stock tickers. The feature engineered data for all defined states for training, testing and validation of various states is also created in this section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZn57cOPgsy6"
      },
      "source": [
        "### **Foundational data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDVtOpJNpSwp"
      },
      "outputs": [],
      "source": [
        "# We define the time period for our analysis here. The start date and end date used for this purpose is shown below.\n",
        "# Note that this period will encompass both in the sample and out of the sample data and as this is a time series data we will split the\n",
        "# time horizon into in the sample, out of the sample and validation.\n",
        "# time format = '%Y-%m-%d'\n",
        "\n",
        "START_DATE =  '2006-01-01'\n",
        "END_DATE   =  '2009-12-31'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f-nzawapdI8"
      },
      "outputs": [],
      "source": [
        "# These are stock tickers whose stock price data we are going to use in our capstone.\n",
        "# Note that all these companies are part of NIFTY 50 index and account for bulk of its market capitalization\n",
        "\n",
        "tickers = ['BHARTIARTL.NS',  'NTPC.NS',     'MARUTI.NS', 'NESTLEIND.NS', 'BAJFINANCE.NS', 'KOTAKBANK.NS',  'TATASTEEL.NS',  'ONGC.NS',       'BAJAJ-AUTO.NS', 'LT.NS',           'ITC.NS',   'TCS.NS',     'BRITANNIA.NS',\n",
        "           'SHRIRAMFIN.NS',  'ADANIENT.NS', 'CIPLA.NS',  'WIPRO.NS',     'INDUSINDBK.NS', 'ULTRACEMCO.NS', 'TATACONSUM.NS', 'BAJAJFINSV.NS', 'RELIANCE.NS',   'HEROMOTOCO.NS',   'TITAN.NS', 'HINDALCO.NS','APOLLOHOSP.NS', 'CASH']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct3zh0IUp4RO"
      },
      "source": [
        "Next, we extract and transform our data. We use Yahoo Finance to source our data. Notice that we also introduce 'CASH' as one of the tickers. We do so to allow our agents to move investments from stock to cash and vice versa when there is a bearish or bullish phase when all stocks are expected to behave a symmetric and coordinated manner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5YtBz0DqVcT"
      },
      "outputs": [],
      "source": [
        "# We create CASH as our 'ticker' here.\n",
        "\n",
        "tickers_wo_cash = tickers.copy()\n",
        "tickers_wo_cash.remove('CASH')\n",
        "data = yf.download(tickers_wo_cash, start=START_DATE, end=END_DATE)\n",
        "data = data.dropna()\n",
        "data = data.stack().reset_index()\n",
        "#data = data.drop(['Close'], axis=1)\n",
        "data.columns = ['date','tic','close','high','low','open','volume']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybKW8Cq8qX87"
      },
      "outputs": [],
      "source": [
        "# We provide time series data for our CASH ticker\n",
        "\n",
        "cashData = data[data.tic=='TCS.NS'].copy()\n",
        "cashData['tic']    = 'CASH'\n",
        "cashData['close']  = 100 + np.random.normal(loc=4,scale=0.01,size=len(cashData))\n",
        "cashData['high']   = 100 + np.random.normal(loc=4,scale=0.01,size=len(cashData))\n",
        "cashData['low']    = 100 + np.random.normal(loc=4,scale=0.01,size=len(cashData))\n",
        "cashData['open']   = 100 + np.random.normal(loc=4,scale=0.01,size=len(cashData))\n",
        "cashData['volume'] = 100 + np.random.normal(loc=4,scale=0.01,size=len(cashData))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTkArtS5qYMM"
      },
      "outputs": [],
      "source": [
        "# We combine the original data with the cash data we created above\n",
        "\n",
        "data = pd.concat([data, cashData])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3Db9TtPg5sK"
      },
      "source": [
        "### **Data for state representing technical indicators (TI)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qsiuG-befmj"
      },
      "source": [
        "Below we create data for our state representing technical indicators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8hL9zyTqYP3"
      },
      "outputs": [],
      "source": [
        "# We use the function we defined before for technical indicators\n",
        "\n",
        "data['volume'] =data['volume']/10000\n",
        "data['volume'] =data['volume'].apply(lambda x: round(x, 0))\n",
        "tech_ind_data = create_technical_indicators(data, technical_indicators, ti_abbreviations)\n",
        "del data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data for closing prices for tickers for traditional approaches**"
      ],
      "metadata": {
        "id": "1S40E76DNu5A"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeYU_qwBezDz"
      },
      "source": [
        "Below we create the price data that we need for running our traditional approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_My684UqpPt"
      },
      "outputs": [],
      "source": [
        "# Reset the Index to tic and date\n",
        "price_data = tech_ind_data[['date',\t'tic',\t'close',\t'high',\t'low',\t'open',\t'volume']].copy()\n",
        "price_data = price_data.reset_index().set_index(['tic', 'date']).sort_index()\n",
        "\n",
        "# Get the list of all the tickers\n",
        "tic_list = list(set([i for i,j in price_data.index]))\n",
        "\n",
        "# Create an empty data frame for the close prices\n",
        "df_close = pd.DataFrame()\n",
        "\n",
        "for ticker in tic_list:\n",
        "    series = price_data.xs(ticker).close\n",
        "    df_close[ticker] = series\n",
        "\n",
        "price_data = df_close.reset_index()\n",
        "del df_close"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1JAtGHJhGvI"
      },
      "source": [
        "### **Data for state representing lagged return data (RET)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ_RKRZJfEcF"
      },
      "source": [
        "We now create a lag returns data for evaluating states that represent lagged returns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wIIKAsae951"
      },
      "outputs": [],
      "source": [
        "return_lags_data = pd.DataFrame()\n",
        "\n",
        "dataValues = tech_ind_data[['tic', 'date', 'close']].sort_values(by = ['tic', 'date'], inplace=False)\n",
        "\n",
        "return_lags_data['close']  = dataValues['close']\n",
        "return_lags_data['ret_1']  = dataValues['close'].pct_change(1)\n",
        "return_lags_data['ret_2']  = dataValues['close'].pct_change(2)\n",
        "return_lags_data['ret_5']  = dataValues['close'].pct_change(5)\n",
        "return_lags_data['ret_10'] = dataValues['close'].pct_change(10)\n",
        "return_lags_data['ret_21'] = dataValues['close'].pct_change(21)\n",
        "return_lags_data['ret_30'] = dataValues['close'].pct_change(30)\n",
        "return_lags_data['tic']    = dataValues['tic']\n",
        "return_lags_data['date']   = dataValues['date']\n",
        "return_lags_data           = return_lags_data.fillna(method='bfill')\n",
        "return_lags_data           = return_lags_data.sort_values(by=['date', 'tic'])\n",
        "\n",
        "del dataValues"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describing the returns data"
      ],
      "metadata": {
        "id": "6m3u7F9FzShX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "return_lags_data[[\"ret_1\",\t\"ret_2\",\t\"ret_5\",\t\"ret_10\",\t\"ret_21\",\t\"ret_30\"]].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "vgyHRa7gzVII",
        "outputId": "ad2ab9d2-136f-4c23-8b22-358942953b28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              ret_1         ret_2         ret_5        ret_10        ret_21  \\\n",
              "count  28809.000000  28809.000000  28809.000000  28809.000000  28809.000000   \n",
              "mean       0.001746      0.003508      0.008778      0.017689      0.037307   \n",
              "std        0.122674      0.175954      0.282555      0.412337      0.604004   \n",
              "min       -0.984078     -0.984400     -0.984185     -0.983875     -0.983426   \n",
              "25%       -0.007835     -0.011079     -0.016974     -0.023734     -0.032761   \n",
              "50%        0.000128      0.000294      0.002142      0.004900      0.010631   \n",
              "75%        0.009010      0.014041      0.024662      0.038496      0.062900   \n",
              "max       18.517799     19.258989     20.009379     20.708274     23.152545   \n",
              "\n",
              "             ret_30  \n",
              "count  28809.000000  \n",
              "mean       0.053166  \n",
              "std        0.707215  \n",
              "min       -0.982635  \n",
              "25%       -0.037264  \n",
              "50%        0.015646  \n",
              "75%        0.079778  \n",
              "max       23.019816  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a717413-e213-414d-98c4-16c4ee4a0979\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ret_1</th>\n",
              "      <th>ret_2</th>\n",
              "      <th>ret_5</th>\n",
              "      <th>ret_10</th>\n",
              "      <th>ret_21</th>\n",
              "      <th>ret_30</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>28809.000000</td>\n",
              "      <td>28809.000000</td>\n",
              "      <td>28809.000000</td>\n",
              "      <td>28809.000000</td>\n",
              "      <td>28809.000000</td>\n",
              "      <td>28809.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.001746</td>\n",
              "      <td>0.003508</td>\n",
              "      <td>0.008778</td>\n",
              "      <td>0.017689</td>\n",
              "      <td>0.037307</td>\n",
              "      <td>0.053166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.122674</td>\n",
              "      <td>0.175954</td>\n",
              "      <td>0.282555</td>\n",
              "      <td>0.412337</td>\n",
              "      <td>0.604004</td>\n",
              "      <td>0.707215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-0.984078</td>\n",
              "      <td>-0.984400</td>\n",
              "      <td>-0.984185</td>\n",
              "      <td>-0.983875</td>\n",
              "      <td>-0.983426</td>\n",
              "      <td>-0.982635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.007835</td>\n",
              "      <td>-0.011079</td>\n",
              "      <td>-0.016974</td>\n",
              "      <td>-0.023734</td>\n",
              "      <td>-0.032761</td>\n",
              "      <td>-0.037264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000128</td>\n",
              "      <td>0.000294</td>\n",
              "      <td>0.002142</td>\n",
              "      <td>0.004900</td>\n",
              "      <td>0.010631</td>\n",
              "      <td>0.015646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.009010</td>\n",
              "      <td>0.014041</td>\n",
              "      <td>0.024662</td>\n",
              "      <td>0.038496</td>\n",
              "      <td>0.062900</td>\n",
              "      <td>0.079778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>18.517799</td>\n",
              "      <td>19.258989</td>\n",
              "      <td>20.009379</td>\n",
              "      <td>20.708274</td>\n",
              "      <td>23.152545</td>\n",
              "      <td>23.019816</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a717413-e213-414d-98c4-16c4ee4a0979')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9a717413-e213-414d-98c4-16c4ee4a0979 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9a717413-e213-414d-98c4-16c4ee4a0979');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-adc8abf1-1992-420a-9f2e-e75b84ffcd95\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-adc8abf1-1992-420a-9f2e-e75b84ffcd95')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-adc8abf1-1992-420a-9f2e-e75b84ffcd95 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"return_lags_data[[\\\"ret_1\\\",\\t\\\"ret_2\\\",\\t\\\"ret_5\\\",\\t\\\"ret_10\\\",\\t\\\"ret_21\\\",\\t\\\"ret_30\\\"]]\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"ret_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10184.629792435788,\n        \"min\": -0.9840784454538544,\n        \"max\": 28809.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.0017456996070425834,\n          0.00012847844350116766,\n          28809.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ret_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10184.589661882179,\n        \"min\": -0.9844004514686971,\n        \"max\": 28809.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.003508249118748767,\n          0.0002935667313428425,\n          28809.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ret_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10184.545942331986,\n        \"min\": -0.9841850421869442,\n        \"max\": 28809.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.008778290728994607,\n          0.0021420787517947293,\n          28809.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ret_10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10184.503292163212,\n        \"min\": -0.9838746539032167,\n        \"max\": 28809.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.01768889218595924,\n          0.004900444479019939,\n          28809.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ret_21\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10184.368715535364,\n        \"min\": -0.9834264795623407,\n        \"max\": 28809.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.03730653480270361,\n          0.010630567541515923,\n          28809.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ret_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10184.368444800128,\n        \"min\": -0.9826345143085718,\n        \"max\": 28809.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.05316578766596801,\n          0.015645761342345077,\n          28809.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91ZYJ_wht0Nh"
      },
      "source": [
        "### **Defining start and end dates for our training, testing and validation**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZBRf7Gvty9Y"
      },
      "outputs": [],
      "source": [
        "# Define the start and end dates for the train, test and validation data\n",
        "\n",
        "train_pct = 0.75  # percentage of train data\n",
        "test_pct  = 0.20  # percentage of test data\n",
        "\n",
        "date_list = list(tech_ind_data.date.unique()) # List of dates in the data\n",
        "\n",
        "date_list_len  = len(date_list) # len of the date list\n",
        "train_data_len = int(train_pct * date_list_len) # length of the train data\n",
        "test_data_len  = int(test_pct * date_list_len) # length of the test data\n",
        "\n",
        "train_start_date = date_list[0]\n",
        "train_end_date   = date_list[train_data_len]\n",
        "print(train_end_date)\n",
        "\n",
        "test_start_date = date_list[train_data_len+1]\n",
        "test_end_date   = date_list[train_data_len + test_data_len]\n",
        "print(test_end_date)\n",
        "\n",
        "valid_start_date = date_list[train_data_len + test_data_len + 1]\n",
        "valid_end_date   = date_list[-1]\n",
        "print(valid_end_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckoPmysghOwp"
      },
      "source": [
        "### **Data for state representing LSTM forecasts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cib2jVFOfUyO"
      },
      "source": [
        "We now create data for states representing predictions from our LSTM model. For that we first create training data to train a LSTM model and then use this model to spew out our 'state' representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRkDCoBUe-Ua"
      },
      "outputs": [],
      "source": [
        "# Closing price data we use for creating input data for our LSTM model\n",
        "\n",
        "finalData = price_data.set_index('date',inplace=False).transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPnJ_q4kgoCV"
      },
      "outputs": [],
      "source": [
        "# We now create training data and testing data for our neural network\n",
        "# Creating training data for all our tickers\n",
        "\n",
        "trainData = []\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "intermediate = 0\n",
        "\n",
        "for i in range(len(finalData)):\n",
        "    intermediate = finalData.iloc[i, 0:train_data_len].values\n",
        "    intermediate = intermediate.reshape(-1,1)\n",
        "    intermediate = scaler.fit_transform(intermediate)\n",
        "    trainData.append(intermediate)\n",
        "\n",
        "trainDataX = []\n",
        "trainDataY = []\n",
        "dummy1 = []\n",
        "dummy2 = []\n",
        "\n",
        "for i in range(len(finalData)):\n",
        "    for j in range(10, len(trainData[i])):\n",
        "        dummy1.append(trainData[i][j-10:j][0])\n",
        "        dummy2.append(np.array(trainData[i][j][0]))\n",
        "\n",
        "    dummy1 = np.array(dummy1)\n",
        "    trainDataX.append(np.reshape(dummy1, (dummy1.shape[0], dummy1.shape[1], 1)))\n",
        "    dummy2 = np.array(dummy2)\n",
        "    trainDataY.append(dummy2)\n",
        "    dummy1 = []\n",
        "    dummy2 = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnOyMAjFgoGn"
      },
      "outputs": [],
      "source": [
        "# We create testing data now. We use this to validate our LSTM model.\n",
        "\n",
        "testData = []\n",
        "dummy = []\n",
        "\n",
        "for i in range(len(finalData)):\n",
        "    intermediate = finalData.iloc[i, train_data_len:].values\n",
        "    intermediate = intermediate.reshape(-1,1)\n",
        "    intermediate = scaler.fit_transform(intermediate)\n",
        "    testData.append(intermediate)\n",
        "\n",
        "\n",
        "for i in range(len(finalData)):\n",
        "    for j in range(10, len(testData[i])):\n",
        "        dummy.append(testData[i][j-10:j][0])\n",
        "\n",
        "    dummy = np.array(dummy)\n",
        "    testData.append(np.reshape(dummy, (dummy.shape[0], dummy.shape[1], 1)))\n",
        "    dummy = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6d97GfMhdlK"
      },
      "outputs": [],
      "source": [
        "# We define our LSTM model here. We use LSTM as it is efficient with sequential data\n",
        "# We choose MSE as our loss and Adam as our optimizer\n",
        "\n",
        "stockModel = Sequential()\n",
        "stockModel.add(LSTM(25, return_sequences=True, input_shape=(trainDataX[0].shape[1], 1)))\n",
        "stockModel.add(LSTM(25, return_sequences=True))\n",
        "stockModel.add(LSTM(25))\n",
        "stockModel.add(Dense(25))\n",
        "stockModel.add(Dense(trainDataX[0].shape[1]))\n",
        "stockModel.compile(optimizer='adam',loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0X98k4Khdoj"
      },
      "outputs": [],
      "source": [
        "# We observe the LSTM configuration below\n",
        "\n",
        "stockModel.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju-bVLfrgoX3"
      },
      "outputs": [],
      "source": [
        "# We now train the LSTM model here based on the training data we created before.\n",
        "# We select 15 epochs and batch size of 16.\n",
        "# We set verbose to 0 to avoid messages\n",
        "\n",
        "n_epochs = 15\n",
        "trainResults = []\n",
        "\n",
        "for i in range(len(tickers)):\n",
        "    trainResults.append(stockModel.fit(trainDataX[i], trainDataY[i], epochs = n_epochs, batch_size = 16, verbose=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_Sddvy9vsv9"
      },
      "source": [
        "We visualize the progression of losses over multiple epochs for results from our LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoRiLrb7vqHs"
      },
      "outputs": [],
      "source": [
        "TrainTestSplit = train_data_len\n",
        "fig, axs = plt.subplots(2, 2, figsize=(15, 7))\n",
        "plt.suptitle(\"Results for Baseline Scenario\", fontsize=14)\n",
        "\n",
        "axs[0, 0].plot(range(n_epochs), trainResults[0].history['loss'], color = 'b')\n",
        "axs[0, 0].set_title(\"Loss progression for \" + tickers[0])\n",
        "axs[0, 1].plot(range(n_epochs),  trainResults[1].history['loss'], 'tab:orange')\n",
        "axs[0, 1].set_title(\"Loss progression for \" + tickers[1])\n",
        "axs[1, 0].plot(range(n_epochs),  trainResults[2].history['loss'], 'tab:green')\n",
        "axs[1, 0].set_title(\"Loss progression for \" + tickers[2])\n",
        "axs[1, 1].plot(range(n_epochs),  trainResults[3].history['loss'], 'tab:red')\n",
        "axs[1, 1].set_title(\"Loss progression for \" + tickers[3])\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel = \"Epoch Number\", ylabel = \"MSE Loss\")\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94cDs4Vxq1on"
      },
      "source": [
        "\n",
        "### **Checking performance of our LSTM output to validate its role as a state for our RL agents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cESkNsJTv48i"
      },
      "outputs": [],
      "source": [
        "# We now predict based on testing sample using LSTM model\n",
        "\n",
        "predResults = []\n",
        "\n",
        "for i in range(len(tickers)):\n",
        "    predictions_scaled = stockModel.predict(testData[i])\n",
        "    predictions = scaler.fit(np.expand_dims(finalData.iloc[i, :], 1)).inverse_transform(predictions_scaled)\n",
        "    predResults.append(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVETk8cDim_Q"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# We plot the predicted results versus the actual data for our  model\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(21, 9))\n",
        "plt.suptitle(\"Results for LSTM forecasts\", fontsize=14)\n",
        "\n",
        "axs[0, 0].plot(finalData.iloc[0, TrainTestSplit:].to_list(), color = 'b')\n",
        "axs[0, 0].plot(predResults[0], color = 'k')\n",
        "axs[0, 0].set_title(\"Prediction results for \"+ tickers[0])\n",
        "\n",
        "axs[0, 1].plot(finalData.iloc[1, TrainTestSplit:].to_list(), 'tab:orange')\n",
        "axs[0, 1].plot(predResults[1], color = 'k')\n",
        "axs[0, 1].set_title(\"Prediction results for \"+ tickers[1])\n",
        "\n",
        "axs[1, 0].plot(finalData.iloc[2, TrainTestSplit:].to_list(), 'tab:green')\n",
        "axs[1, 0].plot(predResults[2], color = 'k')\n",
        "axs[1, 0].set_title(\"Prediction results for \"+ tickers[2])\n",
        "\n",
        "axs[1, 1].plot(finalData.iloc[3, TrainTestSplit:].to_list(), 'tab:red')\n",
        "axs[1, 1].plot(predResults[3], color = 'k')\n",
        "axs[1, 1].set_title(\"Prediction results for \"+ tickers[3])\n",
        "\n",
        "\n",
        "for ax, tick in zip(axs.flat, tickers):\n",
        "    ax.set(xlabel = \"Number of Days since cut-off date\", ylabel = \"Stock price for \" + tick)\n",
        "    ax.legend((\"Real price for \"+ tick, \"Predicted price for \"+ tick), loc=\"upper left\")\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XL7UMjLgob1"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 2, figsize=(21, 9))\n",
        "plt.suptitle(\"Results for LSTM forecasts\", fontsize=14)\n",
        "\n",
        "axs[0, 0].plot(finalData.iloc[7, TrainTestSplit:].to_list(), color = 'b')\n",
        "axs[0, 0].plot(predResults[7], color = 'k')\n",
        "axs[0, 0].set_title(\"Prediction results for \"+ tickers[7])\n",
        "\n",
        "axs[0, 1].plot(finalData.iloc[8, TrainTestSplit:].to_list(), 'tab:orange')\n",
        "axs[0, 1].plot(predResults[8], color = 'k')\n",
        "axs[0, 1].set_title(\"Prediction results for \"+ tickers[8])\n",
        "\n",
        "axs[1, 0].plot(finalData.iloc[9, TrainTestSplit:].to_list(), 'tab:green')\n",
        "axs[1, 0].plot(predResults[9], color = 'k')\n",
        "axs[1, 0].set_title(\"Prediction results for \"+ tickers[9])\n",
        "\n",
        "axs[1, 1].plot(finalData.iloc[10, TrainTestSplit:].to_list(), 'tab:red')\n",
        "axs[1, 1].plot(predResults[10], color = 'k')\n",
        "axs[1, 1].set_title(\"Prediction results for \"+ tickers[10])\n",
        "\n",
        "for ax, tick in zip(axs.flat, tickers):\n",
        "    ax.set(xlabel = \"Number of Days since cut-off date\", ylabel = \"Stock price for \" + tick)\n",
        "    ax.legend((\"Real price for \"+ tick, \"Predicted price for \"+ tick), loc=\"upper left\")\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuJvyyRrqABx"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 2, figsize=(21, 9))\n",
        "plt.suptitle(\"Results for LSTM forecasts\", fontsize=14)\n",
        "\n",
        "axs[0, 0].plot(finalData.iloc[11, TrainTestSplit:].to_list(), color = 'b')\n",
        "axs[0, 0].plot(predResults[11], color = 'k')\n",
        "axs[0, 0].set_title(\"Prediction results for \"+ tickers[11])\n",
        "\n",
        "axs[0, 1].plot(finalData.iloc[12, TrainTestSplit:].to_list(), 'tab:orange')\n",
        "axs[0, 1].plot(predResults[12], color = 'k')\n",
        "axs[0, 1].set_title(\"Prediction results for \"+ tickers[12])\n",
        "\n",
        "axs[1, 0].plot(finalData.iloc[13, TrainTestSplit:].to_list(), 'tab:green')\n",
        "axs[1, 0].plot(predResults[13], color = 'k')\n",
        "axs[1, 0].set_title(\"Prediction results for \"+ tickers[13])\n",
        "\n",
        "axs[1, 1].plot(finalData.iloc[14, TrainTestSplit:].to_list(), 'tab:red')\n",
        "axs[1, 1].plot(predResults[14], color = 'k')\n",
        "axs[1, 1].set_title(\"Prediction results for \"+ tickers[14])\n",
        "\n",
        "\n",
        "for ax, tick in zip(axs.flat, tickers):\n",
        "    ax.set(xlabel = \"Number of Days since cut-off date\", ylabel = \"Stock price for \" + tick)\n",
        "    ax.legend((\"Real price for \"+ tick, \"Predicted price for \"+ tick), loc=\"upper left\")\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjCcyhWzqASW"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 2, figsize=(21, 9))\n",
        "plt.suptitle(\"Results for LSTM forecasts\", fontsize=14)\n",
        "\n",
        "axs[0, 0].plot(finalData.iloc[15, TrainTestSplit:].to_list(), color = 'b')\n",
        "axs[0, 0].plot(predResults[15], color = 'k')\n",
        "axs[0, 0].set_title(\"Prediction results for \"+ tickers[15])\n",
        "\n",
        "axs[0, 1].plot(finalData.iloc[16, TrainTestSplit:].to_list(), 'tab:orange')\n",
        "axs[0, 1].plot(predResults[16], color = 'k')\n",
        "axs[0, 1].set_title(\"Prediction results for \"+ tickers[16])\n",
        "\n",
        "axs[1, 0].plot(finalData.iloc[17, TrainTestSplit:].to_list(), 'tab:green')\n",
        "axs[1, 0].plot(predResults[17], color = 'k')\n",
        "axs[1, 0].set_title(\"Prediction results for \"+ tickers[17])\n",
        "\n",
        "axs[1, 1].plot(finalData.iloc[18, TrainTestSplit:].to_list(), 'tab:red')\n",
        "axs[1, 1].plot(predResults[18], color = 'k')\n",
        "axs[1, 1].set_title(\"Prediction results for \"+ tickers[18])\n",
        "\n",
        "\n",
        "for ax, tick in zip(axs.flat, tickers):\n",
        "    ax.set(xlabel = \"Number of Days since cut-off date\", ylabel = \"Stock price for \" + tick)\n",
        "    ax.legend((\"Real price for \"+ tick, \"Predicted price for \"+ tick), loc=\"upper left\")\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1_LFRSYqBAO"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 2, figsize=(21, 9))\n",
        "plt.suptitle(\"Results for LSTM forecasts\", fontsize=14)\n",
        "\n",
        "axs[0, 0].plot(finalData.iloc[19, TrainTestSplit:].to_list(), color = 'b')\n",
        "axs[0, 0].plot(predResults[19], color = 'k')\n",
        "axs[0, 0].set_title(\"Prediction results for \"+ tickers[19])\n",
        "\n",
        "axs[0, 1].plot(finalData.iloc[20, TrainTestSplit:].to_list(), 'tab:orange')\n",
        "axs[0, 1].plot(predResults[20], color = 'k')\n",
        "axs[0, 1].set_title(\"Prediction results for \"+ tickers[20])\n",
        "\n",
        "axs[1, 0].plot(finalData.iloc[21, TrainTestSplit:].to_list(), 'tab:green')\n",
        "axs[1, 0].plot(predResults[21], color = 'k')\n",
        "axs[1, 0].set_title(\"Prediction results for \"+ tickers[21])\n",
        "\n",
        "axs[1, 1].plot(finalData.iloc[22, TrainTestSplit:].to_list(), 'tab:red')\n",
        "axs[1, 1].plot(predResults[22], color = 'k')\n",
        "axs[1, 1].set_title(\"Prediction results for \"+ tickers[22])\n",
        "\n",
        "\n",
        "for ax, tick in zip(axs.flat, tickers):\n",
        "    ax.set(xlabel = \"Number of Days since cut-off date\", ylabel = \"Stock price for \" + tick)\n",
        "    ax.legend((\"Real price for \"+ tick, \"Predicted price for \"+ tick), loc=\"upper left\")\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0IwPkwEqwNK"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 2, figsize=(21, 9))\n",
        "plt.suptitle(\"Results for LSTM forecasts\", fontsize=14)\n",
        "\n",
        "axs[0, 0].plot(finalData.iloc[23, TrainTestSplit:].to_list(), color = 'b')\n",
        "axs[0, 0].plot(predResults[23], color = 'k')\n",
        "axs[0, 0].set_title(\"Prediction results for \"+ tickers[23])\n",
        "\n",
        "axs[0, 1].plot(finalData.iloc[24, TrainTestSplit:].to_list(), 'tab:orange')\n",
        "axs[0, 1].plot(predResults[24], color = 'k')\n",
        "axs[0, 1].set_title(\"Prediction results for \"+ tickers[24])\n",
        "\n",
        "axs[1, 0].plot(finalData.iloc[25, TrainTestSplit:].to_list(), 'tab:green')\n",
        "axs[1, 0].plot(predResults[25], color = 'k')\n",
        "axs[1, 0].set_title(\"Prediction results for \"+ tickers[25])\n",
        "\n",
        "for ax, tick in zip(axs.flat, tickers):\n",
        "    ax.set(xlabel = \"Number of Days since cut-off date\", ylabel = \"Stock price for \" + tick)\n",
        "    ax.legend((\"Real price for \"+ tick, \"Predicted price for \"+ tick), loc=\"upper left\")\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2AFr1ASroWe"
      },
      "source": [
        "### **Creating data for LSTM states**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As our LSTM model is reasonably performimg, we create training, testing and validation data for States represented by LSTM output."
      ],
      "metadata": {
        "id": "82_FNcHFPwW6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXImFjjKqwar"
      },
      "outputs": [],
      "source": [
        "# We now predict based on testing sample using our LSTM model which serves as state space\n",
        "\n",
        "lstmData = []\n",
        "\n",
        "for i in range(len(finalData)):\n",
        "    intermediate = finalData.iloc[i,:].values\n",
        "    intermediate = intermediate.reshape(-1,1)\n",
        "    intermediate = scaler.fit_transform(intermediate)\n",
        "    lstmData.append(intermediate)\n",
        "\n",
        "lstmFeatures = []\n",
        "\n",
        "for i in range(len(tickers)):\n",
        "    predictions_scaled = stockModel.predict(lstmData[i])\n",
        "    predictions = scaler.fit(np.expand_dims(finalData.iloc[i, TrainTestSplit:], 1)).inverse_transform(predictions_scaled)\n",
        "    lstmFeatures.append(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaG43Gpqqwdb"
      },
      "outputs": [],
      "source": [
        "ticlist = list(tech_ind_data['tic'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIHuiSqbqwgr"
      },
      "outputs": [],
      "source": [
        "lstmFeaturesDF = pd.DataFrame()\n",
        "lstmFeaturesDF['date'] = tech_ind_data['date']\n",
        "lstmFeaturesDF['tic'] = tech_ind_data['tic']\n",
        "lstmFeaturesDF['close'] = tech_ind_data['close']\n",
        "lstmFeaturesDF['fcst'] = 0\n",
        "lstmFeaturesDF = lstmFeaturesDF.sort_values(by=['tic','date'])\n",
        "\n",
        "for i in range(len(lstmFeatures)):\n",
        "  lstmFeaturesDF.loc[lstmFeaturesDF['tic']==ticlist[i], \"fcst\"]= list(lstmFeatures[i].squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRepRuN2sSW_"
      },
      "outputs": [],
      "source": [
        "lstmFeaturesDF = lstmFeaturesDF.sort_values(by=['date','tic'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We visualize the state space data created using our LSTM model."
      ],
      "metadata": {
        "id": "rUnh1gETQQgm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnT7t2PHsSmF"
      },
      "outputs": [],
      "source": [
        "lstmFeaturesDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc6epJfo_leB"
      },
      "source": [
        "### **Data for state representing Transformer forecasts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdShV7c2bddk"
      },
      "source": [
        "We now create data for states representing predictions from our Transformer model. For we first create training data to train a Transformer model and then use this model to spew out our 'state' representation. We carry out this exercise in a separate notebook as the training requires GPU as opposed to CPU used here. We first import here the forecast data that we created from our transformer model in another notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFa2_Qmtdor5"
      },
      "outputs": [],
      "source": [
        "TransformerFcst = pd.read_csv(\"/content/TransformerFeaturesDF\", index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We visualize the data imported for transformer state space."
      ],
      "metadata": {
        "id": "4mOBfZ2iQnwV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoNMk1c_eOjr"
      },
      "outputs": [],
      "source": [
        "TransformerFcst"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now create the state space data for our transformer forecasts"
      ],
      "metadata": {
        "id": "HbBOGT4hQv66"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCeLVrnxepFr"
      },
      "outputs": [],
      "source": [
        "TransformerFeaturesDF = lstmFeaturesDF.copy()\n",
        "\n",
        "for tick in tickers_wo_cash :\n",
        "  TransformerFeaturesDF[TransformerFeaturesDF['tic']==tick][\"fcst\"] = list(TransformerFcst[tick].squeeze())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We view the final output for transformer data here"
      ],
      "metadata": {
        "id": "uOtiP8_LQ22N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDewJWBdhuQn"
      },
      "outputs": [],
      "source": [
        "TransformerFeaturesDF.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX2GpAwPs5_Y"
      },
      "source": [
        "### **Creating training, testing and validation data for all 'states' of RL agents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbSh6h-nstOs"
      },
      "outputs": [],
      "source": [
        "# Split the whole dataset\n",
        "\n",
        "train_data_ti = data_split(tech_ind_data,  train_start_date, train_end_date)\n",
        "test_data_ti  = data_split(tech_ind_data,  test_start_date,  test_end_date)\n",
        "valid_data_ti = data_split(tech_ind_data,  valid_start_date, valid_end_date)\n",
        "\n",
        "train_data_ret = data_split(return_lags_data,  train_start_date, train_end_date)\n",
        "test_data_ret  = data_split(return_lags_data,  test_start_date,  test_end_date)\n",
        "valid_data_ret = data_split(return_lags_data,  valid_start_date, valid_end_date)\n",
        "\n",
        "train_data_lstm = data_split(lstmFeaturesDF,  train_start_date, train_end_date)\n",
        "test_data_lstm  = data_split(lstmFeaturesDF,  test_start_date,  test_end_date)\n",
        "valid_data_lstm = data_split(lstmFeaturesDF,  valid_start_date, valid_end_date)\n",
        "\n",
        "train_data_transformer = data_split(TransformerFeaturesDF,  train_start_date, train_end_date)\n",
        "test_data_transformer  = data_split(TransformerFeaturesDF,  test_start_date,  test_end_date)\n",
        "valid_data_transformer = data_split(TransformerFeaturesDF,  valid_start_date, valid_end_date)\n",
        "\n",
        "# Split the Close Prices dataset\n",
        "prices_train_data =  price_data[price_data['date']<=train_end_date].reset_index(drop=True).set_index(['date'])\n",
        "prices_test_data  =  price_data[(price_data['date']>=test_start_date) & (price_data['date']<=test_end_date)].reset_index(drop=True).set_index(['date'])\n",
        "prices_valid_data =  price_data[price_data['date']>=valid_start_date].reset_index(drop=True).set_index(['date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Section 6: Analysing correlations and regime changes in time series data of closing prices**\n"
      ],
      "metadata": {
        "id": "SJkRRu6qRJR3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We analyse correlations and regime changes in our time series data as this provided explanatory background and context for the observed portfolio performances."
      ],
      "metadata": {
        "id": "rZuOiI2tRlNB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq2-4I_AspeY"
      },
      "source": [
        "### **Reviewing correlations of returns from our closing price data of the chosen tickers**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCq6kGZ8qpUP"
      },
      "outputs": [],
      "source": [
        "cov_matrix=price_data[tickers_wo_cash].pct_change().dropna().cov()*np.sqrt(252)*100\n",
        "plt.figure(figsize=(21, 9))\n",
        "sns.heatmap(cov_matrix, cmap='YlOrBr', annot=True, fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Covariance Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTgbyyAdqzym"
      },
      "outputs": [],
      "source": [
        "# We view the correlation heatmap for the final selected tickers.\n",
        "np.set_printoptions(formatter={'float': '{: 0.2f}'.format})\n",
        "\n",
        "plt.figure(figsize=(21, 9))\n",
        "mask = np.triu(np.ones_like(price_data[tickers_wo_cash].pct_change().dropna().corr(), dtype=np.bool_))\n",
        "heatmap = sns.heatmap(price_data[tickers_wo_cash].pct_change().dropna().corr(), mask=mask, cmap='Blues', vmin=-.01, vmax=1, annot=True)\n",
        "heatmap.set_title('Correlation Matrix for chosen tickers', fontdict={'fontsize':12}, pad=12);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZUxSCkc9qba"
      },
      "source": [
        "### **Analysing regimes in the data (using NIFTY 50 as the proxy)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We analyse the regimes in Nifty 50 data as it is a good proxy for our chosen tickers. We use the HMM model to determine the various regimes. As this is a stock price index data, the regimes correspond to bullish, bearish and stagnant regimes,"
      ],
      "metadata": {
        "id": "8GlBlVcHXkwa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAjGfM0hnDGK"
      },
      "outputs": [],
      "source": [
        "# We define and extract the Nifty 50 data from yf\n",
        "\n",
        "nifty_returns = pd.DataFrame()\n",
        "nifty_prices = pd.DataFrame()\n",
        "nifty_regime = pd.DataFrame()\n",
        "nifty_prices[\"Close price\"] = yf.download(\"^NSEI\", start=START_DATE, end=END_DATE)['Close'][1:]\n",
        "nifty_returns[\"nifty_return\"] = yf.download(\"^NSEI\", start=START_DATE, end=END_DATE)['Close'].pct_change()\n",
        "nifty_regime[\"Price\"] = nifty_prices[\"Close price\"]\n",
        "nifty_regime[\"Return\"] = nifty_returns[\"nifty_return\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnUNGtB1pzba"
      },
      "outputs": [],
      "source": [
        "# We define the hmm model to determine the regimes.\n",
        "\n",
        "model = hmm.GaussianHMM(n_components=3, covariance_type=\"full\", n_iter=10000000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHDKgQiMIpHG"
      },
      "outputs": [],
      "source": [
        "# We calculate the difference in closing prices to input into hmm model\n",
        "\n",
        "nifty_regime['diff'] = nifty_regime['Price'].diff()\n",
        "nifty_regime['States'] = nifty_regime['diff'].apply(lambda x: 1 if x > 0 else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUizqSkCI2hC"
      },
      "outputs": [],
      "source": [
        "# Dropping any null values\n",
        "\n",
        "nifty_regime = nifty_regime.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVSMiDk_G6wM"
      },
      "outputs": [],
      "source": [
        "# We fit the hmm model with the data created above\n",
        "model.fit(nifty_regime[\"diff\"].to_frame())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x853wn4qrf6i"
      },
      "outputs": [],
      "source": [
        "# We use the model to predict the regimes\n",
        "\n",
        "nifty_regime['Regime'] = model.predict(nifty_regime[\"diff\"].to_frame())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVDNhsrYrf-K"
      },
      "outputs": [],
      "source": [
        "means = nifty_regime.groupby(['Regime'])['diff'].mean();\n",
        "lst_1 = means.index.tolist();\n",
        "lst_2 = means.sort_values().index.tolist();\n",
        "map_regimes = dict(zip(lst_2, lst_1));\n",
        "nifty_regime['Regime'] = nifty_regime['Regime'].map(map_regimes);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfJShXCUrgCt"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "# We plot the regimes against the time series data\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20,8));\n",
        "ax.plot(nifty_regime['Price']);\n",
        "cmap = ListedColormap(['r','b','g'],'indexed');\n",
        "norm = BoundaryNorm(range(3 + 1), cmap.N);\n",
        "inxval = mdates.date2num(nifty_regime['Price'].index.to_pydatetime());\n",
        "points = np.array([inxval, nifty_regime['Price']]).T.reshape(-1, 1, 2);\n",
        "segments = np.concatenate([points[:-1], points[1:]], axis=1);\n",
        "lc = LineCollection(segments, cmap=cmap, norm=norm);\n",
        "55\n",
        "lc.set_array(nifty_regime['Regime']);\n",
        "plt.gca().add_collection(lc);\n",
        "plt.xlim(nifty_regime['Price'].index.min(), nifty_regime['Price'].index.max());\n",
        "plt.ylim(nifty_regime['Price'].min(), nifty_regime['Price'].max());\n",
        "r_patch = mpatches.Patch(color='red', label='Bear');\n",
        "g_patch = mpatches.Patch(color='green', label='Bull');\n",
        "b_patch = mpatches.Patch(color='blue', label='Stagnant');\n",
        "plt.legend(handles=[r_patch, g_patch, b_patch]);\n",
        "plt.title(\"Identifying bullish, bearish and stagnant phases in Nifty Index\",  fontsize=30)\n",
        "plt.xlabel(\"Time period (Years - Months)\")\n",
        "plt.ylabel(\"Nifty Index Level\")\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fMAiP-sLJlF"
      },
      "source": [
        "<hr style='border:2px solid black'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWyP-1IJU4XV"
      },
      "source": [
        "## **Section 7: Training and testing of traditional and RL agents**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si9EXyTxv6vM"
      },
      "source": [
        "In this section, we train and test all our approaches/agents with the training and testing data that we had created earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nx_sAej6KEB0"
      },
      "outputs": [],
      "source": [
        "Strategy_Returns_Data_trg = pd.DataFrame()\n",
        "Strategy_Returns_Data_trg.index = prices_train_data.index[2:]\n",
        "\n",
        "Strategy_Returns_Data_test = pd.DataFrame()\n",
        "Strategy_Returns_Data_test.index = prices_test_data.index[2:]\n",
        "cut_off_date = Strategy_Returns_Data_test.index[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nWfDquF_Ogb"
      },
      "outputs": [],
      "source": [
        "returns_train_data = prices_train_data[tickers_wo_cash].pct_change().dropna()\n",
        "returns_test_data  = prices_test_data[tickers_wo_cash].pct_change().dropna()\n",
        "initial_capital    = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlHUjaoAp5Tg"
      },
      "source": [
        "## **A. Markowitz Mean-Variance Approach**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuH1kVIwpzr6"
      },
      "outputs": [],
      "source": [
        "# We determine the weights based on the training data\n",
        "\n",
        "cov_matrix_markow = risk_models.CovarianceShrinkage(prices_train_data[tickers_wo_cash]).ledoit_wolf()\n",
        "ef = EfficientFrontier(None, cov_matrix_markow, weight_bounds=(0, 1))\n",
        "ef.min_volatility()\n",
        "weights_markow = ef.clean_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqKLCV7ip8j_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "outputId": "a64c44a1-b202-4b5b-c79a-0777d795ab5e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2100x900 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot the weights\n",
        "plt.figure(figsize=(21, 9))\n",
        "bar = plt.bar(weights_markow.keys(), weights_markow.values(), color='skyblue')\n",
        "plt.xlabel(\"Tickers\")\n",
        "plt.xticks(tickers_wo_cash)\n",
        "plt.ylabel(\"Optimized Weights\")\n",
        "plt.title(\"Weights from Markowitz Optimization\")\n",
        "plt.bar_label(bar, labels=[f'{x*100:,.4f}' for x in bar.datavalues])\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0xmwB7rp8mz"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "capital = initial_capital\n",
        "capital_before_tc = initial_capital\n",
        "old_capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for t in range(1, len(returns_train_data)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = np.dot(np.array(list(weights_markow.values())), returns_train_data.iloc[t].values)\n",
        "\n",
        "    # Update portfolio value\n",
        "    capital_before_tc *= (1 + portfolio_return)\n",
        "    tcost = transaction_cost * abs(capital_before_tc - old_capital)/old_capital\n",
        "    capital *= (1 + portfolio_return - tcost)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "    old_capital = capital\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(list(returns_train_data.index[1:]), portfolio_values, label=\"Markowitz Portfolio\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance Based on Markowitz optimization - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_markow\"] = portfolio_returns\n",
        "# Calculate performance metrics\n",
        "final_value_trg_markow = capital\n",
        "total_return_trg_markow = final_value_trg_markow - initial_capital\n",
        "sharpe_ratio_trg_markow = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_markow = (final_value_trg_markow / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_markow = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_markow:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_markow:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_markow*100 :.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_markow:.4f}\")\n",
        "print(f\"Maximum Drawdown (%): {maxdraw_trg_markow:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyVAinZ5p8qM"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "capital_before_tc = initial_capital\n",
        "old_capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "\n",
        "for t in range(1, len(returns_test_data)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = np.dot(np.array(list(weights_markow.values())), returns_test_data.iloc[t].values)\n",
        "\n",
        "    # Update portfolio value\n",
        "    capital_before_tc *= (1 + portfolio_return)\n",
        "    tcost = transaction_cost * abs(capital_before_tc - old_capital)/old_capital\n",
        "    capital *= (1 + portfolio_return - tcost)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "    old_capital = capital\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_test_data.index[1:], portfolio_values, label=\"Markowitz Portfolio\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance Based on Markowitz optimization - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_markow\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "returns_test_markow = pd.DataFrame(portfolio_returns)\n",
        "final_value_test_markow = capital\n",
        "total_return_test_markow = final_value_test_markow - initial_capital\n",
        "sharpe_ratio_test_markow = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_markow = (final_value_test_markow / initial_capital) ** (1 / (len(returns_test_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_markow = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_markow:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_markow:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_markow * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_markow:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_markow:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEe0ob7NuImA"
      },
      "source": [
        "## **B. Kelly's Criterion for Portfolio Optimization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZylL8s6auQhF"
      },
      "outputs": [],
      "source": [
        "# We determine the weights as per Kelly's criteria\n",
        "\n",
        "variances = returns_train_data.var()  # Variance of returns\n",
        "expected_returns = returns_train_data.mean()\n",
        "# Step 2: Calculate Kelly Criterion for each security\n",
        "kelly_fractions = expected_returns / variances\n",
        "kelly_fractions_normalized = kelly_fractions / kelly_fractions.sum()\n",
        "weights_kelly = kelly_fractions_normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETq2H6AZuKrw"
      },
      "outputs": [],
      "source": [
        "# Plot the weights\n",
        "plt.figure(figsize=(21, 9))\n",
        "bar = plt.bar(list(weights_kelly.index), list(weights_kelly), color='skyblue')\n",
        "plt.xlabel(\"Tickers\")\n",
        "plt.xticks(list(weights_kelly.index))\n",
        "plt.ylabel(\"Optimized Weights\")\n",
        "plt.title(\"Weights from Kelly Criterion\")\n",
        "plt.bar_label(bar, labels=[f'{x*100:,.4f}' for x in bar.datavalues])\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCN6G0MvuLBa"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "capital_before_tc = initial_capital\n",
        "old_capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for t in range(1, len(returns_train_data)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = np.dot(weights_kelly, returns_train_data.iloc[t].values)\n",
        "\n",
        "    # Update portfolio value\n",
        "    capital_before_tc *= (1 + portfolio_return)\n",
        "    tcost = transaction_cost * abs(capital_before_tc - old_capital)/old_capital\n",
        "    capital *= (1 + portfolio_return - tcost)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "    old_capital = capital\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"Kelly Criterion Portfolio\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on Kelly Criterion - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_kelly\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_kelly = capital\n",
        "total_return_trg_kelly = final_value_trg_kelly - initial_capital\n",
        "sharpe_ratio_trg_kelly = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_kelly = (final_value_trg_kelly / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_kelly = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_kelly:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_kelly:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_kelly * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_kelly:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_kelly:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvgYhXoOuLE3"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "capital_before_tc = initial_capital\n",
        "old_capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for t in range(1, len(returns_test_data)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = np.dot(weights_kelly, returns_test_data.iloc[t].values)\n",
        "\n",
        "    # Update portfolio value\n",
        "    capital_before_tc *= (1 + portfolio_return)\n",
        "    tcost = transaction_cost * abs(capital_before_tc - old_capital)/old_capital\n",
        "    capital *= (1 + portfolio_return - tcost)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "    old_capital = capital\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_test_data.index[1:], portfolio_values, label=\"Kelly Criterion Portfolio\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on Kelly Criterion - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_kelly\"] = portfolio_returns\n",
        "\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_kelly = capital\n",
        "total_return_test_kelly = final_value_test_kelly - initial_capital\n",
        "sharpe_ratio_test_kelly = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_kelly = (final_value_test_kelly / initial_capital) ** (1 / (len(returns_test_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_kelly = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_kelly:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_kelly:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_kelly * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_kelly:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_kelly:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmK0LBNLG_zX"
      },
      "source": [
        "## **C. De Prado's Denoising Approach**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2PbeoWMuLG6"
      },
      "outputs": [],
      "source": [
        "N = returns_train_data.shape[1]\n",
        "T = returns_train_data.shape[0]\n",
        "x = returns_train_data.copy()\n",
        "# code snippet 2.2 - marcenko-pastur pdf explains eigenvalues of random matrix x\n",
        "cor = np.corrcoef(x, rowvar=0) # cor.shape = (1000,1000). If rowvar=1 - row represents a var, with observations in the columns.\n",
        "eVal0 , eVec0 = getPCA( cor )\n",
        "pdf0 = mpPDF(1., q=x.shape[0]/float(x.shape[1]), pts=N)\n",
        "pdf1 = fitKDE(np.diag(eVal0), bWidth=.005) #empirical pdf\n",
        "\n",
        "# code snippet 2.3 - random matrix with signal\n",
        "alpha, nCols, nFact, q = .995, N, 100, 10\n",
        "pdf0 = mpPDF(1., q=x.shape[0]/float(x.shape[1]), pts=N)\n",
        "cov = np.cov(np.random.normal(size=(nCols*q, nCols)), rowvar=0) #size = (1000*10,1000)\n",
        "cov = alpha*cov+(1-alpha)*getRndCov(nCols, nFact) # noise + signal\n",
        "corr0 = cov2corr(cov)\n",
        "eVal01, eVec01 = getPCA(corr0)\n",
        "#pdf2 = fitKDE(np.diag(eVal01), bWidth=.15) #empirical pdf\n",
        "\n",
        "# Figure 2.1 Plot empirical:KDE and Marcenko-Pastur, and histogram\n",
        "fig = plt.figure()\n",
        "ax  = fig.add_subplot(111)\n",
        "ax.hist(np.diag(eVal01), density = True, bins=50) # Histogram the eigenvalues\n",
        "\n",
        "eMax0, var0 = findMaxEval(np.diag(eVal01), q, bWidth=.01)\n",
        "nFacts0 = eVal01.shape[0]-np.diag(eVal01)[::-1].searchsorted(eMax0)\n",
        "\n",
        "#code snippet 2.3 - with random matrix with signal\n",
        "######################\n",
        "# Figure 2.1 Plot empirical:KDE and Marcenko-Pastur, and histogram\n",
        "pdf0 = mpPDF(var0, q=x.shape[0]/float(x.shape[1]), pts=N)\n",
        "fig = plt.figure()\n",
        "ax  = fig.add_subplot(111)\n",
        "ax.hist(np.diag(eVal01), density = True, bins=50) # Histogram the eigenvalues\n",
        "\n",
        "plt.plot(pdf0.keys(), pdf0, color='r', label=\"Marcenko-Pastur pdf\")\n",
        "#plt.plot(pdf1.keys(), pdf1, color='g', label=\"Empirical:KDE\")\n",
        "#plt.plot(x_range, pdf2, color='b', label=\"Eigenvalues of random-matrix with signal\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()\n",
        "######################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1LiQCrjuLJw"
      },
      "outputs": [],
      "source": [
        "# code snippet 2.5 - denoising by constant residual eigenvalue\n",
        "corr1 = denoisedCorr(eVal01, eVec01, nFacts0)\n",
        "eVal1, eVec1 = getPCA(corr1)\n",
        "\n",
        "denoised_eigenvalue = np.diag(eVal1)\n",
        "eigenvalue_prior = np.diag(eVal01)\n",
        "plt.plot(range(0, len(denoised_eigenvalue)), np.log(denoised_eigenvalue), color='r', label=\"Denoised eigen-function\")\n",
        "plt.plot(range(0, len(eigenvalue_prior)), np.log(eigenvalue_prior), color='g', label=\"Original eigen-function\")\n",
        "plt.xlabel(\"Eigenvalue number\")\n",
        "plt.ylabel(\"Eigenvalue (log-scale)\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()\n",
        "\n",
        "corr_detoned_denoised = detoned_corr(corr1, eVal1, eVec1)\n",
        "\n",
        "eVal1_detoned, eVec1_detoned = getPCA(corr_detoned_denoised)\n",
        "detoned_denoised_eigenvalue = np.diag(eVal1_detoned)\n",
        "denoised_eigenvalue = np.diag(eVal1)\n",
        "eigenvalue_prior = np.diag(eVal01)\n",
        "\n",
        "plt.plot(range(0, len(detoned_denoised_eigenvalue)), np.log(detoned_denoised_eigenvalue), color='b', label=\"Detoned, denoised eigen-function\")\n",
        "plt.plot(range(0, len(denoised_eigenvalue)), np.log(denoised_eigenvalue), color='r', label=\"Denoised eigen-function\")\n",
        "plt.plot(range(0, len(eigenvalue_prior)), np.log(eigenvalue_prior), color='g', label=\"Original eigen-function\")\n",
        "plt.xlabel(\"Eigenvalue number\")\n",
        "plt.ylabel(\"Eigenvalue (log-scale)\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUmwTKHWuLNY"
      },
      "outputs": [],
      "source": [
        "std = np.sqrt(np.diag(returns_train_data.cov()))\n",
        "cov_denoised = corr2cov(corr1, std)\n",
        "weights_denoised = optPort(cov_denoised, returns_train_data.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fln6kodeJGCu"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "capital_before_tc = initial_capital\n",
        "old_capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for t in range(1, len(returns_train_data)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = np.dot(weights_denoised, returns_train_data.iloc[t].values)\n",
        "\n",
        "    # Update portfolio value\n",
        "    capital_before_tc *= (1 + portfolio_return)\n",
        "    tcost = transaction_cost * abs(capital_before_tc - old_capital)/old_capital\n",
        "    capital *= (1 + portfolio_return - tcost)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "    old_capital = capital\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"Denoised Portfolio\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on Denoising - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_denoised\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_denoised = capital\n",
        "total_return_trg_denoised = final_value_trg_denoised - initial_capital\n",
        "sharpe_ratio_trg_denoised = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_denoised = (final_value_trg_denoised / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_denoised = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_denoised:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_denoised:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_denoised * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_denoised:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_denoised:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY7lw2BjMtuq"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "capital_before_tc = initial_capital\n",
        "old_capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for t in range(1, len(returns_test_data)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = np.dot(weights_denoised, returns_test_data.iloc[t].values)\n",
        "\n",
        "    # Update portfolio value\n",
        "    capital_before_tc *= (1 + portfolio_return)\n",
        "    tcost = transaction_cost * abs(capital_before_tc - old_capital)/old_capital\n",
        "    capital *= (1 + portfolio_return - tcost)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "    old_capital = capital\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_test_data.index[1:], portfolio_values, label=\"Denoised Portfolio\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on Denoising - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_denoised\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_denoised = capital\n",
        "total_return_test_denoised = final_value_test_denoised - initial_capital\n",
        "sharpe_ratio_test_denoised = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_denoised = (final_value_test_denoised / initial_capital) ** (1 / (len(returns_test_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_denoised = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_denoised:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_denoised:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_denoised * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_denoised:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_denoised:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlhk8uxBN9ur"
      },
      "source": [
        "## **D. Equal-weighted Approach**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN4FCpAvOMjs"
      },
      "outputs": [],
      "source": [
        "weights_eq = np.ones(len(tickers_wo_cash))/len(tickers_wo_cash)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcVrIHcKMtxQ"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "capital_before_tc = initial_capital\n",
        "old_capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for t in range(1, len(returns_train_data)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = np.dot(weights_eq, returns_train_data.iloc[t].values)\n",
        "\n",
        "    # Update portfolio value\n",
        "    capital_before_tc *= (1 + portfolio_return)\n",
        "    tcost = transaction_cost * abs(capital_before_tc - old_capital)/old_capital\n",
        "    capital *= (1 + portfolio_return - tcost)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "    old_capital = capital\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"Equal-weighted Portfolio\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on Equal weights - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_eq\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_eq = capital\n",
        "total_return_trg_eq = final_value_trg_eq - initial_capital\n",
        "sharpe_ratio_trg_eq = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_eq = (final_value_trg_eq / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_eq = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_eq:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_eq:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_eq * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_eq:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_eq:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoBH8RG9Mt1g"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "capital_before_tc = initial_capital\n",
        "old_capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for t in range(1, len(returns_test_data)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = np.dot(weights_eq, returns_test_data.iloc[t].values)\n",
        "\n",
        "    # Update portfolio value\n",
        "    capital_before_tc *= (1 + portfolio_return)\n",
        "    tcost = transaction_cost * abs(capital_before_tc - old_capital)/old_capital\n",
        "    capital *= (1 + portfolio_return - tcost)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "    old_capital = capital\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 8))\n",
        "plt.plot(returns_test_data.index[1:], portfolio_values, label=\"Equal-weighted Portfolio\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on Equal weights - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_eq\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_eq = capital\n",
        "total_return_test_eq = final_value_test_eq - initial_capital\n",
        "sharpe_ratio_test_eq = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_eq = (final_value_test_eq / initial_capital) ** (1 / (len(returns_test_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_eq = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_eq:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_eq:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_eq * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_eq:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_eq:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqPNFD7Cg_6G"
      },
      "source": [
        "## **E. A2C RL Model with TI as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZH6LNUYq0-X"
      },
      "outputs": [],
      "source": [
        "stock_dimension = len(tickers)\n",
        "state_space = stock_dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-b1TeJzq1Fd"
      },
      "outputs": [],
      "source": [
        "env_kwargs = { \"hmax\": 500, \"initial_amount\": 1000000, \"transaction_cost_pct\": transaction_cost, \"state_space\": state_space,  \"stock_dim\": stock_dimension,  \"tech_indicator_list\": ti_abbreviations,\n",
        "    \"action_space\": stock_dimension,  \"reward_scaling\": 0, 'initial_weights': [1/stock_dimension]*stock_dimension}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8IkaPzVq1H4"
      },
      "outputs": [],
      "source": [
        "e_train_gym = StockPortfolioEnv(df = train_data_ti, **env_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLuZtPGLq1KE"
      },
      "outputs": [],
      "source": [
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-qnEVkVq1Ma"
      },
      "outputs": [],
      "source": [
        "# initialize\n",
        "agent = DRLAgent(env = env_train)\n",
        "model_a2c_ti = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS_TI)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wExEiDV6q1O3"
      },
      "outputs": [],
      "source": [
        "trained_a2c_ti = agent.train_model(model=model_a2c_ti, tb_log_name='a2c', total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['a2c_ti'] = trained_a2c_ti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxUCIgzCTu3l"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "# A2C Train Model\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ti, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "a2c_train_returns_ti, _ = DRLAgent.DRL_prediction(model=trained_a2c_ti, test_data = train_data_ti, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNRAkEgNTu6j"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(a2c_train_returns_ti)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = a2c_train_returns_ti['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"A2C TI Portfolio\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on A2C Algorithm with TI as the State - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_a2c_ti\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_a2c_ti = capital\n",
        "total_return_trg_a2c_ti = final_value_trg_a2c_ti - initial_capital\n",
        "sharpe_ratio_trg_a2c_ti = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_a2c_ti = (final_value_trg_a2c_ti / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_a2c_ti = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_a2c_ti:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_a2c_ti:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_a2c_ti * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_a2c_ti:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_a2c_ti:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-ONh50eTu9w"
      },
      "outputs": [],
      "source": [
        "# A2C Test Model\n",
        "import time\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ti, **env_kwargs)\n",
        "env_a2c_ti_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['a2c_ti_test'] = copy.copy(env_a2c_ti_test)\n",
        "DynaCAAST_Obs['a2c_ti_test'] = obs_trade.copy()\n",
        "a2c_test_returns_ti, _ = DRLAgent.DRL_prediction(model=trained_a2c_ti, test_data = test_data_ti, test_env = env_a2c_ti_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWqbudy9Ulzt"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(a2c_test_returns_ti)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = a2c_test_returns_ti['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(a2c_test_returns_ti[\"date\"][1:], portfolio_values, label=\"A2C TI Portfolio\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on A2C Algorithm  with TI as the State- Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_a2c_ti\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_a2c_ti = capital\n",
        "total_return_test_a2c_ti = final_value_test_a2c_ti - initial_capital\n",
        "sharpe_ratio_test_a2c_ti = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_a2c_ti = (final_value_test_a2c_ti / initial_capital) ** (1 / (len(returns_test_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_a2c_ti = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_a2c_ti:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_a2c_ti:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_a2c_ti * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio : {sharpe_ratio_test_a2c_ti:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_a2c_ti:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j388XXnrVQ1k"
      },
      "source": [
        "## **F. PPO RL Model with TI as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePn8-E80q1RO"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "model_ppo_ti = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS_TI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKrvuOciq1T5"
      },
      "outputs": [],
      "source": [
        "trained_ppo_ti = agent.train_model(model=model_ppo_ti, tb_log_name='ppo', total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['ppo_ti'] = trained_ppo_ti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ogG0wGHWUkN"
      },
      "outputs": [],
      "source": [
        "# PPO Train Model\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ti, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "ppo_train_returns_ti, _ = DRLAgent.DRL_prediction(model=trained_ppo_ti, test_data = train_data_ti, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKG_nCDJWUnb"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(ppo_train_returns_ti)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = ppo_train_returns_ti['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"PPO TI Portfolio\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on PPO Algorithm with TI as the State - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_ppo_ti\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_ppo_ti = capital\n",
        "total_return_trg_ppo_ti = final_value_trg_ppo_ti - initial_capital\n",
        "sharpe_ratio_trg_ppo_ti = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_ppo_ti = (final_value_trg_ppo_ti / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_ppo_ti = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_ppo_ti:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_ppo_ti:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_ppo_ti * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_ppo_ti:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_ppo_ti:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YudotpfjWUqk"
      },
      "outputs": [],
      "source": [
        "# PPO Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ti, **env_kwargs)\n",
        "env_ppo_ti_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ppo_ti_test'] = copy.copy(env_ppo_ti_test)\n",
        "DynaCAAST_Obs['ppo_ti_test'] = obs_trade.copy()\n",
        "\n",
        "ppo_test_returns_ti, _ = DRLAgent.DRL_prediction(model=trained_ppo_ti, test_data = test_data_ti, test_env = env_ppo_ti_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vuTba12WUtU"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(ppo_test_returns_ti)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = ppo_test_returns_ti['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(ppo_test_returns_ti[\"date\"][1:], portfolio_values, label=\"PPO TI Portfolio\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on PPO Algorithm  with TI as the State- Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_ppo_ti\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_ppo_ti = capital\n",
        "total_return_test_ppo_ti = final_value_test_ppo_ti - initial_capital\n",
        "sharpe_ratio_test_ppo_ti = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_ppo_ti = (final_value_test_ppo_ti / initial_capital) ** (1 / (len(ppo_test_returns_ti) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_ppo_ti = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_ppo_ti:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_ppo_ti:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_ppo_ti * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_ppo_ti:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_ppo_ti:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YncprzUbYk8J"
      },
      "source": [
        "## **G. DDPG RL Model with TI as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yywMX-M4q1W3"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_ddpg_ti = agent.get_model(\"ddpg\",model_kwargs = DDPG_PARAMS_TI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNkL8qunYyda"
      },
      "outputs": [],
      "source": [
        "trained_ddpg_ti = agent.train_model(model=model_ddpg_ti, tb_log_name='ddpg',  total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['ddpg_ti'] = trained_ddpg_ti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGM58sotZFWa"
      },
      "outputs": [],
      "source": [
        "# DDPG Train Model num_stock = df_pct_change.shape[1]\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ti, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "ddpg_train_returns_ti, _ = DRLAgent.DRL_prediction(model=trained_ddpg_ti, test_data = train_data_ti, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoP9_kgxZFaA"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(ddpg_train_returns_ti)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = ddpg_train_returns_ti['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"DDPG TI Portfolio\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on DDPG Algorithm  with TI as the State - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_ddpg_ti\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_ddpg_ti = capital\n",
        "total_return_trg_ddpg_ti = final_value_trg_ddpg_ti - initial_capital\n",
        "sharpe_ratio_trg_ddpg_ti = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_ddpg_ti = (final_value_trg_ddpg_ti / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_ddpg_ti = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_ddpg_ti:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_ddpg_ti:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_ddpg_ti * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_ddpg_ti:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_ddpg_ti:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGaPVu-hayd8"
      },
      "outputs": [],
      "source": [
        "# DDPG Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ti, **env_kwargs)\n",
        "env_ddpg_ti_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ddpg_ti_test'] = copy.copy(env_ddpg_ti_test)\n",
        "DynaCAAST_Obs['ddpg_ti_test'] = obs_trade.copy()\n",
        "ddpg_test_returns_ti, _ = DRLAgent.DRL_prediction(model=trained_ddpg_ti, test_data = test_data_ti, test_env = env_ddpg_ti_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewUgRL9dayhy"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(ddpg_test_returns_ti)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = ddpg_test_returns_ti['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(ddpg_test_returns_ti[\"date\"][1:], portfolio_values, label=\"DDPG TI Portfolio\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on DDPG Algorithm with TI as the State - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_ddpg_ti\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_ddpg_ti = capital\n",
        "total_return_test_ddpg_ti = final_value_test_ddpg_ti - initial_capital\n",
        "sharpe_ratio_test_ddpg_ti = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_ddpg_ti = (final_value_test_ddpg_ti / initial_capital) ** (1 / (len(ddpg_test_returns_ti) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_ddpg_ti = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_ddpg_ti:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_ddpg_ti:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_ddpg_ti * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_ddpg_ti:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_ddpg_ti:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar_Q5r-ihFlF"
      },
      "source": [
        "## **H. SAC RL Model with TI as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrRm3T0mhQd9"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_sac_ti = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS_TI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf-VNYdrhQu5"
      },
      "outputs": [],
      "source": [
        "trained_sac_ti = agent.train_model(model=model_sac_ti, tb_log_name='sac', total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['sac_ti'] = trained_sac_ti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVHgs-JehiE-"
      },
      "outputs": [],
      "source": [
        "#  SAC Train Model num_stock = df_pct_change.shape[1]\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ti, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "sac_train_returns_ti, _ = DRLAgent.DRL_prediction(model=trained_sac_ti, test_data = train_data_ti, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsa1toTRZFd-"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(sac_train_returns_ti)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = sac_train_returns_ti['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"SAC TI Portfolio\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on SAC Algorithm  with TI as the State- Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_sac_ti\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_sac_ti = capital\n",
        "total_return_trg_sac_ti = final_value_trg_sac_ti - initial_capital\n",
        "sharpe_ratio_trg_sac_ti = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_sac_ti = (final_value_trg_sac_ti / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_sac_ti = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_sac_ti:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_sac_ti:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_sac_ti * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio Kelly: {sharpe_ratio_trg_sac_ti:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_sac_ti:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hug3F6Ao300d"
      },
      "outputs": [],
      "source": [
        "# SAC Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ti, **env_kwargs)\n",
        "env_sac_ti_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['sac_ti_test'] = copy.copy(env_sac_ti_test)\n",
        "DynaCAAST_Obs['sac_ti_test'] = copy.copy(obs_trade)\n",
        "sac_test_returns_ti, _ = DRLAgent.DRL_prediction(model=trained_sac_ti, test_data = test_data_ti, test_env = env_sac_ti_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_H1Qgkl3_hC"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(sac_test_returns_ti)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = sac_test_returns_ti['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(sac_test_returns_ti[\"date\"][1:], portfolio_values, label=\"SAC TI Portfolio\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on SAC Algorithm  with TI as the State- Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_sac_ti\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_sac_ti = capital\n",
        "total_return_test_sac_ti = final_value_test_sac_ti - initial_capital\n",
        "sharpe_ratio_test_sac_ti = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_sac_ti = (final_value_test_sac_ti / initial_capital) ** (1 / (len(sac_test_returns_ti) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_sac_ti = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_sac_ti:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_sac_ti:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_sac_ti * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_sac_ti:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_sac_ti:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfcP5vj_16aA"
      },
      "source": [
        "## **I. TD3 RL Model with TI as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX7WR-YSq05W"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_td3_ti = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS_TI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzuBBu45q078"
      },
      "outputs": [],
      "source": [
        "trained_td3_ti = agent.train_model(model=model_td3_ti, tb_log_name='td3', total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['td3_ti'] = trained_td3_ti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AtYp4gGsFep"
      },
      "outputs": [],
      "source": [
        "# td3 Train Model num_stock = df_pct_change.shape[1]\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ti, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "td3_train_returns_ti, _ = DRLAgent.DRL_prediction(model=trained_td3_ti, test_data = train_data_ti, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRODYMITRRM3"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(td3_train_returns_ti)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = td3_train_returns_ti['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"TD3 TI Portfolio\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on TD3 Algorithm  with TI as the State- Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_td3_ti\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_td3_ti = capital\n",
        "total_return_trg_td3_ti = final_value_trg_td3_ti - initial_capital\n",
        "sharpe_ratio_trg_td3_ti = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_td3_ti = (final_value_trg_td3_ti / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_td3_ti = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_td3_ti:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_td3_ti:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_td3_ti * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_td3_ti:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_td3_ti:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTSa-7nMxzm5"
      },
      "outputs": [],
      "source": [
        "# TD3 Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ti, **env_kwargs)\n",
        "env_td3_ti_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['td3_ti_test'] = copy.copy(env_td3_ti_test)\n",
        "DynaCAAST_Obs['td3_ti_test'] = obs_trade.copy()\n",
        "\n",
        "td3_test_returns_ti, _ = DRLAgent.DRL_prediction(model=trained_td3_ti, test_data = test_data_ti, test_env = env_td3_ti_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJMny-_9TFy0"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(td3_test_returns_ti)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = td3_test_returns_ti['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(td3_test_returns_ti[\"date\"][1:], portfolio_values, label=\"TD3 TI Portfolio\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on TD3 Algorithm with TI as the State - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_td3_ti\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_td3_ti = capital\n",
        "total_return_test_td3_ti = final_value_test_td3_ti - initial_capital\n",
        "sharpe_ratio_test_td3_ti = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_td3_ti = (final_value_test_td3_ti / initial_capital) ** (1 / (len(td3_test_returns_ti) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_td3_ti = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_td3_ti:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_td3_ti:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_td3_ti * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_td3_ti:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_td3_ti:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xswM8mGwBfcX"
      },
      "source": [
        "## **J. Performance Analysis of RL agents using TI as their states**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkCAZByfvpbT"
      },
      "outputs": [],
      "source": [
        "returns_train = prices_train_data.pct_change() # get the assets daily returns\n",
        "returns_test = prices_test_data.pct_change()\n",
        "\n",
        "\n",
        "a2c_train_cum_returns_ti = (1 + a2c_train_returns_ti.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "a2c_train_cum_returns_ti = a2c_train_cum_returns_ti['daily_return']\n",
        "a2c_train_cum_returns_ti.name = 'A2C TI Model'\n",
        "\n",
        "ppo_train_cum_returns_ti = (1 + ppo_train_returns_ti.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "ppo_train_cum_returns_ti = ppo_train_cum_returns_ti['daily_return']\n",
        "ppo_train_cum_returns_ti.name = 'PPO TI Model'\n",
        "\n",
        "ddpg_train_cum_returns_ti = (1 + ddpg_train_returns_ti.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "ddpg_train_cum_returns_ti = ddpg_train_cum_returns_ti['daily_return']\n",
        "ddpg_train_cum_returns_ti.name = 'DDPG TI Model'\n",
        "\n",
        "sac_train_cum_returns_ti = (1 + sac_train_returns_ti.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "sac_train_cum_returns_ti = sac_train_cum_returns_ti['daily_return']\n",
        "sac_train_cum_returns_ti.name = 'SAC TI Model'\n",
        "\n",
        "td3_train_cum_returns_ti = (1 + td3_train_returns_ti.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "td3_train_cum_returns_ti = td3_train_cum_returns_ti['daily_return']\n",
        "td3_train_cum_returns_ti.name = 'TD3 TI Model'\n",
        "\n",
        "date_list = list(ddpg_train_cum_returns_ti.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkYYsgk3vpeS"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Plot the culmulative returns of the portfolios\n",
        "fig, ax = plt.subplots(figsize=(21,9))\n",
        "a2c_train_cum_returns_ti.plot(ax=ax, color='blue', alpha=0.4)\n",
        "ppo_train_cum_returns_ti.plot(ax=ax, color='green', alpha=0.4)\n",
        "ddpg_train_cum_returns_ti.plot(ax=ax, color='skyblue', alpha=0.4)\n",
        "sac_train_cum_returns_ti.plot(ax=ax, color='red', alpha=0.4)\n",
        "td3_train_cum_returns_ti.plot(ax=ax, color='black', alpha=0.4)\n",
        "\n",
        "plt.legend(loc=\"best\");\n",
        "plt.grid(True);\n",
        "ax.set_ylabel(\"Cumulative return\");\n",
        "ax.set_title(\"Performance on the training data with Technical Indicators as the state\", fontsize=14);\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVTsQBf0vpgh"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# get the culmulative returns for each portfolio\n",
        "\n",
        "a2c_test_cum_returns_ti = (1 + a2c_test_returns_ti['daily_return']).cumprod()\n",
        "a2c_test_cum_returns_ti.name = 'A2C TI Model'\n",
        "a2c_test_cum_returns_ti.index = a2c_test_returns_ti['date']\n",
        "\n",
        "ppo_test_cum_returns_ti = (1 + ppo_test_returns_ti['daily_return']).cumprod()\n",
        "ppo_test_cum_returns_ti.name = 'PPO TI Model'\n",
        "ppo_test_cum_returns_ti.index = ppo_test_returns_ti['date']\n",
        "\n",
        "ddpg_test_cum_returns_ti = (1 + ddpg_test_returns_ti['daily_return']).cumprod()\n",
        "ddpg_test_cum_returns_ti.name = 'DDPG TI Model'\n",
        "ddpg_test_cum_returns_ti.index = ddpg_test_returns_ti['date']\n",
        "\n",
        "sac_test_cum_returns_ti = (1 + sac_test_returns_ti['daily_return']).cumprod()\n",
        "sac_test_cum_returns_ti.name = 'SAC TI Model'\n",
        "sac_test_cum_returns_ti.index = sac_test_returns_ti['date']\n",
        "\n",
        "td3_test_cum_returns_ti = (1 + td3_test_returns_ti['daily_return']).cumprod()\n",
        "td3_test_cum_returns_ti.name = 'TD3 TI Model'\n",
        "td3_test_cum_returns_ti.index = td3_test_returns_ti['date']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exzBJhNVSlHY"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "# Plot the culmulative returns of the portfolios\n",
        "fig, ax = plt.subplots(figsize=(21,9))\n",
        "a2c_test_cum_returns_ti.plot(ax=ax, color='blue', alpha=.4)\n",
        "ppo_test_cum_returns_ti.plot(ax=ax, color='green', alpha=.4)\n",
        "ddpg_test_cum_returns_ti.plot(ax=ax, color='skyblue', alpha=.4)\n",
        "sac_test_cum_returns_ti.plot(ax=ax, color='red', alpha=0.4)\n",
        "td3_test_cum_returns_ti.plot(ax=ax, color='black', alpha=0.4)\n",
        "\n",
        "plt.legend(loc=\"best\");\n",
        "plt.grid(True);\n",
        "ax.set_ylabel(\"Cumulative return\");\n",
        "ax.set_title(\"Performance on the testing data with Technical Indicators as the state\", fontsize=14);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0DNrZViCfa_"
      },
      "source": [
        "## **K. A2C RL Model with Lagged Returns as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eV2m1iZtCfbA"
      },
      "outputs": [],
      "source": [
        "stock_dimension = len(tickers)\n",
        "state_space = stock_dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9y6_RhV8CfbA"
      },
      "outputs": [],
      "source": [
        "env_kwargs = { \"hmax\": 500, \"initial_amount\": 1000000, \"transaction_cost_pct\": transaction_cost, \"state_space\": state_space,  \"stock_dim\": stock_dimension,  \"tech_indicator_list\": return_lags,\n",
        "    \"action_space\": stock_dimension,  \"reward_scaling\": 0, 'initial_weights': [1/stock_dimension]*stock_dimension}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyvHc8kpCfbA"
      },
      "outputs": [],
      "source": [
        "e_train_gym = StockPortfolioEnv(df = train_data_ret, **env_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkjTMbG_CfbA"
      },
      "outputs": [],
      "source": [
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5z9SRrsCCfbA"
      },
      "outputs": [],
      "source": [
        "# initialize\n",
        "agent = DRLAgent(env = env_train)\n",
        "model_a2c_ret = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS_RET)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkPu4zJmCfbB"
      },
      "outputs": [],
      "source": [
        "trained_a2c_ret = agent.train_model(model=model_a2c_ret, tb_log_name='a2c', total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['a2c_ret'] = trained_a2c_ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udBdcTtiCfbB"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "# A2C Train Model\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ret, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "a2c_train_returns_ret, _ = DRLAgent.DRL_prediction(model=trained_a2c_ret, test_data = train_data_ret, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKHYOuw8CfbB"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(a2c_train_returns_ret)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = a2c_train_returns_ret['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"A2C RET Portfolio\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on A2C Algorithm on Lagged Returns State - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_a2c_ret\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_a2c_ret = capital\n",
        "total_return_trg_a2c_ret = final_value_trg_a2c_ret - initial_capital\n",
        "sharpe_ratio_trg_a2c_ret = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_a2c_ret = (final_value_trg_a2c_ret / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_a2c_ret = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_a2c_ret:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_a2c_ret:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_a2c_ret * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_a2c_ret:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_a2c_ret:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRlAN5lMCfbB"
      },
      "outputs": [],
      "source": [
        "# A2C Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ret, **env_kwargs)\n",
        "env_a2c_ret_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['a2c_ret_test'] = copy.copy(env_a2c_ret_test)\n",
        "DynaCAAST_Obs['a2c_ret_test'] = obs_trade.copy()\n",
        "a2c_test_returns_ret, _ = DRLAgent.DRL_prediction(model=trained_a2c_ret, test_data = test_data_ret, test_env = env_a2c_ret_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YctWmDH5CfbB"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(a2c_test_returns_ret)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = a2c_test_returns_ret['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(a2c_test_returns_ret[\"date\"][1:], portfolio_values, label=\"A2C RET Portfolio\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on A2C Algorithm with Lagged Returns as the state - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_a2c_ret\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_a2c_ret = capital\n",
        "total_return_test_a2c_ret = final_value_test_a2c_ret - initial_capital\n",
        "sharpe_ratio_test_a2c_ret = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_a2c_ret = (final_value_test_a2c_ret / initial_capital) ** (1 / (len(returns_test_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_a2c_ret = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_a2c_ret:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_a2c_ret:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_a2c_ret * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio : {sharpe_ratio_test_a2c_ret:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_a2c_ret:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdRAQEOqCfbC"
      },
      "source": [
        "## **L. PPO RL Model with Lagged Returns as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGGVU54HCfbC"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "model_ppo_ret = agent.get_model(\"ppo\", model_kwargs = PPO_PARAMS_RET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZOc5a-VCfbC"
      },
      "outputs": [],
      "source": [
        "trained_ppo_ret = agent.train_model(model=model_ppo_ret, tb_log_name='ppo', total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['ppo_ret'] = trained_ppo_ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t_jNoUHCfbC"
      },
      "outputs": [],
      "source": [
        "# PPO Train Model\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ret, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "ppo_train_returns_ret, _ = DRLAgent.DRL_prediction(model=trained_ppo_ret, test_data = train_data_ret, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DAEJXfGCfbC"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(ppo_train_returns_ret)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = ppo_train_returns_ret['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"PPO RET Portfolio\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on PPO Algorithm with Lagged Returns as the state  - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_ppo_ret\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_ppo_ret = capital\n",
        "total_return_trg_ppo_ret = final_value_trg_ppo_ret - initial_capital\n",
        "sharpe_ratio_trg_ppo_ret = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_ppo_ret = (final_value_trg_ppo_ret / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_ppo_ret = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_ppo_ret:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_ppo_ret:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_ppo_ret * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_ppo_ret:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_ppo_ret:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1_7sxpMCfbD"
      },
      "outputs": [],
      "source": [
        "# PPO Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ret, **env_kwargs)\n",
        "env_ppo_ret_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ppo_ret_test'] = copy.copy(env_ppo_ret_test)\n",
        "DynaCAAST_Obs['ppo_ret_test'] = obs_trade.copy()\n",
        "ppo_test_returns_ret, _ = DRLAgent.DRL_prediction(model=trained_ppo_ret, test_data = test_data_ret, test_env = env_ppo_ret_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjSCFcm9CfbD"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(ppo_test_returns_ret)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = ppo_test_returns_ret['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(ppo_test_returns_ti[\"date\"][1:], portfolio_values, label=\"PPO RET Portfolio\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on PPO Algorithm with Lagged Returns as the state  - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_ppo_ret\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_ppo_ret = capital\n",
        "total_return_test_ppo_ret = final_value_test_ppo_ret - initial_capital\n",
        "sharpe_ratio_test_ppo_ret = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_ppo_ret = (final_value_test_ppo_ret / initial_capital) ** (1 / (len(ppo_test_returns_ret) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_ppo_ret = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_ppo_ret:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_ppo_ret:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_ppo_ret * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_ppo_ret:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_ppo_ret:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGL7AwwyCfbD"
      },
      "source": [
        "## **M. DDPG RL Model with Lagged Returns as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxQ4zkt2CfbD"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_ddpg_ret = agent.get_model(\"ddpg\", model_kwargs = DDPG_PARAMS_RET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCt5rM5pCfbD"
      },
      "outputs": [],
      "source": [
        "trained_ddpg_ret = agent.train_model(model= model_ddpg_ret, tb_log_name='ddpg',  total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['ddpg_ret'] = trained_ddpg_ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVN5VeBKCfbD"
      },
      "outputs": [],
      "source": [
        "# DDPG Train Model num_stock = df_pct_change.shape[1]\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ret, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "ddpg_train_returns_ret, _ = DRLAgent.DRL_prediction(model=trained_ddpg_ret, test_data = train_data_ret, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrrOv_UOCfbD"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(ddpg_train_returns_ret)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = ddpg_train_returns_ret['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"DDPG RET Portfolio\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on DDPG Algorithm with Lagged Returns as the state  - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_ddpg_ret\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_ddpg_ret = capital\n",
        "total_return_trg_ddpg_ret = final_value_trg_ddpg_ret - initial_capital\n",
        "sharpe_ratio_trg_ddpg_ret = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_ddpg_ret = (final_value_trg_ddpg_ret / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_ddpg_ret = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_ddpg_ret:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_ddpg_ret:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_ddpg_ret * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_ddpg_ret:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_ddpg_ret:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tjGe35eCfbE"
      },
      "outputs": [],
      "source": [
        "# DDPG Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ret, **env_kwargs)\n",
        "env_ddpg_ret_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ddpg_ret_test'] = copy.copy(env_ddpg_ret_test)\n",
        "DynaCAAST_Obs['ddpg_ret_test'] = obs_trade.copy()\n",
        "ddpg_test_returns_ret, _ = DRLAgent.DRL_prediction(model=trained_ddpg_ret, test_data = test_data_ret, test_env = env_ddpg_ret_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC0JkFQFCfbE"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(ddpg_test_returns_ret)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = ddpg_test_returns_ret['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(ddpg_test_returns_ret[\"date\"][1:], portfolio_values, label=\"DDPG RET Portfolio\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on DDPG Algorithm with Lagged Returns as the state  - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_ddpg_ret\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_ddpg_ret = capital\n",
        "total_return_test_ddpg_ret = final_value_test_ddpg_ret - initial_capital\n",
        "sharpe_ratio_test_ddpg_ret = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_ddpg_ret = (final_value_test_ddpg_ret / initial_capital) ** (1 / (len(ddpg_test_returns_ret) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_ddpg_ret = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_ddpg_ret:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_ddpg_ret:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_ddpg_ret * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_ddpg_ret:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_ddpg_ret:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM4PkNmoCfbE"
      },
      "source": [
        "## **N. SAC RL Model with Lagged Returns as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC71G20RCfbE"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_sac_ret = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS_RET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1ap9xBcCfbE"
      },
      "outputs": [],
      "source": [
        "trained_sac_ret = agent.train_model(model=model_sac_ret, tb_log_name='sac', total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['sac_ret'] = trained_sac_ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eucOsa4XCfbE"
      },
      "outputs": [],
      "source": [
        "#  SAC Train Model num_stock = df_pct_change.shape[1]\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ret, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "sac_train_returns_ret, _ = DRLAgent.DRL_prediction(model=trained_sac_ret, test_data = train_data_ret, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3THFEdIfCfbE"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(sac_train_returns_ret)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = sac_train_returns_ret['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"SAC RET Portfolio\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on SAC Algorithm with Lagged Returns as the state  - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_sac_ret\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_sac_ret = capital\n",
        "total_return_trg_sac_ret = final_value_trg_sac_ret - initial_capital\n",
        "sharpe_ratio_trg_sac_ret = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_sac_ret = (final_value_trg_sac_ret / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_sac_ret = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_sac_ret:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_sac_ret:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_sac_ret * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio Kelly: {sharpe_ratio_trg_sac_ret:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_sac_ret:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1sIkg38CfbF"
      },
      "outputs": [],
      "source": [
        "# SAC Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ret, **env_kwargs)\n",
        "env_sac_ret_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['sac_ret_test'] = copy.copy(env_sac_ret_test)\n",
        "DynaCAAST_Obs['sac_ret_test'] = obs_trade.copy()\n",
        "sac_test_returns_ret, _ = DRLAgent.DRL_prediction(model=trained_sac_ret, test_data = test_data_ret, test_env = env_sac_ret_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUpTLLfLCfbF"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(sac_test_returns_ret)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = sac_test_returns_ret['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(sac_test_returns_ret[\"date\"][1:], portfolio_values, label=\"SAC RET Portfolio\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on SAC Algorithm with Lagged Returns as the state  - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_sac_ret\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_sac_ret = capital\n",
        "total_return_test_sac_ret = final_value_test_sac_ret - initial_capital\n",
        "sharpe_ratio_test_sac_ret = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_sac_ret = (final_value_test_sac_ret / initial_capital) ** (1 / (len(sac_test_returns_ret) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_sac_ret = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_sac_ret:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_sac_ret:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_sac_ret * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_sac_ret:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_sac_ret:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv48YLFgCfbF"
      },
      "source": [
        "## **O. TD3 RL Model with Lagged Returns as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvGgjdPyCfbF"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_td3_ret = agent.get_model(\"td3\", model_kwargs = TD3_PARAMS_RET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ6sSOz4CfbG"
      },
      "outputs": [],
      "source": [
        "trained_td3_ret = agent.train_model(model=model_td3_ret, tb_log_name='td3', total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['td3_ret'] = trained_td3_ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma53SivYCfbG"
      },
      "outputs": [],
      "source": [
        "# td3 Train Model num_stock = df_pct_change.shape[1]\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ret, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "td3_train_returns_ret, _ = DRLAgent.DRL_prediction(model=trained_td3_ret, test_data = train_data_ret, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QemZcgevCfbG"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(td3_train_returns_ret)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = td3_train_returns_ret['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"TD3 RET Portfolio\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on TD3 Algorithm with Lagged Returns as the state  - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_td3_ret\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_td3_ret = capital\n",
        "total_return_trg_td3_ret = final_value_trg_td3_ret - initial_capital\n",
        "sharpe_ratio_trg_td3_ret = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_td3_ret = (final_value_trg_td3_ret / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_td3_ret = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_td3_ret:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_td3_ret:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_td3_ret * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_td3_ret:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_td3_ret:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZMuTrhfCfbG"
      },
      "outputs": [],
      "source": [
        "# TD3 Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ret, **env_kwargs)\n",
        "env_td3_ret_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['td3_ret_test'] = copy.copy(env_td3_ret_test)\n",
        "DynaCAAST_Obs['td3_ret_test'] = obs_trade.copy()\n",
        "td3_test_returns_ret, _ = DRLAgent.DRL_prediction(model=trained_td3_ret, test_data = test_data_ret, test_env = env_td3_ret_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8cXCfCZCfbH"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(td3_test_returns_ret)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = td3_test_returns_ret['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(td3_test_returns_ret[\"date\"][1:], portfolio_values, label=\"TD3 RET Portfolio\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on TD3 Algorithm with Lagged Returns as the state  - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_td3_ret\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_td3_ret = capital\n",
        "total_return_test_td3_ret = final_value_test_td3_ret - initial_capital\n",
        "sharpe_ratio_test_td3_ret = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_td3_ret = (final_value_test_td3_ret / initial_capital) ** (1 / (len(td3_test_returns_ret) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_td3_ret = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_td3_ret:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_td3_ret:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_td3_ret * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_td3_ret:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_td3_ret:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aBSGpV3CfbH"
      },
      "source": [
        "## **P. Performance Analysis of RL agents using Lagged Returns as their states**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOpgqDFkCfbH"
      },
      "outputs": [],
      "source": [
        "returns_train = prices_train_data.pct_change() # get the assets daily returns\n",
        "returns_test = prices_test_data.pct_change()\n",
        "\n",
        "\n",
        "a2c_train_cum_returns_ret = (1 + a2c_train_returns_ret.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "a2c_train_cum_returns_ret = a2c_train_cum_returns_ret['daily_return']\n",
        "a2c_train_cum_returns_ret.name = 'A2C RET Model'\n",
        "\n",
        "ppo_train_cum_returns_ret = (1 + ppo_train_returns_ret.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "ppo_train_cum_returns_ret = ppo_train_cum_returns_ret['daily_return']\n",
        "ppo_train_cum_returns_ret.name = 'PPO RET Model'\n",
        "\n",
        "ddpg_train_cum_returns_ret = (1 + ddpg_train_returns_ret.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "ddpg_train_cum_returns_ret = ddpg_train_cum_returns_ret['daily_return']\n",
        "ddpg_train_cum_returns_ret.name = 'DDPG RET Model'\n",
        "\n",
        "sac_train_cum_returns_ret = (1 + sac_train_returns_ret.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "sac_train_cum_returns_ret = sac_train_cum_returns_ret['daily_return']\n",
        "sac_train_cum_returns_ret.name = 'SAC RET Model'\n",
        "\n",
        "td3_train_cum_returns_ret = (1 + td3_train_returns_ret.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "td3_train_cum_returns_ret = td3_train_cum_returns_ret['daily_return']\n",
        "td3_train_cum_returns_ret.name = 'TD3 RET Model'\n",
        "\n",
        "date_list = list(ddpg_train_cum_returns_ret.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FnVWsVmCfbH"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Plot the culmulative returns of the portfolios\n",
        "fig, ax = plt.subplots(figsize=(21,9))\n",
        "a2c_train_cum_returns_ret.plot(ax=ax, color='blue', alpha=0.4)\n",
        "ppo_train_cum_returns_ret.plot(ax=ax, color='green', alpha=0.4)\n",
        "ddpg_train_cum_returns_ret.plot(ax=ax, color='skyblue', alpha=0.4)\n",
        "sac_train_cum_returns_ret.plot(ax=ax, color='red', alpha=0.4)\n",
        "td3_train_cum_returns_ret.plot(ax=ax, color='black', alpha=0.4)\n",
        "\n",
        "plt.legend(loc=\"best\");\n",
        "plt.grid(True);\n",
        "ax.set_ylabel(\"Cumulative return\");\n",
        "ax.set_title(\"Performance on the training data with the Return lags as the State\", fontsize=14);\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaaJU6DxCfbH"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# get the culmulative returns for each portfolio\n",
        "\n",
        "a2c_test_cum_returns_ret = (1 + a2c_test_returns_ret['daily_return']).cumprod()\n",
        "a2c_test_cum_returns_ret.name = 'A2C RET Model'\n",
        "a2c_test_cum_returns_ret.index = a2c_test_returns_ret['date']\n",
        "\n",
        "ppo_test_cum_returns_ret = (1 + ppo_test_returns_ret['daily_return']).cumprod()\n",
        "ppo_test_cum_returns_ret.name = 'PPO RET Model'\n",
        "ppo_test_cum_returns_ret.index = ppo_test_returns_ret['date']\n",
        "\n",
        "ddpg_test_cum_returns_ret = (1 + ddpg_test_returns_ret['daily_return']).cumprod()\n",
        "ddpg_test_cum_returns_ret.name = 'DDPG RET Model'\n",
        "ddpg_test_cum_returns_ret.index = ddpg_test_returns_ret['date']\n",
        "\n",
        "sac_test_cum_returns_ret = (1 + sac_test_returns_ret['daily_return']).cumprod()\n",
        "sac_test_cum_returns_ret.name = 'SAC RET Model'\n",
        "sac_test_cum_returns_ret.index = sac_test_returns_ret['date']\n",
        "\n",
        "td3_test_cum_returns_ret = (1 + td3_test_returns_ret['daily_return']).cumprod()\n",
        "td3_test_cum_returns_ret.name = 'TD3 RET Model'\n",
        "td3_test_cum_returns_ret.index = td3_test_returns_ret['date']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5hEjANbCfbJ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "# Plot the culmulative returns of the portfolios\n",
        "fig, ax = plt.subplots(figsize=(21,9))\n",
        "a2c_test_cum_returns_ret.plot(ax=ax, color='blue', alpha=.4)\n",
        "ppo_test_cum_returns_ret.plot(ax=ax, color='green', alpha=.4)\n",
        "ddpg_test_cum_returns_ret.plot(ax=ax, color='skyblue', alpha=.4)\n",
        "sac_test_cum_returns_ret.plot(ax=ax, color='red', alpha=0.4)\n",
        "td3_test_cum_returns_ret.plot(ax=ax, color='black', alpha=0.4)\n",
        "\n",
        "plt.legend(loc=\"best\");\n",
        "plt.grid(True);\n",
        "ax.set_ylabel(\"Cumulative return\");\n",
        "ax.set_title(\"Performance on the testing data with the Return lags as the State\", fontsize=14);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF_FmJaZChum"
      },
      "source": [
        "## **Q. A2C RL Model with LSTM predictions as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifuEZeCOChun"
      },
      "outputs": [],
      "source": [
        "stock_dimension = len(tickers)\n",
        "state_space = stock_dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ihVG3MfChun"
      },
      "outputs": [],
      "source": [
        "env_kwargs = { \"hmax\": 500, \"initial_amount\": 1000000, \"transaction_cost_pct\": transaction_cost, \"state_space\": state_space,  \"stock_dim\": stock_dimension,  \"tech_indicator_list\": lstm_fcst,\n",
        "    \"action_space\": stock_dimension,  \"reward_scaling\": 0, 'initial_weights': [1/stock_dimension]*stock_dimension}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ByXgLZkChun"
      },
      "outputs": [],
      "source": [
        "e_train_gym = StockPortfolioEnv(df = train_data_lstm, **env_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTYGf1cKChun"
      },
      "outputs": [],
      "source": [
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edxvq__KChuo"
      },
      "outputs": [],
      "source": [
        "# initialize\n",
        "agent = DRLAgent(env = env_train)\n",
        "model_a2c_lstm = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS_LSTM)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1dSl-VNChuo"
      },
      "outputs": [],
      "source": [
        "trained_a2c_lstm = agent.train_model(model=model_a2c_lstm, tb_log_name='a2c', total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['a2c_lstm'] = trained_a2c_lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAv4EtcWChuo"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "# A2C Train Model\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_lstm, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "a2c_train_returns_lstm, _ = DRLAgent.DRL_prediction(model=trained_a2c_lstm, test_data = train_data_lstm, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDCVKn55Chuo"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(a2c_train_returns_lstm)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = a2c_train_returns_lstm['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"A2C with LSTM as the State Portfolio\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on A2C Algorithm  with LSTM as the State - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_a2c_lstm\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_a2c_lstm = capital\n",
        "total_return_trg_a2c_lstm = final_value_trg_a2c_lstm - initial_capital\n",
        "sharpe_ratio_trg_a2c_lstm = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_a2c_lstm = (final_value_trg_a2c_lstm / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_a2c_lstm = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_a2c_lstm:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_a2c_lstm:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_a2c_lstm * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_a2c_lstm:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_a2c_lstm:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbFvw1SrChuo"
      },
      "outputs": [],
      "source": [
        "# A2C Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_lstm, **env_kwargs)\n",
        "env_a2c_lstm_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['a2c_lstm_test'] = copy.copy(env_a2c_lstm_test)\n",
        "DynaCAAST_Obs['a2c_lstm_test'] = obs_trade.copy()\n",
        "a2c_test_returns_lstm, _ = DRLAgent.DRL_prediction(model=trained_a2c_lstm, test_data = test_data_lstm, test_env = env_a2c_lstm_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFVbPl-cChuo"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(a2c_test_returns_lstm)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = a2c_test_returns_lstm['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(a2c_test_returns_lstm[\"date\"][1:], portfolio_values, label=\"A2C Portfolio  with LSTM as the State\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on A2C Algorithm  with LSTM as the State - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_a2c_lstm\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_a2c_lstm = capital\n",
        "total_return_test_a2c_lstm = final_value_test_a2c_lstm - initial_capital\n",
        "sharpe_ratio_test_a2c_lstm = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_a2c_lstm = (final_value_test_a2c_lstm / initial_capital) ** (1 / (len(returns_test_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_a2c_lstm = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_a2c_lstm:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_a2c_lstm:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_a2c_lstm * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio : {sharpe_ratio_test_a2c_lstm:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_a2c_lstm:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNRKrPJTChup"
      },
      "source": [
        "## **R. PPO RL Model with LSTM predictions as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tT_JwJMxChup"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "model_ppo_lstm = agent.get_model(\"ppo\", model_kwargs = PPO_PARAMS_LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyDlhmJ-Chup"
      },
      "outputs": [],
      "source": [
        "trained_ppo_lstm = agent.train_model(model=model_ppo_lstm, tb_log_name='ppo', total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['ppo_lstm'] = trained_ppo_lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VB63jE5jChup"
      },
      "outputs": [],
      "source": [
        "# PPO Train Model\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_lstm, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "ppo_train_returns_lstm, _ = DRLAgent.DRL_prediction(model=trained_ppo_lstm, test_data = train_data_lstm, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkZ_PAsSChup"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(ppo_train_returns_lstm)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = ppo_train_returns_lstm['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"PPO Portfolio with LSTM as the State \", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on PPO Algorithm  with LSTM as the State - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_ppo_lstm\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_ppo_lstm = capital\n",
        "total_return_trg_ppo_lstm = final_value_trg_ppo_lstm - initial_capital\n",
        "sharpe_ratio_trg_ppo_lstm = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_ppo_lstm = (final_value_trg_ppo_lstm / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_ppo_lstm = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_ppo_lstm:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_ppo_lstm:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_ppo_lstm * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_ppo_lstm:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_ppo_lstm:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaFg7B8pChuq"
      },
      "outputs": [],
      "source": [
        "# PPO Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_lstm, **env_kwargs)\n",
        "env_ppo_lstm_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ppo_lstm_test'] = copy.copy(env_ppo_lstm_test)\n",
        "DynaCAAST_Obs['ppo_lstm_test'] = obs_trade.copy()\n",
        "ppo_test_returns_lstm, _ = DRLAgent.DRL_prediction(model=trained_ppo_lstm, test_data = test_data_lstm, test_env = env_ppo_lstm_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6Rt7Sm-Chuq"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(ppo_test_returns_lstm)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = ppo_test_returns_lstm['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(ppo_test_returns_lstm[\"date\"][1:], portfolio_values, label=\"PPO Portfolio with LSTM as the State\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on PPO Algorithm with LSTM as the State  - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_ppo_lstm\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_ppo_lstm = capital\n",
        "total_return_test_ppo_lstm = final_value_test_ppo_lstm - initial_capital\n",
        "sharpe_ratio_test_ppo_lstm = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_ppo_lstm = (final_value_test_ppo_lstm / initial_capital) ** (1 / (len(ppo_test_returns_lstm) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_ppo_lstm = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_ppo_lstm:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_ppo_lstm:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_ppo_lstm * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_ppo_lstm:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_ppo_lstm:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkF9jljDChuq"
      },
      "source": [
        "## **S. DDPG RL Model with LSTM predictions as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0SM_wKrChuq"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_ddpg_lstm = agent.get_model(\"ddpg\", model_kwargs = DDPG_PARAMS_LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLlRwA6kChuq"
      },
      "outputs": [],
      "source": [
        "trained_ddpg_lstm = agent.train_model(model= model_ddpg_lstm, tb_log_name='ddpg',  total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['ddpg_lstm'] = trained_ddpg_lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQf6I3lMChuq"
      },
      "outputs": [],
      "source": [
        "# DDPG Train Model num_stock = df_pct_change.shape[1]\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_lstm, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "ddpg_train_returns_lstm, _ = DRLAgent.DRL_prediction(model=trained_ddpg_lstm, test_data = train_data_lstm, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UonddUbDChuq"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(ddpg_train_returns_lstm)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = ddpg_train_returns_lstm['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"DDPG Portfolio with LSTM as the State \", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on DDPG Algorithm with LSTM as the State - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_ddpg_lstm\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_ddpg_lstm = capital\n",
        "total_return_trg_ddpg_lstm = final_value_trg_ddpg_lstm - initial_capital\n",
        "sharpe_ratio_trg_ddpg_lstm = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_ddpg_lstm = (final_value_trg_ddpg_lstm / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_ddpg_lstm = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_ddpg_lstm:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_ddpg_lstm:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_ddpg_lstm * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_ddpg_lstm:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_ddpg_lstm:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahBJK0ibChur"
      },
      "outputs": [],
      "source": [
        "# DDPG Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_lstm, **env_kwargs)\n",
        "env_ddpg_lstm_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ddpg_lstm_test'] = copy.copy(env_ddpg_lstm_test)\n",
        "DynaCAAST_Obs['ddpg_lstm_test'] = obs_trade.copy()\n",
        "ddpg_test_returns_lstm, _ = DRLAgent.DRL_prediction(model=trained_ddpg_lstm, test_data = test_data_lstm, test_env = env_ddpg_lstm_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiX9OYE4Chur"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(ddpg_test_returns_lstm)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = ddpg_test_returns_lstm['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(ddpg_test_returns_lstm[\"date\"][1:], portfolio_values, label=\"DDPG Portfolio with LSTM as State\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on DDPG Algorithm with LSTM as State - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_ddpg_lstm\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_ddpg_lstm = capital\n",
        "total_return_test_ddpg_lstm = final_value_test_ddpg_lstm - initial_capital\n",
        "sharpe_ratio_test_ddpg_lstm = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_ddpg_lstm = (final_value_test_ddpg_lstm / initial_capital) ** (1 / (len(ddpg_test_returns_lstm) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_ddpg_lstm = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_ddpg_lstm:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_ddpg_lstm:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_ddpg_lstm * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_ddpg_lstm:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_ddpg_lstm:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtB6pW7AChur"
      },
      "source": [
        "## **T. SAC RL Model with LSTM predictions as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whchEAIHChur"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_sac_lstm = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS_LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvOB6Oh7Chur"
      },
      "outputs": [],
      "source": [
        "trained_sac_lstm = agent.train_model(model=model_sac_lstm, tb_log_name='sac', total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['sac_lstm'] = trained_sac_lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNYrct8-Chur"
      },
      "outputs": [],
      "source": [
        "#  SAC Train Model num_stock = df_pct_change.shape[1]\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_lstm, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "sac_train_returns_lstm, _ = DRLAgent.DRL_prediction(model=trained_sac_lstm, test_data = train_data_lstm, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wl6svvzQChus"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(sac_train_returns_lstm)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = sac_train_returns_lstm['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"SAC Portfolio with LSTM as State\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on SAC Algorithm with LSTM as State - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_sac_lstm\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_sac_lstm = capital\n",
        "total_return_trg_sac_lstm = final_value_trg_sac_lstm - initial_capital\n",
        "sharpe_ratio_trg_sac_lstm = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_sac_lstm = (final_value_trg_sac_lstm / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_sac_lstm = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_sac_lstm:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_sac_lstm:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_sac_lstm * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio Kelly: {sharpe_ratio_trg_sac_lstm:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_sac_lstm:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXZylVYnChus"
      },
      "outputs": [],
      "source": [
        "# SAC Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_lstm, **env_kwargs)\n",
        "env_sac_lstm_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['sac_lstm_test'] = copy.copy(env_sac_lstm_test)\n",
        "DynaCAAST_Obs['sac_lstm_test'] = obs_trade.copy()\n",
        "sac_test_returns_lstm, _ = DRLAgent.DRL_prediction(model=trained_sac_lstm, test_data = test_data_lstm, test_env = env_sac_lstm_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kJfkw07Chus"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(sac_test_returns_lstm)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = sac_test_returns_lstm['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(sac_test_returns_lstm[\"date\"][1:], portfolio_values, label=\"SAC Portfolio with LSTM as State\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on SAC Algorithm with LSTM as State - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_sac_lstm\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_sac_lstm = capital\n",
        "total_return_test_sac_lstm = final_value_test_sac_lstm - initial_capital\n",
        "sharpe_ratio_test_sac_lstm = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_sac_lstm = (final_value_test_sac_lstm / initial_capital) ** (1 / (len(sac_test_returns_lstm) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_sac_lstm = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_sac_lstm:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_sac_lstm:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_sac_lstm * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_sac_lstm:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_sac_lstm:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlibehAUChus"
      },
      "source": [
        "## **U. TD3 RL Model with LSTM predictions as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBO0mq-XChut"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_td3_lstm = agent.get_model(\"td3\", model_kwargs = TD3_PARAMS_LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZOzbi2qChut"
      },
      "outputs": [],
      "source": [
        "trained_td3_lstm = agent.train_model(model=model_td3_lstm, tb_log_name='td3', total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['td3_lstm'] = trained_td3_lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQ9zv55bChut"
      },
      "outputs": [],
      "source": [
        "# td3 Train Model num_stock = df_pct_change.shape[1]\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_lstm, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "td3_train_returns_lstm, _ = DRLAgent.DRL_prediction(model=trained_td3_lstm, test_data = train_data_lstm, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEHUdYPYChut"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(td3_train_returns_lstm)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = td3_train_returns_lstm['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"TD3 Portfolio with LSTM as State\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on TD3 Algorithm with LSTM as State - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_td3_lstm\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_td3_lstm = capital\n",
        "total_return_trg_td3_lstm = final_value_trg_td3_lstm - initial_capital\n",
        "sharpe_ratio_trg_td3_lstm = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_td3_lstm = (final_value_trg_td3_lstm / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_td3_lstm = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_td3_lstm:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_td3_lstm:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_td3_lstm * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_td3_lstm:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_td3_lstm:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9QKK6CBChut"
      },
      "outputs": [],
      "source": [
        "# TD3 Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_lstm, **env_kwargs)\n",
        "env_td3_lstm_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['td3_lstm_test'] = copy.copy(env_td3_lstm_test)\n",
        "DynaCAAST_Obs['td3_lstm_test'] = obs_trade.copy()\n",
        "td3_test_returns_lstm, _ = DRLAgent.DRL_prediction(model=trained_td3_lstm, test_data = test_data_lstm, test_env = env_td3_lstm_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvJgoTDWChut"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(td3_test_returns_lstm)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = td3_test_returns_lstm['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(td3_test_returns_lstm[\"date\"][1:], portfolio_values, label=\"TD3 Portfolio with LSTM as State\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on TD3 Algorithm with LSTM as State - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_td3_lstm\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_td3_lstm = capital\n",
        "total_return_test_td3_lstm = final_value_test_td3_lstm - initial_capital\n",
        "sharpe_ratio_test_td3_lstm = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_td3_lstm = (final_value_test_td3_lstm / initial_capital) ** (1 / (len(td3_test_returns_lstm) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_td3_lstm = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_td3_lstm:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_td3_lstm:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_td3_lstm * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_td3_lstm:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_td3_lstm:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hhlm7WGmChuu"
      },
      "source": [
        "## **V. Performance Analysis of RL agents using LSTM predictions as their states**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NN25wbP1Chuu"
      },
      "outputs": [],
      "source": [
        "returns_train = prices_train_data.pct_change() # get the assets daily returns\n",
        "returns_test = prices_test_data.pct_change()\n",
        "\n",
        "\n",
        "a2c_train_cum_returns_lstm = (1 + a2c_train_returns_lstm.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "a2c_train_cum_returns_lstm = a2c_train_cum_returns_lstm['daily_return']\n",
        "a2c_train_cum_returns_lstm.name = 'A2C LSTM Model'\n",
        "\n",
        "ppo_train_cum_returns_lstm = (1 + ppo_train_returns_lstm.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "ppo_train_cum_returns_lstm = ppo_train_cum_returns_lstm['daily_return']\n",
        "ppo_train_cum_returns_lstm.name = 'PPO LSTM Model'\n",
        "\n",
        "ddpg_train_cum_returns_lstm = (1 + ddpg_train_returns_lstm.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "ddpg_train_cum_returns_lstm = ddpg_train_cum_returns_lstm['daily_return']\n",
        "ddpg_train_cum_returns_lstm.name = 'DDPG LSTM Model'\n",
        "\n",
        "sac_train_cum_returns_lstm = (1 + sac_train_returns_lstm.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "sac_train_cum_returns_lstm = sac_train_cum_returns_lstm['daily_return']\n",
        "sac_train_cum_returns_lstm.name = 'SAC LSTM Model'\n",
        "\n",
        "td3_train_cum_returns_lstm = (1 + td3_train_returns_lstm.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "td3_train_cum_returns_lstm = td3_train_cum_returns_lstm['daily_return']\n",
        "td3_train_cum_returns_lstm.name = 'TD3 LSTM Model'\n",
        "\n",
        "date_list = list(ddpg_train_cum_returns_lstm.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ3wgYlCChuu"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Plot the culmulative returns of the portfolios\n",
        "fig, ax = plt.subplots(figsize=(21,9))\n",
        "a2c_train_cum_returns_lstm.plot(ax=ax, color='blue', alpha=0.4)\n",
        "ppo_train_cum_returns_lstm.plot(ax=ax, color='green', alpha=0.4)\n",
        "ddpg_train_cum_returns_lstm.plot(ax=ax, color='skyblue', alpha=0.4)\n",
        "sac_train_cum_returns_lstm.plot(ax=ax, color='red', alpha=0.4)\n",
        "td3_train_cum_returns_lstm.plot(ax=ax, color='black', alpha=0.4)\n",
        "\n",
        "plt.legend(loc=\"best\");\n",
        "plt.grid(True);\n",
        "ax.set_ylabel(\"Cumulative return\");\n",
        "ax.set_title(\"Performance on the training data with LSTM forecast as the State\", fontsize=14);\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpDtIWvaChuu"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# get the culmulative returns for each portfolio\n",
        "\n",
        "a2c_test_cum_returns_lstm = (1 + a2c_test_returns_lstm['daily_return']).cumprod()\n",
        "a2c_test_cum_returns_lstm.name = 'A2C LSTM Model'\n",
        "a2c_test_cum_returns_lstm.index = a2c_test_returns_lstm['date']\n",
        "\n",
        "ppo_test_cum_returns_lstm = (1 + ppo_test_returns_lstm['daily_return']).cumprod()\n",
        "ppo_test_cum_returns_lstm.name = 'PPO LSTM Model'\n",
        "ppo_test_cum_returns_lstm.index = ppo_test_returns_lstm['date']\n",
        "\n",
        "ddpg_test_cum_returns_lstm = (1 + ddpg_test_returns_lstm['daily_return']).cumprod()\n",
        "ddpg_test_cum_returns_lstm.name = 'DDPG LSTM Model'\n",
        "ddpg_test_cum_returns_lstm.index = ddpg_test_returns_lstm['date']\n",
        "\n",
        "sac_test_cum_returns_lstm = (1 + sac_test_returns_lstm['daily_return']).cumprod()\n",
        "sac_test_cum_returns_lstm.name = 'SAC LSTM Model'\n",
        "sac_test_cum_returns_lstm.index = sac_test_returns_lstm['date']\n",
        "\n",
        "td3_test_cum_returns_lstm = (1 + td3_test_returns_lstm['daily_return']).cumprod()\n",
        "td3_test_cum_returns_lstm.name = 'TD3 LSTM Model'\n",
        "td3_test_cum_returns_lstm.index = td3_test_returns_lstm['date']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5hQ_hvFChuv"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "# Plot the culmulative returns of the portfolios\n",
        "fig, ax = plt.subplots(figsize=(21,9))\n",
        "a2c_test_cum_returns_lstm.plot(ax=ax, color='blue', alpha=.4)\n",
        "ppo_test_cum_returns_lstm.plot(ax=ax, color='green', alpha=.4)\n",
        "ddpg_test_cum_returns_lstm.plot(ax=ax, color='skyblue', alpha=.4)\n",
        "sac_test_cum_returns_lstm.plot(ax=ax, color='red', alpha=0.4)\n",
        "td3_test_cum_returns_lstm.plot(ax=ax, color='black', alpha=0.4)\n",
        "\n",
        "plt.legend(loc=\"best\");\n",
        "plt.grid(True);\n",
        "ax.set_ylabel(\"Cumulative return\");\n",
        "ax.set_title(\"Performance on the testing data with LSTM forecast as the State\", fontsize=14);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m7_0OlxK3_H"
      },
      "source": [
        "<hr style='border:2px solid black'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l2d6SMX6zBX"
      },
      "source": [
        "## **W. A2C RL Model with Transformer Model predictions as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbd98dRg6zBY"
      },
      "outputs": [],
      "source": [
        "stock_dimension = len(tickers)\n",
        "state_space = stock_dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DIjv6ie6zBZ"
      },
      "outputs": [],
      "source": [
        "env_kwargs = { \"hmax\": 500, \"initial_amount\": 1000000, \"transaction_cost_pct\": transaction_cost, \"state_space\": state_space,  \"stock_dim\": stock_dimension,  \"tech_indicator_list\": transformer_fcst,\n",
        "    \"action_space\": stock_dimension,  \"reward_scaling\": 0, 'initial_weights': [1/stock_dimension]*stock_dimension}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xCH31pd6zBZ"
      },
      "outputs": [],
      "source": [
        "e_train_gym = StockPortfolioEnv(df = train_data_transformer, **env_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smrThM1o6zBZ"
      },
      "outputs": [],
      "source": [
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHGEH71K6zBZ"
      },
      "outputs": [],
      "source": [
        "# initialize\n",
        "agent = DRLAgent(env = env_train)\n",
        "model_a2c_transformer = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS_TRANSFORMER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrJnaMCA6zBZ"
      },
      "outputs": [],
      "source": [
        "trained_a2c_transformer = agent.train_model(model=model_a2c_transformer, tb_log_name='a2c', total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['a2c_transformer'] = trained_a2c_transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aj0Tiz_N6zBa"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "# A2C Train Model\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_transformer, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "a2c_train_returns_transformer, _ = DRLAgent.DRL_prediction(model=trained_a2c_transformer, test_data = train_data_transformer, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3cGJf2g6zBa"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(a2c_train_returns_transformer)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = a2c_train_returns_transformer['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"A2C with Transformer Model as the State Portfolio\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on A2C Algorithm  with transformer forecast as the State - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_a2c_transformer\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_a2c_transformer = capital\n",
        "total_return_trg_a2c_transformer = final_value_trg_a2c_transformer - initial_capital\n",
        "sharpe_ratio_trg_a2c_transformer = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_a2c_transformer = (final_value_trg_a2c_transformer / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_a2c_transformer = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_a2c_transformer:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_a2c_transformer:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_a2c_transformer * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_a2c_transformer:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_a2c_transformer:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAp0DKJe6zBa"
      },
      "outputs": [],
      "source": [
        "# A2C Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_transformer, **env_kwargs)\n",
        "env_a2c_transformer_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['a2c_transformer_test'] = copy.copy(env_a2c_transformer_test)\n",
        "DynaCAAST_Obs['a2c_transformer_test'] = obs_trade.copy()\n",
        "a2c_test_returns_transformer, _ = DRLAgent.DRL_prediction(model=trained_a2c_transformer, test_data = test_data_transformer, test_env = env_a2c_transformer_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ymLhy-z6zBa"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(a2c_test_returns_transformer)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = a2c_test_returns_transformer['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(a2c_test_returns_transformer[\"date\"][1:], portfolio_values, label=\"A2C Portfolio  with Transformer Forecast as the State\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on A2C Algorithm  with Transformer Forecast as the State - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_a2c_transformer\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_a2c_transformer = capital\n",
        "total_return_test_a2c_transformer = final_value_test_a2c_transformer - initial_capital\n",
        "sharpe_ratio_test_a2c_transformer = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_a2c_transformer = (final_value_test_a2c_transformer / initial_capital) ** (1 / (len(returns_test_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_a2c_transformer = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_a2c_transformer:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_a2c_transformer:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_a2c_transformer * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio : {sharpe_ratio_test_a2c_transformer:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_a2c_transformer:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMLieUEc6zBb"
      },
      "source": [
        "## **X. PPO RL Model with Transformer Model predictions as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQltLNbT6zBb"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "model_ppo_transformer = agent.get_model(\"ppo\", model_kwargs = PPO_PARAMS_TRANSFORMER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0Cx-w7q6zBb"
      },
      "outputs": [],
      "source": [
        "trained_ppo_transformer = agent.train_model(model=model_ppo_transformer, tb_log_name='ppo', total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['ppo_transformer'] = trained_ppo_transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTqV89E76zBb"
      },
      "outputs": [],
      "source": [
        "# PPO Train Model\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_transformer, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "ppo_train_returns_transformer, _ = DRLAgent.DRL_prediction(model=trained_ppo_transformer, test_data = train_data_transformer, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PO1r2vqX6zBc"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(ppo_train_returns_transformer)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = ppo_train_returns_transformer['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"PPO Portfolio with Transformer Model Forecast as the State \", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on PPO Algorithm  with Transformer Model Forecast as the State - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_ppo_transformer\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_ppo_transformer = capital\n",
        "total_return_trg_ppo_transformer = final_value_trg_ppo_transformer - initial_capital\n",
        "sharpe_ratio_trg_ppo_transformer = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_ppo_transformer = (final_value_trg_ppo_transformer / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_ppo_transformer = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_ppo_transformer:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_ppo_transformer:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_ppo_transformer * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_ppo_transformer:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_ppo_transformer:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvjAUL4n6zBc"
      },
      "outputs": [],
      "source": [
        "# PPO Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_transformer, **env_kwargs)\n",
        "env_ppo_transformer_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ppo_transformer_test'] = copy.copy(env_ppo_transformer_test)\n",
        "DynaCAAST_Obs['ppo_transformer_test'] = obs_trade.copy()\n",
        "ppo_test_returns_transformer, _ = DRLAgent.DRL_prediction(model=trained_ppo_transformer, test_data = test_data_transformer, test_env = env_ppo_transformer_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7GaAefw6zBc"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(ppo_test_returns_transformer)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = ppo_test_returns_transformer['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(ppo_test_returns_transformer[\"date\"][1:], portfolio_values, label=\"PPO Portfolio with Transformer Model Forecast as the State\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on PPO Algorithm with Transformer Model Forecast as the State  - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_ppo_transformer\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_ppo_transformer = capital\n",
        "total_return_test_ppo_transformer = final_value_test_ppo_transformer - initial_capital\n",
        "sharpe_ratio_test_ppo_transformer = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_ppo_transformer = (final_value_test_ppo_transformer / initial_capital) ** (1 / (len(ppo_test_returns_transformer) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_ppo_transformer = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_ppo_transformer:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_ppo_transformer:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_ppo_transformer * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_ppo_transformer:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_ppo_transformer:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh8PRue36zBc"
      },
      "source": [
        "## **Y. DDPG RL Model with Transformer Model predictions as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8bP9CAG6zBc"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_ddpg_transformer = agent.get_model(\"ddpg\", model_kwargs = DDPG_PARAMS_TRANSFORMER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4xElcUE6zBd"
      },
      "outputs": [],
      "source": [
        "trained_ddpg_transformer = agent.train_model(model= model_ddpg_transformer, tb_log_name='ddpg',  total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['ddpg_transformer'] = trained_ddpg_transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWF9aFo36zBd"
      },
      "outputs": [],
      "source": [
        "# DDPG Train Model num_stock = df_pct_change.shape[1]\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_transformer, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "ddpg_train_returns_transformer, _ = DRLAgent.DRL_prediction(model=trained_ddpg_transformer, test_data = train_data_transformer, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "188vgYoJ6zBd"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(ddpg_train_returns_transformer)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = ddpg_train_returns_transformer['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"DDPG Portfolio with Transformer Model Forecast as the State \", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on DDPG Algorithm with Transformer Model Forecast as the State - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_ddpg_transformer\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_ddpg_transformer = capital\n",
        "total_return_trg_ddpg_transformer = final_value_trg_ddpg_transformer - initial_capital\n",
        "sharpe_ratio_trg_ddpg_transformer = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_ddpg_transformer = (final_value_trg_ddpg_transformer / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_ddpg_transformer = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_ddpg_transformer:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_ddpg_transformer:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_ddpg_transformer * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_ddpg_transformer:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_ddpg_transformer:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7ftTJqo6zBd"
      },
      "outputs": [],
      "source": [
        "# DDPG Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_transformer, **env_kwargs)\n",
        "env_ddpg_transformer_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ddpg_transformer_test'] = copy.copy(env_ddpg_transformer_test)\n",
        "DynaCAAST_Obs['ddpg_transformer_test'] = obs_trade.copy()\n",
        "ddpg_test_returns_transformer, _ = DRLAgent.DRL_prediction(model=trained_ddpg_transformer, test_data = test_data_transformer, test_env = env_ddpg_transformer_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-E3hh7uW6zBd"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(ddpg_test_returns_transformer)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = ddpg_test_returns_transformer['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(ddpg_test_returns_transformer[\"date\"][1:], portfolio_values, label=\"DDPG Portfolio with Transformer Model Forecast as State\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on DDPG Algorithm with Transformer Model Forecast as State - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_ddpg_transformer\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_ddpg_transformer = capital\n",
        "total_return_test_ddpg_transformer = final_value_test_ddpg_transformer - initial_capital\n",
        "sharpe_ratio_test_ddpg_transformer = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_ddpg_transformer = (final_value_test_ddpg_transformer / initial_capital) ** (1 / (len(ddpg_test_returns_transformer) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_ddpg_transformer = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_ddpg_transformer:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_ddpg_transformer:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_ddpg_transformer * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_ddpg_transformer:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_ddpg_transformer:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mKA1gzg6zBe"
      },
      "source": [
        "## **Z. SAC RL Model with Transformer Model predictions as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyK8d2lP6zBe"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_sac_transformer = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS_TRANSFORMER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRkgVzRn6zBe"
      },
      "outputs": [],
      "source": [
        "trained_sac_transformer = agent.train_model(model=model_sac_transformer, tb_log_name='sac', total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['sac_transformer'] = trained_sac_transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwjkUsp_6zBe"
      },
      "outputs": [],
      "source": [
        "#  SAC Train Model num_stock = df_pct_change.shape[1]\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_transformer, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "sac_train_returns_transformer, _ = DRLAgent.DRL_prediction(model=trained_sac_transformer, test_data = train_data_transformer, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8YGlzpR6zBe"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(sac_train_returns_transformer)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = sac_train_returns_transformer['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"SAC Portfolio with Transformer Model Forecast as State\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on SAC Algorithm with Transformer Model Forecast as State - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_sac_transformer\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_sac_transformer = capital\n",
        "total_return_trg_sac_transformer = final_value_trg_sac_transformer - initial_capital\n",
        "sharpe_ratio_trg_sac_transformer = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_sac_transformer = (final_value_trg_sac_transformer / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_sac_transformer = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_sac_transformer:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_sac_transformer:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_sac_transformer * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio Kelly: {sharpe_ratio_trg_sac_transformer:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_sac_transformer:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hZtMq7f6zBe"
      },
      "outputs": [],
      "source": [
        "# SAC Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_transformer, **env_kwargs)\n",
        "env_sac_transformer_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['sac_transformer_test'] = copy.copy(env_sac_transformer_test)\n",
        "DynaCAAST_Obs['sac_transformer_test'] = obs_trade.copy()\n",
        "sac_test_returns_transformer, _ = DRLAgent.DRL_prediction(model=trained_sac_transformer, test_data = test_data_transformer, test_env = env_sac_transformer_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd_Cvajf6zBf"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(sac_test_returns_transformer)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = sac_test_returns_transformer['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(sac_test_returns_transformer[\"date\"][1:], portfolio_values, label=\"SAC Portfolio with Transformer Model Forecast as State\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on SAC Algorithm with Transformer Model Forecast as State - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_sac_transformer\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_sac_transformer = capital\n",
        "total_return_test_sac_transformer = final_value_test_sac_transformer - initial_capital\n",
        "sharpe_ratio_test_sac_transformer = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_sac_transformer = (final_value_test_sac_transformer / initial_capital) ** (1 / (len(sac_test_returns_transformer) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_sac_transformer = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_sac_transformer:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_sac_transformer:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_sac_transformer * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_sac_transformer:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_sac_transformer:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMvcbOcs6zBf"
      },
      "source": [
        "## **AA. TD3 RL Model with Transformer Model predictions as the state of the RL agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLnHzeKv6zBf"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_td3_transformer = agent.get_model(\"td3\", model_kwargs = TD3_PARAMS_TRANSFORMER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2wvNknm6zBf"
      },
      "outputs": [],
      "source": [
        "trained_td3_transformer = agent.train_model(model=model_td3_transformer, tb_log_name='td3', total_timesteps=total_timesteps_)\n",
        "DynaCAAST_Model['td3_transformer'] = trained_td3_transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWrbEcOR6zBf"
      },
      "outputs": [],
      "source": [
        "# td3 Train Model num_stock = df_pct_change.shape[1]\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_transformer, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "td3_train_returns_transformer, _ = DRLAgent.DRL_prediction(model=trained_td3_transformer, test_data = train_data_transformer, test_env = env_trade, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1mNFkS56zBf"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(td3_train_returns_transformer)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = td3_train_returns_transformer['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(returns_train_data.index[1:], portfolio_values, label=\"TD3 Portfolio with Transformer Model Forecast as State\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on TD3 Algorithm with Transformer Model Forecast as State - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_td3_transformer\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_trg_td3_transformer = capital\n",
        "total_return_trg_td3_transformer = final_value_trg_td3_transformer - initial_capital\n",
        "sharpe_ratio_trg_td3_transformer = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_trg_td3_transformer = (final_value_trg_td3_transformer / initial_capital) ** (1 / (len(returns_train_data) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_trg_td3_transformer = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_trg_td3_transformer:.2f}\")\n",
        "print(f\"Total Return: {total_return_trg_td3_transformer:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_trg_td3_transformer * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_trg_td3_transformer:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_trg_td3_transformer:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aG_xRXJA6zBf"
      },
      "outputs": [],
      "source": [
        "# TD3 Test Model\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_transformer, **env_kwargs)\n",
        "env_td3_transformer_test, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['td3_transformer_test'] = copy.copy(env_td3_transformer_test)\n",
        "DynaCAAST_Obs['td3_transformer_test'] = obs_trade.copy()\n",
        "td3_test_returns_transformer, _ = DRLAgent.DRL_prediction(model=trained_td3_transformer, test_data = test_data_transformer, test_env = env_td3_transformer_test, test_obs = obs_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BquBEKSA6zBg"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(td3_test_returns_transformer)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = td3_test_returns_transformer['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(td3_test_returns_transformer[\"date\"][1:], portfolio_values, label=\"TD3 Portfolio with Transformer Model Forecast as State\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on TD3 Algorithm with Transformer Model Forecast as State - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_td3_transformer\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_td3_transformer = capital\n",
        "total_return_test_td3_transformer = final_value_test_td3_transformer - initial_capital\n",
        "sharpe_ratio_test_td3_transformer = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_td3_transformer = (final_value_test_td3_transformer / initial_capital) ** (1 / (len(td3_test_returns_transformer) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_td3_transformer = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_td3_transformer:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_td3_transformer:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_td3_transformer * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_td3_transformer:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_td3_transformer:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVZ7rM5A6zBg"
      },
      "source": [
        "## **AB. Performance Analysis of RL agents using Transformer Model predictions as their states**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ul6KW8cT6zBg"
      },
      "outputs": [],
      "source": [
        "returns_train = prices_train_data.pct_change() # get the assets daily returns\n",
        "returns_test = prices_test_data.pct_change()\n",
        "\n",
        "\n",
        "a2c_train_cum_returns_transformer = (1 + a2c_train_returns_transformer.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "a2c_train_cum_returns_transformer = a2c_train_cum_returns_transformer['daily_return']\n",
        "a2c_train_cum_returns_transformer.name = 'A2C Transformer Model'\n",
        "\n",
        "ppo_train_cum_returns_transformer = (1 + ppo_train_returns_transformer.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "ppo_train_cum_returns_transformer = ppo_train_cum_returns_transformer['daily_return']\n",
        "ppo_train_cum_returns_transformer.name = 'PPO Transformer Model'\n",
        "\n",
        "ddpg_train_cum_returns_transformer = (1 + ddpg_train_returns_transformer.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "ddpg_train_cum_returns_transformer = ddpg_train_cum_returns_transformer['daily_return']\n",
        "ddpg_train_cum_returns_transformer.name = 'DDPG Transformer Model'\n",
        "\n",
        "sac_train_cum_returns_transformer = (1 + sac_train_returns_transformer.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "sac_train_cum_returns_transformer = sac_train_cum_returns_transformer['daily_return']\n",
        "sac_train_cum_returns_transformer.name = 'SAC Transformer Model'\n",
        "\n",
        "td3_train_cum_returns_transformer = (1 + td3_train_returns_transformer.copy().reset_index(drop=True).set_index(['date'])).cumprod()\n",
        "td3_train_cum_returns_transformer = td3_train_cum_returns_transformer['daily_return']\n",
        "td3_train_cum_returns_transformer.name = 'TD3 Transformer Model'\n",
        "\n",
        "date_list = list(ddpg_train_cum_returns_transformer.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1N-Ze20M6zBg"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Plot the culmulative returns of the portfolios\n",
        "fig, ax = plt.subplots(figsize=(21,9))\n",
        "a2c_train_cum_returns_transformer.plot(ax=ax, color='blue', alpha=0.4)\n",
        "ppo_train_cum_returns_transformer.plot(ax=ax, color='green', alpha=0.4)\n",
        "ddpg_train_cum_returns_transformer.plot(ax=ax, color='skyblue', alpha=0.4)\n",
        "sac_train_cum_returns_transformer.plot(ax=ax, color='red', alpha=0.4)\n",
        "td3_train_cum_returns_transformer.plot(ax=ax, color='black', alpha=0.4)\n",
        "\n",
        "plt.legend(loc=\"best\");\n",
        "plt.grid(True);\n",
        "ax.set_ylabel(\"Cumulative return\");\n",
        "ax.set_title(\"Performance on the training data with Transformer Model Forecast as the State\", fontsize=14);\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJl4P06E6zBg"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# get the culmulative returns for each portfolio\n",
        "\n",
        "a2c_test_cum_returns_transformer = (1 + a2c_test_returns_transformer['daily_return']).cumprod()\n",
        "a2c_test_cum_returns_transformer.name = 'A2C Transformer Model'\n",
        "a2c_test_cum_returns_transformer.index = a2c_test_returns_transformer['date']\n",
        "\n",
        "ppo_test_cum_returns_transformer = (1 + ppo_test_returns_transformer['daily_return']).cumprod()\n",
        "ppo_test_cum_returns_transformer.name = 'PPO Transformer Model'\n",
        "ppo_test_cum_returns_transformer.index = ppo_test_returns_transformer['date']\n",
        "\n",
        "ddpg_test_cum_returns_transformer = (1 + ddpg_test_returns_transformer['daily_return']).cumprod()\n",
        "ddpg_test_cum_returns_transformer.name = 'DDPG Transformer Model'\n",
        "ddpg_test_cum_returns_transformer.index = ddpg_test_returns_transformer['date']\n",
        "\n",
        "sac_test_cum_returns_transformer = (1 + sac_test_returns_transformer['daily_return']).cumprod()\n",
        "sac_test_cum_returns_transformer.name = 'SAC Transformer Model'\n",
        "sac_test_cum_returns_transformer.index = sac_test_returns_transformer['date']\n",
        "\n",
        "td3_test_cum_returns_transformer = (1 + td3_test_returns_transformer['daily_return']).cumprod()\n",
        "td3_test_cum_returns_transformer.name = 'TD3 Transformer Model'\n",
        "td3_test_cum_returns_transformer.index = td3_test_returns_transformer['date']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_efOBY4F6zBi"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "# Plot the culmulative returns of the portfolios\n",
        "fig, ax = plt.subplots(figsize=(21,9))\n",
        "a2c_test_cum_returns_transformer.plot(ax=ax, color='blue', alpha=.4)\n",
        "ppo_test_cum_returns_transformer.plot(ax=ax, color='green', alpha=.4)\n",
        "ddpg_test_cum_returns_transformer.plot(ax=ax, color='skyblue', alpha=.4)\n",
        "sac_test_cum_returns_transformer.plot(ax=ax, color='red', alpha=0.4)\n",
        "td3_test_cum_returns_transformer.plot(ax=ax, color='black', alpha=0.4)\n",
        "\n",
        "plt.legend(loc=\"best\");\n",
        "plt.grid(True);\n",
        "ax.set_ylabel(\"Cumulative return\");\n",
        "ax.set_title(\"Performance on the testing data with Transformer Model Forecast as the State\", fontsize=14);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr style='border:2px solid black'>"
      ],
      "metadata": {
        "id": "CC066PBEoWtk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-dhhRvs1pQr"
      },
      "source": [
        "## **Section 8: Performance Analysis of Traditional Approaches on testing dataset**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr style='border:2px solid black'>"
      ],
      "metadata": {
        "id": "fYfhf-LZoK91"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj4RhMnA3JNV"
      },
      "source": [
        "Below we perform an analysis of traditional algorithms to understand the causes of this performance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "returns_train = prices_train_data.pct_change() # get the assets daily returns\n",
        "returns_test = prices_test_data.pct_change()\n",
        "\n",
        "eq_test_cum_returns = (1 + Strategy_Returns_Data_test[\"return_eq\"].copy().reset_index(drop=True)).cumprod()\n",
        "eq_test_cum_returns.name = 'Equal Weight Approach'\n",
        "eq_test_cum_returns = eq_test_cum_returns.to_frame()\n",
        "eq_test_cum_returns.set_index( returns_test[0:-2].index, inplace=True)\n",
        "\n",
        "markow_test_cum_returns = (1 + Strategy_Returns_Data_test[\"return_markow\"].copy().reset_index(drop=True)).cumprod()\n",
        "markow_test_cum_returns.name = 'Markowitz Mean-Variance Approach'\n",
        "markow_test_cum_returns = markow_test_cum_returns.to_frame()\n",
        "markow_test_cum_returns.set_index( returns_test[0:-2].index, inplace=True)\n",
        "\n",
        "kelly_test_cum_returns = (1 + Strategy_Returns_Data_test[\"return_kelly\"].copy().reset_index(drop=True)).cumprod()\n",
        "kelly_test_cum_returns.name = 'Kelly Portfolio Criterion'\n",
        "kelly_test_cum_returns = kelly_test_cum_returns.to_frame()\n",
        "kelly_test_cum_returns.set_index( returns_test[0:-2].index, inplace=True)\n",
        "\n",
        "denoised_test_cum_returns = (1 + Strategy_Returns_Data_test[\"return_denoised\"].copy().reset_index(drop=True)).cumprod()\n",
        "denoised_test_cum_returns.name = 'Denoised Approach'\n",
        "denoised_test_cum_returns = denoised_test_cum_returns.to_frame()\n",
        "denoised_test_cum_returns.set_index( returns_test[0:-2].index, inplace=True)\n",
        "\n",
        "date_list = list(denoised_test_cum_returns.index)"
      ],
      "metadata": {
        "id": "Bp4515YTgIOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "# Plot the culmulative returns of the portfolios\n",
        "fig, ax = plt.subplots(figsize=(21,9))\n",
        "eq_test_cum_returns.plot(ax=ax, color='blue', alpha=.4)\n",
        "markow_test_cum_returns.plot(ax=ax, color='green', alpha=.4)\n",
        "kelly_test_cum_returns.plot(ax=ax, color='skyblue', alpha=.4)\n",
        "denoised_test_cum_returns.plot(ax=ax, color='red', alpha=0.4)\n",
        "\n",
        "plt.legend(loc=\"best\");\n",
        "plt.grid(True)\n",
        "ax.set_ylabel(\"Cumulative return\");\n",
        "ax.set_title(\"Performance of Traditional Approaches on the testing data\", fontsize=14);"
      ],
      "metadata": {
        "id": "hqFp7yF4gIfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr style='border:2px solid black'>"
      ],
      "metadata": {
        "id": "BLoAdWAgoY94"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDK57t7JChuv"
      },
      "source": [
        "## **Section 9: Performance Analysis of all traditional and RL agents**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr style='border:2px solid black'>"
      ],
      "metadata": {
        "id": "PtV-Ad6uoTjZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktyLtGWDF5L7"
      },
      "source": [
        "We analyse the performance of all trading agents - traditional and RL based in this section. We first evaluate against the training data (in the sample)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe6j57pSGDhY"
      },
      "outputs": [],
      "source": [
        "dict = {'Approach ' : [\"Markowitz\", \"Kelly\", \"Denoising\", \"Equal weighted\", \"\", \"A2C - TI\",\"PPO - TI\", \"DDPG - TI\", \"SAC - TI\", \"TD3 - TI\",\"\", \"A2C - RET\",\"PPO - RET \", \"DDPG - RET \", \"SAC - RET \", \"TD3 - RET \",\"\", \"A2C - LSTM \",\"PPO - LSTM \", \"DDPG - LSTM \", \"SAC - LSTM \", \"TD3 - LSTM \",\"\", \"A2C - Transformer \",\"PPO - Transformer \", \"DDPG - Transformer \", \"SAC - Transformer \", \"TD3 - Transformer \"  ],\n",
        "        'Initial Capital' : [np.round(100, 4), np.round(100, 4), np.round(100, 4),np.round(100, 4),\"\",  np.round(100, 4), np.round(100, 4), np.round(100, 4), np.round(100, 4),np.round(100, 4), \"\",  np.round(100, 4), np.round(100, 4), np.round(100, 4), np.round(100, 4),np.round(100, 4), \"\",  np.round(100, 4), np.round(100, 4), np.round(100, 4), np.round(100, 4),np.round(100, 4), \"\",  np.round(100, 4), np.round(100, 4), np.round(100, 4), np.round(100, 4),np.round(100, 4)],\n",
        "        'Total Gain' : [np.round(total_return_trg_markow, 4), np.round(total_return_trg_kelly, 4), np.round(total_return_trg_denoised, 4),np.round(total_return_trg_eq, 4),\"\",  np.round(total_return_trg_a2c_ti, 4), np.round(total_return_trg_ppo_ti, 4), np.round(total_return_trg_ddpg_ti, 4), np.round(total_return_trg_sac_ti, 4), np.round(total_return_trg_td3_ti, 4) ,\"\",  np.round(total_return_trg_a2c_ret, 4), np.round(total_return_trg_ppo_ret, 4), np.round(total_return_trg_ddpg_ret, 4), np.round(total_return_trg_sac_ret, 4),np.round(total_return_trg_td3_ret, 4) ,\"\",  np.round(total_return_trg_a2c_lstm, 4), np.round(total_return_trg_ppo_lstm, 4), np.round(total_return_trg_ddpg_lstm, 4), np.round(total_return_trg_sac_lstm, 4),np.round(total_return_trg_td3_lstm, 4),\"\",  np.round(total_return_trg_a2c_transformer, 4), np.round(total_return_trg_ppo_transformer, 4), np.round(total_return_trg_ddpg_transformer, 4), np.round(total_return_trg_sac_transformer, 4),np.round(total_return_trg_td3_transformer, 4)],\n",
        "        'Final Capital' : [np.round(final_value_trg_markow, 4), np.round(final_value_trg_kelly, 4), np.round(final_value_trg_denoised, 4),np.round(final_value_trg_eq, 4),\"\",  np.round(final_value_trg_a2c_ti, 4), np.round(final_value_trg_ppo_ti, 4), np.round(final_value_trg_ddpg_ti, 4), np.round(final_value_trg_sac_ti, 4),np.round(final_value_trg_td3_ti, 4) ,\"\",  np.round(final_value_trg_a2c_ret, 4), np.round(final_value_trg_ppo_ret, 4), np.round(final_value_trg_ddpg_ret, 4), np.round(final_value_trg_sac_ret, 4),np.round(final_value_trg_td3_ret, 4),\"\",  np.round(final_value_trg_a2c_lstm, 4), np.round(final_value_trg_ppo_lstm, 4), np.round(final_value_trg_ddpg_lstm, 4), np.round(final_value_trg_sac_lstm, 4),np.round(final_value_trg_td3_lstm, 4),\"\",  np.round(final_value_trg_a2c_transformer, 4), np.round(final_value_trg_ppo_transformer, 4), np.round(final_value_trg_ddpg_transformer, 4), np.round(final_value_trg_sac_transformer, 4),np.round(final_value_trg_td3_transformer, 4)],\n",
        "        'Annualized Return' : [np.round(annualized_return_trg_markow, 4), np.round(annualized_return_trg_kelly, 4), np.round(annualized_return_trg_denoised, 4),np.round(annualized_return_trg_eq, 4),\"\",  np.round(annualized_return_trg_a2c_ti, 4), np.round(annualized_return_trg_ppo_ti, 4), np.round(annualized_return_trg_ddpg_ti, 4), np.round(annualized_return_trg_sac_ti, 4),np.round(annualized_return_trg_td3_ti, 4) ,\"\",  np.round(annualized_return_trg_a2c_ret, 4), np.round(annualized_return_trg_ppo_ret, 4), np.round(annualized_return_trg_ddpg_ret, 4), np.round(annualized_return_trg_sac_ret, 4),np.round(annualized_return_trg_td3_ret, 4) ,\"\",  np.round(annualized_return_trg_a2c_lstm, 4), np.round(annualized_return_trg_ppo_lstm, 4), np.round(annualized_return_trg_ddpg_lstm, 4), np.round(annualized_return_trg_sac_lstm, 4),np.round(annualized_return_trg_td3_lstm, 4) ,\"\",  np.round(annualized_return_trg_a2c_transformer, 4), np.round(annualized_return_trg_ppo_transformer, 4), np.round(annualized_return_trg_ddpg_transformer, 4), np.round(annualized_return_trg_sac_transformer, 4),np.round(annualized_return_trg_td3_transformer, 4)],\n",
        "        'Sharpe Ratio (SR)' : [np.round(sharpe_ratio_trg_markow, 4), np.round(sharpe_ratio_trg_kelly, 4), np.round(sharpe_ratio_trg_denoised, 4), np.round(sharpe_ratio_trg_eq, 4),\"\",  np.round(sharpe_ratio_trg_a2c_ti, 4), np.round(sharpe_ratio_trg_ppo_ti, 4), np.round(sharpe_ratio_trg_ddpg_ti, 4), np.round(sharpe_ratio_trg_sac_ti, 4),np.round(sharpe_ratio_trg_td3_ti, 4) ,\"\",  np.round(sharpe_ratio_trg_a2c_ret, 4),np.round(sharpe_ratio_trg_ppo_ret, 4), np.round(sharpe_ratio_trg_ddpg_ret, 4), np.round(sharpe_ratio_trg_sac_ret, 4),np.round(sharpe_ratio_trg_td3_ret, 4) ,\"\",  np.round(sharpe_ratio_trg_a2c_lstm, 4),np.round(sharpe_ratio_trg_ppo_lstm, 4), np.round(sharpe_ratio_trg_ddpg_lstm, 4), np.round(sharpe_ratio_trg_sac_lstm, 4),np.round(sharpe_ratio_trg_td3_lstm, 4),\"\",  np.round(sharpe_ratio_trg_a2c_transformer, 4),np.round(sharpe_ratio_trg_ppo_transformer, 4), np.round(sharpe_ratio_trg_ddpg_transformer, 4), np.round(sharpe_ratio_trg_sac_transformer, 4),np.round(sharpe_ratio_trg_td3_transformer, 4)],\n",
        "        'Maximum Drawdown(%)' : [np.round(maxdraw_trg_markow, 4), np.round(maxdraw_trg_kelly, 4), np.round(maxdraw_trg_denoised, 4), np.round(maxdraw_trg_eq, 4),\"\",  np.round(maxdraw_trg_a2c_ti, 4),np.round(maxdraw_trg_ppo_ti, 4), np.round(maxdraw_trg_ddpg_ti, 4), np.round(maxdraw_trg_sac_ti, 4),np.round(maxdraw_trg_td3_ti, 4) ,\"\",  np.round(maxdraw_trg_a2c_ret, 4),np.round(maxdraw_trg_ppo_ret, 4), np.round(maxdraw_trg_ddpg_ret, 4), np.round(maxdraw_trg_sac_ret, 4),np.round(maxdraw_trg_td3_ret, 4) ,\"\",  np.round(maxdraw_trg_a2c_lstm, 4),np.round(maxdraw_trg_ppo_lstm, 4), np.round(maxdraw_trg_ddpg_lstm, 4), np.round(maxdraw_trg_sac_lstm, 4),np.round(maxdraw_trg_td3_lstm, 4),\"\",  np.round(maxdraw_trg_a2c_transformer, 4),np.round(maxdraw_trg_ppo_transformer, 4), np.round(maxdraw_trg_ddpg_transformer, 4), np.round(maxdraw_trg_sac_transformer, 4),np.round(maxdraw_trg_td3_transformer, 4)]}\n",
        "\n",
        "df = pd.DataFrame(dict, index = None)\n",
        "pdtabulate = lambda df: tabulate(df, headers='keys', tablefmt='heavy_grid', showindex=False)\n",
        "print(pdtabulate(df))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(df.to_html()))"
      ],
      "metadata": {
        "id": "vI8_Kmqsx9mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiW0iJHYvH6K"
      },
      "source": [
        "More critically, we also analyse the performance of all these algorithms against out-of-sample data (testing data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R71cfBGTvSqy"
      },
      "outputs": [],
      "source": [
        "dict = {'Approach ' : [\"Markowitz\", \"Kelly\", \"Denoising\", \"Equal weighted\", \"\", \"A2C - TI\",\"PPO - TI\", \"DDPG - TI\", \"SAC - TI\", \"TD3 - TI\",\"\", \"A2C - RET\",\"PPO - RET \", \"DDPG - RET \", \"SAC - RET \", \"TD3 - RET \",\"\", \"A2C - LSTM \",\"PPO - LSTM \", \"DDPG - LSTM \", \"SAC - LSTM \", \"TD3 - LSTM \",\"\", \"A2C - Transformer \",\"PPO - Transformer \", \"DDPG - Transformer \", \"SAC - Transformer \", \"TD3 - Transformer \"  ],\n",
        "        'Initial Capital' : [np.round(100, 4), np.round(100, 4), np.round(100, 4),np.round(100, 4),\"\",  np.round(100, 4), np.round(100, 4), np.round(100, 4), np.round(100, 4),np.round(100, 4), \"\",  np.round(100, 4), np.round(100, 4), np.round(100, 4), np.round(100, 4),np.round(100, 4), \"\",  np.round(100, 4), np.round(100, 4), np.round(100, 4), np.round(100, 4),np.round(100, 4), \"\",  np.round(100, 4), np.round(100, 4), np.round(100, 4), np.round(100, 4),np.round(100, 4)],\n",
        "        'Total Gain' : [np.round(total_return_test_markow, 4), np.round(total_return_test_kelly, 4), np.round(total_return_test_denoised, 4),np.round(total_return_test_eq, 4),\"\",  np.round(total_return_test_a2c_ti, 4), np.round(total_return_test_ppo_ti, 4), np.round(total_return_test_ddpg_ti, 4), np.round(total_return_test_sac_ti, 4), np.round(total_return_test_td3_ti, 4) ,\"\",  np.round(total_return_test_a2c_ret, 4), np.round(total_return_test_ppo_ret, 4), np.round(total_return_test_ddpg_ret, 4), np.round(total_return_test_sac_ret, 4),np.round(total_return_test_td3_ret, 4) ,\"\",  np.round(total_return_test_a2c_lstm, 4), np.round(total_return_test_ppo_lstm, 4), np.round(total_return_test_ddpg_lstm, 4), np.round(total_return_test_sac_lstm, 4),np.round(total_return_test_td3_lstm, 4),\"\",  np.round(total_return_test_a2c_transformer, 4), np.round(total_return_test_ppo_transformer, 4), np.round(total_return_test_ddpg_transformer, 4), np.round(total_return_test_sac_transformer, 4),np.round(total_return_test_td3_transformer, 4)],\n",
        "        'Final Capital' : [np.round(final_value_test_markow, 4), np.round(final_value_test_kelly, 4), np.round(final_value_test_denoised, 4),np.round(final_value_test_eq, 4),\"\",  np.round(final_value_test_a2c_ti, 4), np.round(final_value_test_ppo_ti, 4), np.round(final_value_test_ddpg_ti, 4), np.round(final_value_test_sac_ti, 4),np.round(final_value_test_td3_ti, 4) ,\"\",  np.round(final_value_test_a2c_ret, 4), np.round(final_value_test_ppo_ret, 4), np.round(final_value_test_ddpg_ret, 4), np.round(final_value_test_sac_ret, 4),np.round(final_value_test_td3_ret, 4),\"\",  np.round(final_value_test_a2c_lstm, 4), np.round(final_value_test_ppo_lstm, 4), np.round(final_value_test_ddpg_lstm, 4), np.round(final_value_test_sac_lstm, 4),np.round(final_value_test_td3_lstm, 4),\"\",  np.round(final_value_test_a2c_transformer, 4), np.round(final_value_test_ppo_transformer, 4), np.round(final_value_test_ddpg_transformer, 4), np.round(final_value_test_sac_transformer, 4),np.round(final_value_test_td3_transformer, 4)],\n",
        "        'Annualized Return' : [np.round(annualized_return_test_markow, 4), np.round(annualized_return_test_kelly, 4), np.round(annualized_return_test_denoised, 4),np.round(annualized_return_test_eq, 4),\"\",  np.round(annualized_return_test_a2c_ti, 4), np.round(annualized_return_test_ppo_ti, 4), np.round(annualized_return_test_ddpg_ti, 4), np.round(annualized_return_test_sac_ti, 4),np.round(annualized_return_test_td3_ti, 4) ,\"\",  np.round(annualized_return_test_a2c_ret, 4), np.round(annualized_return_test_ppo_ret, 4), np.round(annualized_return_test_ddpg_ret, 4), np.round(annualized_return_test_sac_ret, 4),np.round(annualized_return_test_td3_ret, 4) ,\"\",  np.round(annualized_return_test_a2c_lstm, 4), np.round(annualized_return_test_ppo_lstm, 4), np.round(annualized_return_test_ddpg_lstm, 4), np.round(annualized_return_test_sac_lstm, 4),np.round(annualized_return_test_td3_lstm, 4) ,\"\",  np.round(annualized_return_test_a2c_transformer, 4), np.round(annualized_return_test_ppo_transformer, 4), np.round(annualized_return_test_ddpg_transformer, 4), np.round(annualized_return_test_sac_transformer, 4),np.round(annualized_return_test_td3_transformer, 4)],\n",
        "        'Sharpe Ratio (SR)' : [np.round(sharpe_ratio_test_markow, 4), np.round(sharpe_ratio_test_kelly, 4), np.round(sharpe_ratio_test_denoised, 4), np.round(sharpe_ratio_test_eq, 4),\"\",  np.round(sharpe_ratio_test_a2c_ti, 4), np.round(sharpe_ratio_test_ppo_ti, 4), np.round(sharpe_ratio_test_ddpg_ti, 4), np.round(sharpe_ratio_test_sac_ti, 4),np.round(sharpe_ratio_test_td3_ti, 4) ,\"\",  np.round(sharpe_ratio_test_a2c_ret, 4),np.round(sharpe_ratio_test_ppo_ret, 4), np.round(sharpe_ratio_test_ddpg_ret, 4), np.round(sharpe_ratio_test_sac_ret, 4),np.round(sharpe_ratio_test_td3_ret, 4) ,\"\",  np.round(sharpe_ratio_test_a2c_lstm, 4),np.round(sharpe_ratio_test_ppo_lstm, 4), np.round(sharpe_ratio_test_ddpg_lstm, 4), np.round(sharpe_ratio_test_sac_lstm, 4),np.round(sharpe_ratio_test_td3_lstm, 4),\"\",  np.round(sharpe_ratio_test_a2c_transformer, 4),np.round(sharpe_ratio_test_ppo_transformer, 4), np.round(sharpe_ratio_test_ddpg_transformer, 4), np.round(sharpe_ratio_test_sac_transformer, 4),np.round(sharpe_ratio_test_td3_transformer, 4)],\n",
        "        'Maximum Drawdown(%)' : [np.round(maxdraw_test_markow, 4), np.round(maxdraw_test_kelly, 4), np.round(maxdraw_test_denoised, 4), np.round(maxdraw_test_eq, 4),\"\",  np.round(maxdraw_test_a2c_ti, 4),np.round(maxdraw_test_ppo_ti, 4), np.round(maxdraw_test_ddpg_ti, 4), np.round(maxdraw_test_sac_ti, 4),np.round(maxdraw_test_td3_ti, 4) ,\"\",  np.round(maxdraw_test_a2c_ret, 4),np.round(maxdraw_test_ppo_ret, 4), np.round(maxdraw_test_ddpg_ret, 4), np.round(maxdraw_test_sac_ret, 4),np.round(maxdraw_test_td3_ret, 4) ,\"\",  np.round(maxdraw_test_a2c_lstm, 4),np.round(maxdraw_test_ppo_lstm, 4), np.round(maxdraw_test_ddpg_lstm, 4), np.round(maxdraw_test_sac_lstm, 4),np.round(maxdraw_test_td3_lstm, 4),\"\",  np.round(maxdraw_test_a2c_transformer, 4),np.round(maxdraw_test_ppo_transformer, 4), np.round(maxdraw_test_ddpg_transformer, 4), np.round(maxdraw_test_sac_transformer, 4),np.round(maxdraw_test_td3_transformer, 4)]}\n",
        "\n",
        "df = pd.DataFrame(dict, index = None)\n",
        "pdtabulate = lambda df: tabulate(df, headers='keys', tablefmt='heavy_grid', showindex=False)\n",
        "print(pdtabulate(df))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(df.to_html()))"
      ],
      "metadata": {
        "id": "Ae3PsOvLyHWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrOfbBsdK1Yf"
      },
      "source": [
        "<hr style='border:2px solid black'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpzlWg9rvm6b"
      },
      "source": [
        "## **Section 10: The DynaCAAST Framework for RL based trading agents (Testing Data)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SoBkvJfvxD3"
      },
      "source": [
        "<hr style='border:2px solid black'>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now review the performance of DynaCAAST Framework on testing dataset. First we clear any old elements in dictionaries for holding environments and observations."
      ],
      "metadata": {
        "id": "4PJh_GoMcyXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DynaCAAST_Env.clear()\n",
        "DynaCAAST_Obs.clear()"
      ],
      "metadata": {
        "id": "51O0iUWmWjqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we prepare multiple environments for running our various RL algorithms. We need multiple environments as each RL agent uses its own state space and requires correspondingly defined environment."
      ],
      "metadata": {
        "id": "h3ed1FwNdEE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_kwargs = { \"hmax\": 500, \"initial_amount\": 1000000, \"transaction_cost_pct\": transaction_cost, \"state_space\": state_space,  \"stock_dim\": stock_dimension,  \"tech_indicator_list\": ti_abbreviations,\n",
        "    \"action_space\": stock_dimension,  \"reward_scaling\": 0, 'initial_weights': [1/stock_dimension]*stock_dimension}\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ti , **env_kwargs)\n",
        "env_a2c_ti, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['a2c_ti'] = copy.copy(env_a2c_ti)\n",
        "DynaCAAST_Obs['a2c_ti'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ti, **env_kwargs)\n",
        "env_ppo_ti, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ppo_ti'] = copy.copy(env_ppo_ti)\n",
        "DynaCAAST_Obs['ppo_ti'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ti, **env_kwargs)\n",
        "env_ddpg_ti, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ddpg_ti'] = copy.copy(env_ddpg_ti)\n",
        "DynaCAAST_Obs['ddpg_ti'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ti, **env_kwargs)\n",
        "env_sac_ti, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['sac_ti'] = copy.copy(env_sac_ti)\n",
        "DynaCAAST_Obs['sac_ti'] = copy.copy(obs_trade)\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ti, **env_kwargs)\n",
        "env_td3_ti, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['td3_ti'] = copy.copy(env_td3_ti)\n",
        "DynaCAAST_Obs['td3_ti'] = obs_trade.copy()\n",
        "\n",
        "env_kwargs = { \"hmax\": 500, \"initial_amount\": 1000000, \"transaction_cost_pct\": transaction_cost, \"state_space\": state_space,  \"stock_dim\": stock_dimension,  \"tech_indicator_list\": return_lags,\n",
        "    \"action_space\": stock_dimension,  \"reward_scaling\": 0, 'initial_weights': [1/stock_dimension]*stock_dimension}\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ret , **env_kwargs)\n",
        "env_a2c_ret, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['a2c_ret'] = copy.copy(env_a2c_ret)\n",
        "DynaCAAST_Obs['a2c_ret'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ret, **env_kwargs)\n",
        "env_ppo_ret, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ppo_ret'] = copy.copy(env_ppo_ret)\n",
        "DynaCAAST_Obs['ppo_ret'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ret, **env_kwargs)\n",
        "env_ddpg_ret, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ddpg_ret'] = copy.copy(env_ddpg_ret)\n",
        "DynaCAAST_Obs['ddpg_ret'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ret, **env_kwargs)\n",
        "env_sac_ret, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['sac_ret'] = copy.copy(env_sac_ret)\n",
        "DynaCAAST_Obs['sac_ret'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_ret, **env_kwargs)\n",
        "env_td3_ret, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['td3_ret'] = copy.copy(env_td3_ret)\n",
        "DynaCAAST_Obs['td3_ret'] = obs_trade.copy()\n",
        "\n",
        "env_kwargs = { \"hmax\": 500, \"initial_amount\": 1000000, \"transaction_cost_pct\": transaction_cost, \"state_space\": state_space,  \"stock_dim\": stock_dimension,  \"tech_indicator_list\": lstm_fcst,\n",
        "    \"action_space\": stock_dimension,  \"reward_scaling\": 0, 'initial_weights': [1/stock_dimension]*stock_dimension}\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_lstm , **env_kwargs)\n",
        "env_a2c_lstm, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['a2c_lstm'] = copy.copy(env_a2c_lstm)\n",
        "DynaCAAST_Obs['a2c_lstm'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_lstm, **env_kwargs)\n",
        "env_ppo_lstm, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ppo_lstm'] = copy.copy(env_ppo_lstm)\n",
        "DynaCAAST_Obs['ppo_lstm'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_lstm, **env_kwargs)\n",
        "env_ddpg_lstm, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ddpg_lstm'] = copy.copy(env_ddpg_lstm)\n",
        "DynaCAAST_Obs['ddpg_lstm'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_lstm, **env_kwargs)\n",
        "env_sac_lstm, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['sac_lstm'] = copy.copy(env_sac_lstm)\n",
        "DynaCAAST_Obs['sac_lstm'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_lstm, **env_kwargs)\n",
        "env_td3_lstm, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['td3_lstm'] = copy.copy(env_td3_lstm)\n",
        "DynaCAAST_Obs['td3_lstm'] = obs_trade.copy()\n",
        "\n",
        "env_kwargs = { \"hmax\": 500, \"initial_amount\": 1000000, \"transaction_cost_pct\": transaction_cost, \"state_space\": state_space,  \"stock_dim\": stock_dimension,  \"tech_indicator_list\": transformer_fcst,\n",
        "    \"action_space\": stock_dimension,  \"reward_scaling\": 0, 'initial_weights': [1/stock_dimension]*stock_dimension}\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_transformer , **env_kwargs)\n",
        "env_a2c_transformer, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['a2c_transformer'] = copy.copy(env_a2c_transformer)\n",
        "DynaCAAST_Obs['a2c_transformer'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_transformer, **env_kwargs)\n",
        "env_ppo_transformer, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ppo_transformer'] = copy.copy(env_ppo_transformer)\n",
        "DynaCAAST_Obs['ppo_transformer'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_transformer, **env_kwargs)\n",
        "env_ddpg_transformer, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ddpg_transformer'] = copy.copy(env_ddpg_transformer)\n",
        "DynaCAAST_Obs['ddpg_transformer'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_transformer, **env_kwargs)\n",
        "env_sac_transformer, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['sac_transformer'] = copy.copy(env_sac_transformer)\n",
        "DynaCAAST_Obs['sac_transformer'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = test_data_transformer, **env_kwargs)\n",
        "env_td3_transformer, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['td3_transformer'] = copy.copy(env_td3_transformer)\n",
        "DynaCAAST_Obs['td3_transformer'] = obs_trade.copy()"
      ],
      "metadata": {
        "id": "0pMvT1M8WbK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we create our DynaCAAST framework and run it on the testing data. We then evaluate the performance of DynaCAAST Framework with all other RL agents and traditional approaches."
      ],
      "metadata": {
        "id": "0gTUHPdrCJek"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBkmCidAvxjd"
      },
      "outputs": [],
      "source": [
        "dyna_portfolio_weights = [np.array([1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27,1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27])]\n",
        "dyna_portfolio_values  = [100]\n",
        "dyna_portfolio_returns = [0]\n",
        "reset_iter = 0\n",
        "last_data_values = np.array([0, 0, 0])\n",
        "\n",
        "for i in range(len(test_data_lstm.index.unique())):\n",
        "  max_rewards = []\n",
        "  max_weights = []\n",
        "  data_values = 0\n",
        "  arg_max = 0\n",
        "\n",
        "  for model, env, obs in zip(list(DynaCAAST_Model.values()), list(DynaCAAST_Env.values()), list(DynaCAAST_Obs.values())):\n",
        "    if reset_iter == 0:\n",
        "      env.reset()\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, dones, info = env.step(action)\n",
        "    max_rewards.append(rewards)\n",
        "    weights = env.env_method(method_name=\"getWeights\")\n",
        "    max_weights.append(weights)\n",
        "\n",
        "  reset_iter = 1\n",
        "\n",
        "  data_values = np.squeeze(env.env_method(method_name=\"getDataCloseValues\"))\n",
        "\n",
        "  prev_portfolio_value = dyna_portfolio_values[-1]\n",
        "\n",
        "  arg_max = np.argmax(np.array(max_rewards))\n",
        "\n",
        "  curr_weights = max_weights[arg_max]\n",
        "\n",
        "  dyna_portfolio_weights.append(curr_weights)\n",
        "\n",
        "  if last_data_values.all() == 0:\n",
        "    new_portfolio_value = prev_portfolio_value\n",
        "    last_data_values = data_values.copy()\n",
        "  else:\n",
        "    new_portfolio_value = np.sum((data_values/last_data_values) * np.array(dyna_portfolio_weights[-1])) * prev_portfolio_value\n",
        "    trans_cost = np.sum(np.absolute((data_values/last_data_values) * (np.array(dyna_portfolio_weights[-1]) -  np.array(dyna_portfolio_weights[-2]))))*transaction_cost\n",
        "    new_portfolio_value = new_portfolio_value - abs(trans_cost)\n",
        "    last_data_values = data_values.copy()\n",
        "\n",
        "  portfolio_return = new_portfolio_value/prev_portfolio_value -1\n",
        "  dyna_portfolio_values.append(new_portfolio_value)\n",
        "  dyna_portfolio_returns.append(portfolio_return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i58L2xVav3m-"
      },
      "outputs": [],
      "source": [
        "test_data_dyna = pd.DataFrame({'daily_return':dyna_portfolio_returns[:-1],\n",
        "                               'Date':list(test_data_lstm.date.unique()) })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-iSUPk3l92Y"
      },
      "outputs": [],
      "source": [
        "test_data_dyna.set_index(['Date'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have the daily returns from DynaCAAST frameowork, we visualize the performance graphically."
      ],
      "metadata": {
        "id": "5lgZACK_Chud"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_AzjLk4v3qP"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(test_data_dyna)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = test_data_dyna['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(td3_test_returns_lstm[\"date\"][1:], portfolio_values, label=\"DynaCAAST Portfolio\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on DynaCAAST Framework - Testing Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_test[\"return_dyna\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_test_dyna = capital\n",
        "total_return_test_dyna = final_value_test_dyna - initial_capital\n",
        "sharpe_ratio_test_dyna = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_test_dyna = (final_value_test_dyna / initial_capital) ** (1 / (len(test_data_dyna) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_test_dyna = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_test_dyna:.2f}\")\n",
        "print(f\"Total Return: {total_return_test_dyna:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_test_dyna * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_test_dyna:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_test_dyna:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y9cYIhT1IVx"
      },
      "source": [
        "We evaluate performance of all approaches including the DynaCAAST framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDTojjku1SDG"
      },
      "outputs": [],
      "source": [
        "dict = {'Approach ' : [\"Markowitz\", \"Kelly\", \"Denoising\", \"Equal weighted\", \"\", \"A2C - TI\",\"PPO - TI\", \"DDPG - TI\", \"SAC - TI\", \"TD3 - TI\",\"\", \"A2C - RET\",\"PPO - RET \", \"DDPG - RET \", \"SAC - RET \", \"TD3 - RET \",\"\", \"A2C - LSTM \",\"PPO - LSTM \", \"DDPG - LSTM \", \"SAC - LSTM \", \"TD3 - LSTM \",\"\", \"A2C - Transformer \",\"PPO - Transformer \", \"DDPG - Transformer \", \"SAC - Transformer \", \"TD3 - Transformer \" , \"\", \"DynaCAAST \"  ],\n",
        "        'Initial Capital' : [np.round(100, 4), np.round(100, 4), np.round(100, 4),np.round(100, 4),\"\",  np.round(100, 4), np.round(100, 4), np.round(100, 4), np.round(100, 4),np.round(100, 4), \"\",  np.round(100, 4), np.round(100, 4), np.round(100, 4), np.round(100, 4),np.round(100, 4), \"\",  np.round(100, 4), np.round(100, 4), np.round(100, 4), np.round(100, 4),np.round(100, 4), \"\",  np.round(100, 4), np.round(100, 4), np.round(100, 4), np.round(100, 4),np.round(100, 4), \"\",  np.round(100, 4)],\n",
        "        'Total Gain' : [np.round(total_return_test_markow, 4), np.round(total_return_test_kelly, 4), np.round(total_return_test_denoised, 4),np.round(total_return_test_eq, 4),\"\",  np.round(total_return_test_a2c_ti, 4), np.round(total_return_test_ppo_ti, 4), np.round(total_return_test_ddpg_ti, 4), np.round(total_return_test_sac_ti, 4), np.round(total_return_test_td3_ti, 4) ,\"\",  np.round(total_return_test_a2c_ret, 4), np.round(total_return_test_ppo_ret, 4), np.round(total_return_test_ddpg_ret, 4), np.round(total_return_test_sac_ret, 4),np.round(total_return_test_td3_ret, 4) ,\"\",  np.round(total_return_test_a2c_lstm, 4), np.round(total_return_test_ppo_lstm, 4), np.round(total_return_test_ddpg_lstm, 4), np.round(total_return_test_sac_lstm, 4),np.round(total_return_test_td3_lstm, 4),\"\",  np.round(total_return_test_a2c_transformer, 4), np.round(total_return_test_ppo_transformer, 4), np.round(total_return_test_ddpg_transformer, 4), np.round(total_return_test_sac_transformer, 4),np.round(total_return_test_td3_transformer, 4), \"\", np.round(total_return_test_dyna, 4)],\n",
        "        'Final Capital' : [np.round(final_value_test_markow, 4), np.round(final_value_test_kelly, 4), np.round(final_value_test_denoised, 4),np.round(final_value_test_eq, 4),\"\",  np.round(final_value_test_a2c_ti, 4), np.round(final_value_test_ppo_ti, 4), np.round(final_value_test_ddpg_ti, 4), np.round(final_value_test_sac_ti, 4),np.round(final_value_test_td3_ti, 4) ,\"\",  np.round(final_value_test_a2c_ret, 4), np.round(final_value_test_ppo_ret, 4), np.round(final_value_test_ddpg_ret, 4), np.round(final_value_test_sac_ret, 4),np.round(final_value_test_td3_ret, 4),\"\",  np.round(final_value_test_a2c_lstm, 4), np.round(final_value_test_ppo_lstm, 4), np.round(final_value_test_ddpg_lstm, 4), np.round(final_value_test_sac_lstm, 4),np.round(final_value_test_td3_lstm, 4),\"\",  np.round(final_value_test_a2c_transformer, 4), np.round(final_value_test_ppo_transformer, 4), np.round(final_value_test_ddpg_transformer, 4), np.round(final_value_test_sac_transformer, 4),np.round(final_value_test_td3_transformer, 4), \"\", np.round(final_value_test_dyna, 4)],\n",
        "        'Annualized Return' : [np.round(annualized_return_test_markow, 4), np.round(annualized_return_test_kelly, 4), np.round(annualized_return_test_denoised, 4),np.round(annualized_return_test_eq, 4),\"\",  np.round(annualized_return_test_a2c_ti, 4), np.round(annualized_return_test_ppo_ti, 4), np.round(annualized_return_test_ddpg_ti, 4), np.round(annualized_return_test_sac_ti, 4),np.round(annualized_return_test_td3_ti, 4) ,\"\",  np.round(annualized_return_test_a2c_ret, 4), np.round(annualized_return_test_ppo_ret, 4), np.round(annualized_return_test_ddpg_ret, 4), np.round(annualized_return_test_sac_ret, 4),np.round(annualized_return_test_td3_ret, 4) ,\"\",  np.round(annualized_return_test_a2c_lstm, 4), np.round(annualized_return_test_ppo_lstm, 4), np.round(annualized_return_test_ddpg_lstm, 4), np.round(annualized_return_test_sac_lstm, 4),np.round(annualized_return_test_td3_lstm, 4) ,\"\",  np.round(annualized_return_test_a2c_transformer, 4), np.round(annualized_return_test_ppo_transformer, 4), np.round(annualized_return_test_ddpg_transformer, 4), np.round(annualized_return_test_sac_transformer, 4),np.round(annualized_return_test_td3_transformer, 4), \"\", np.round(annualized_return_test_dyna, 4)],\n",
        "        'Sharpe Ratio (SR)' : [np.round(sharpe_ratio_test_markow, 4), np.round(sharpe_ratio_test_kelly, 4), np.round(sharpe_ratio_test_denoised, 4), np.round(sharpe_ratio_test_eq, 4),\"\",  np.round(sharpe_ratio_test_a2c_ti, 4), np.round(sharpe_ratio_test_ppo_ti, 4), np.round(sharpe_ratio_test_ddpg_ti, 4), np.round(sharpe_ratio_test_sac_ti, 4),np.round(sharpe_ratio_test_td3_ti, 4) ,\"\",  np.round(sharpe_ratio_test_a2c_ret, 4),np.round(sharpe_ratio_test_ppo_ret, 4), np.round(sharpe_ratio_test_ddpg_ret, 4), np.round(sharpe_ratio_test_sac_ret, 4),np.round(sharpe_ratio_test_td3_ret, 4) ,\"\",  np.round(sharpe_ratio_test_a2c_lstm, 4),np.round(sharpe_ratio_test_ppo_lstm, 4), np.round(sharpe_ratio_test_ddpg_lstm, 4), np.round(sharpe_ratio_test_sac_lstm, 4),np.round(sharpe_ratio_test_td3_lstm, 4),\"\",  np.round(sharpe_ratio_test_a2c_transformer, 4),np.round(sharpe_ratio_test_ppo_transformer, 4), np.round(sharpe_ratio_test_ddpg_transformer, 4), np.round(sharpe_ratio_test_sac_transformer, 4),np.round(sharpe_ratio_test_td3_transformer, 4), \"\", np.round(sharpe_ratio_test_dyna, 4)],\n",
        "        'Maximum Drawdown(%)' : [np.round(maxdraw_test_markow, 4), np.round(maxdraw_test_kelly, 4), np.round(maxdraw_test_denoised, 4), np.round(maxdraw_test_eq, 4),\"\",  np.round(maxdraw_test_a2c_ti, 4),np.round(maxdraw_test_ppo_ti, 4), np.round(maxdraw_test_ddpg_ti, 4), np.round(maxdraw_test_sac_ti, 4),np.round(maxdraw_test_td3_ti, 4) ,\"\",  np.round(maxdraw_test_a2c_ret, 4),np.round(maxdraw_test_ppo_ret, 4), np.round(maxdraw_test_ddpg_ret, 4), np.round(maxdraw_test_sac_ret, 4),np.round(maxdraw_test_td3_ret, 4) ,\"\",  np.round(maxdraw_test_a2c_lstm, 4),np.round(maxdraw_test_ppo_lstm, 4), np.round(maxdraw_test_ddpg_lstm, 4), np.round(maxdraw_test_sac_lstm, 4),np.round(maxdraw_test_td3_lstm, 4),\"\",  np.round(maxdraw_test_a2c_transformer, 4),np.round(maxdraw_test_ppo_transformer, 4), np.round(maxdraw_test_ddpg_transformer, 4), np.round(maxdraw_test_sac_transformer, 4),np.round(maxdraw_test_td3_transformer, 4), \"\", np.round(maxdraw_test_dyna, 4)]}\n",
        "\n",
        "df = pd.DataFrame(dict, index = None)\n",
        "pdtabulate = lambda df: tabulate(df, headers='keys', tablefmt='heavy_grid', showindex=False)\n",
        "print(pdtabulate(df))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(df.to_html()))"
      ],
      "metadata": {
        "id": "fJPwm_N6yQ6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D83V-evNvMXa"
      },
      "source": [
        "## **Section 11: The DynaCAAST Framework for RL based trading agents (vs. Nifty Index)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luZ5aT5fvMXj"
      },
      "source": [
        "<hr style='border:2px solid black'>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now benchmark our DynaCAAST algorithm against Nifty 50 index. That is we compare how our DynaCAAST framework fared versus an investor just holding the Nifty 50 index. For this purpose, we clear our environment and observation dictionaries."
      ],
      "metadata": {
        "id": "KYBtwxcGvMXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DynaCAAST_Env.clear()\n",
        "DynaCAAST_Obs.clear()"
      ],
      "metadata": {
        "id": "UCqtKTnZva4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now create multiple environments for training datasets for our RL agents. We need this as we want to evaluate our DynaCAAST framework against Nifty 50 index for the entire duration of the time period."
      ],
      "metadata": {
        "id": "SPYEZF8Ud_NZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKqb7Lcwva4s"
      },
      "outputs": [],
      "source": [
        "env_kwargs = { \"hmax\": 500, \"initial_amount\": 1000000, \"transaction_cost_pct\": transaction_cost, \"state_space\": state_space,  \"stock_dim\": stock_dimension,  \"tech_indicator_list\": ti_abbreviations,\n",
        "    \"action_space\": stock_dimension,  \"reward_scaling\": 0, 'initial_weights': [1/stock_dimension]*stock_dimension}\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ti , **env_kwargs)\n",
        "env_a2c_ti, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['a2c_ti'] = copy.copy(env_a2c_ti)\n",
        "DynaCAAST_Obs['a2c_ti'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ti, **env_kwargs)\n",
        "env_ppo_ti, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ppo_ti'] = copy.copy(env_ppo_ti)\n",
        "DynaCAAST_Obs['ppo_ti'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ti, **env_kwargs)\n",
        "env_ddpg_ti, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ddpg_ti'] = copy.copy(env_ddpg_ti)\n",
        "DynaCAAST_Obs['ddpg_ti'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ti, **env_kwargs)\n",
        "env_sac_ti, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['sac_ti'] = copy.copy(env_sac_ti)\n",
        "DynaCAAST_Obs['sac_ti'] = copy.copy(obs_trade)\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ti, **env_kwargs)\n",
        "env_td3_ti, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['td3_ti'] = copy.copy(env_td3_ti)\n",
        "DynaCAAST_Obs['td3_ti'] = obs_trade.copy()\n",
        "\n",
        "env_kwargs = { \"hmax\": 500, \"initial_amount\": 1000000, \"transaction_cost_pct\": transaction_cost, \"state_space\": state_space,  \"stock_dim\": stock_dimension,  \"tech_indicator_list\": return_lags,\n",
        "    \"action_space\": stock_dimension,  \"reward_scaling\": 0, 'initial_weights': [1/stock_dimension]*stock_dimension}\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ret , **env_kwargs)\n",
        "env_a2c_ret, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['a2c_ret'] = copy.copy(env_a2c_ret)\n",
        "DynaCAAST_Obs['a2c_ret'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ret, **env_kwargs)\n",
        "env_ppo_ret, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ppo_ret'] = copy.copy(env_ppo_ret)\n",
        "DynaCAAST_Obs['ppo_ret'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ret, **env_kwargs)\n",
        "env_ddpg_ret, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ddpg_ret'] = copy.copy(env_ddpg_ret)\n",
        "DynaCAAST_Obs['ddpg_ret'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ret, **env_kwargs)\n",
        "env_sac_ret, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['sac_ret'] = copy.copy(env_sac_ret)\n",
        "DynaCAAST_Obs['sac_ret'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_ret, **env_kwargs)\n",
        "env_td3_ret, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['td3_ret'] = copy.copy(env_td3_ret)\n",
        "DynaCAAST_Obs['td3_ret'] = obs_trade.copy()\n",
        "\n",
        "env_kwargs = { \"hmax\": 500, \"initial_amount\": 1000000, \"transaction_cost_pct\": transaction_cost, \"state_space\": state_space,  \"stock_dim\": stock_dimension,  \"tech_indicator_list\": lstm_fcst,\n",
        "    \"action_space\": stock_dimension,  \"reward_scaling\": 0, 'initial_weights': [1/stock_dimension]*stock_dimension}\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_lstm , **env_kwargs)\n",
        "env_a2c_lstm, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['a2c_lstm'] = copy.copy(env_a2c_lstm)\n",
        "DynaCAAST_Obs['a2c_lstm'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_lstm, **env_kwargs)\n",
        "env_ppo_lstm, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ppo_lstm'] = copy.copy(env_ppo_lstm)\n",
        "DynaCAAST_Obs['ppo_lstm'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_lstm, **env_kwargs)\n",
        "env_ddpg_lstm, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ddpg_lstm'] = copy.copy(env_ddpg_lstm)\n",
        "DynaCAAST_Obs['ddpg_lstm'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_lstm, **env_kwargs)\n",
        "env_sac_lstm, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['sac_lstm'] = copy.copy(env_sac_lstm)\n",
        "DynaCAAST_Obs['sac_lstm'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_lstm, **env_kwargs)\n",
        "env_td3_lstm, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['td3_lstm'] = copy.copy(env_td3_lstm)\n",
        "DynaCAAST_Obs['td3_lstm'] = obs_trade.copy()\n",
        "\n",
        "env_kwargs = { \"hmax\": 500, \"initial_amount\": 1000000, \"transaction_cost_pct\": transaction_cost, \"state_space\": state_space,  \"stock_dim\": stock_dimension,  \"tech_indicator_list\": transformer_fcst,\n",
        "    \"action_space\": stock_dimension,  \"reward_scaling\": 0, 'initial_weights': [1/stock_dimension]*stock_dimension}\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_transformer , **env_kwargs)\n",
        "env_a2c_transformer, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['a2c_transformer'] = copy.copy(env_a2c_transformer)\n",
        "DynaCAAST_Obs['a2c_transformer'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_transformer, **env_kwargs)\n",
        "env_ppo_transformer, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ppo_transformer'] = copy.copy(env_ppo_transformer)\n",
        "DynaCAAST_Obs['ppo_transformer'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_transformer, **env_kwargs)\n",
        "env_ddpg_transformer, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ddpg_transformer'] = copy.copy(env_ddpg_transformer)\n",
        "DynaCAAST_Obs['ddpg_transformer'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_transformer, **env_kwargs)\n",
        "env_sac_transformer, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['sac_transformer'] = copy.copy(env_sac_transformer)\n",
        "DynaCAAST_Obs['sac_transformer'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = train_data_transformer, **env_kwargs)\n",
        "env_td3_transformer, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['td3_transformer'] = copy.copy(env_td3_transformer)\n",
        "DynaCAAST_Obs['td3_transformer'] = obs_trade.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now run our DynaCAAST framework below."
      ],
      "metadata": {
        "id": "udWFV8VmeTMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dyna_portfolio_weights = [np.array([1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27,1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27])]\n",
        "dyna_portfolio_values  = [100]\n",
        "dyna_portfolio_returns = [0]\n",
        "reset_iter = 0\n",
        "last_data_values = np.array([0, 0, 0])\n",
        "\n",
        "for i in range(len(train_data_lstm.index.unique())):\n",
        "  max_rewards = []\n",
        "  max_weights = []\n",
        "  data_values = 0\n",
        "  arg_max = 0\n",
        "\n",
        "  for model, env, obs in zip(list(DynaCAAST_Model.values()), list(DynaCAAST_Env.values()), list(DynaCAAST_Obs.values())):\n",
        "    if reset_iter == 0:\n",
        "      env.reset()\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, dones, info = env.step(action)\n",
        "    max_rewards.append(rewards)\n",
        "    weights = env.env_method(method_name=\"getWeights\")\n",
        "    max_weights.append(weights)\n",
        "\n",
        "  reset_iter = 1\n",
        "\n",
        "  data_values = np.squeeze(env.env_method(method_name=\"getDataCloseValues\"))\n",
        "\n",
        "  prev_portfolio_value = dyna_portfolio_values[-1]\n",
        "\n",
        "  arg_max = np.argmax(np.array(max_rewards))\n",
        "\n",
        "  curr_weights = max_weights[arg_max]\n",
        "\n",
        "  dyna_portfolio_weights.append(curr_weights)\n",
        "\n",
        "  if last_data_values.all() == 0:\n",
        "    new_portfolio_value = prev_portfolio_value\n",
        "    last_data_values = data_values.copy()\n",
        "  else:\n",
        "    new_portfolio_value = np.sum((data_values/last_data_values) * np.array(dyna_portfolio_weights[-1])) * prev_portfolio_value\n",
        "    trans_cost = np.sum(np.absolute((data_values/last_data_values) * (np.array(dyna_portfolio_weights[-1]) -  np.array(dyna_portfolio_weights[-2]))))*transaction_cost\n",
        "    new_portfolio_value = new_portfolio_value - abs(trans_cost)\n",
        "    last_data_values = data_values.copy()\n",
        "\n",
        "  portfolio_return = new_portfolio_value/prev_portfolio_value -1\n",
        "  dyna_portfolio_values.append(new_portfolio_value)\n",
        "  dyna_portfolio_returns.append(portfolio_return)"
      ],
      "metadata": {
        "id": "ws89pIKavn4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dyna = pd.DataFrame({'daily_return':dyna_portfolio_returns[:-1],\n",
        "                               'Date':list(train_data_lstm.date.unique()) })"
      ],
      "metadata": {
        "id": "8v2rfp55OTxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dyna.set_index(['Date'], inplace=True)"
      ],
      "metadata": {
        "id": "frggL-ALOT_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We visualize the performance of the DynaCAAST framework against training set."
      ],
      "metadata": {
        "id": "HbqVYvN3eZ-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "\n",
        "for i in range(1, len(train_data_dyna)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = train_data_dyna['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(td3_train_returns_lstm[\"date\"][1:], portfolio_values, label=\"DynaCAAST Portfolio\", color=\"blue\")\n",
        "plt.title(\"Portfolio Performance based on DynaCAAST Framework - Training Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Strategy_Returns_Data_trg[\"return_dyna\"] = portfolio_returns\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_train_dyna = capital\n",
        "total_return_train_dyna = final_value_train_dyna - initial_capital\n",
        "sharpe_ratio_train_dyna = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_train_dyna = (final_value_train_dyna / initial_capital) ** (1 / (len(train_data_dyna) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_train_dyna = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_train_dyna:.2f}\")\n",
        "print(f\"Total Return: {total_return_train_dyna:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_train_dyna * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_train_dyna:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_train_dyna:.4f}\")"
      ],
      "metadata": {
        "id": "qBZ4579lOUCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We combine results from training and testing for DynaCAAST to facilitate performance comparison."
      ],
      "metadata": {
        "id": "4SElaqAnenpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Strategy_Returns_Data = pd.concat([Strategy_Returns_Data_trg, Strategy_Returns_Data_test], ignore_index=False, sort=False)"
      ],
      "metadata": {
        "id": "tQOkJV55OFkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We join it with nifty data to have our benckmark results."
      ],
      "metadata": {
        "id": "Zes7ms2SezPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Strategy_Returns_Data = pd.concat([Strategy_Returns_Data, nifty_returns], axis=1)\n",
        "Strategy_Returns_Data = Strategy_Returns_Data.dropna()\n",
        "Strategy_Returns_Data.index = Strategy_Returns_Data.index.tz_localize(\"UTC\")"
      ],
      "metadata": {
        "id": "DmZpa9MNO1Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now evaluate DynaCAAST Framework against Nifty Index below."
      ],
      "metadata": {
        "id": "z5D7kA5ve6VQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pf.create_returns_tear_sheet(Strategy_Returns_Data['return_dyna'], benchmark_rets = Strategy_Returns_Data['nifty_return'], live_start_date=cut_off_date)"
      ],
      "metadata": {
        "id": "q-t_puSTO1l-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giTn4YZLt7K9"
      },
      "source": [
        "## **Section 12: The DynaCAAST Framework versus a buy and hold strategy (Validation Data)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76Q7RKZtuIL7"
      },
      "source": [
        "<hr style='border:2px solid black'>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below utilizing our DynaCAAST framework, we run it again on the validation data to confirm its effectiveness. We then evaluate the performance of DynaCAAST Framework with buy and hold strategy on the validation data."
      ],
      "metadata": {
        "id": "QGqNYf6JDDtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DynaCAAST_Env.clear()\n",
        "DynaCAAST_Obs.clear()"
      ],
      "metadata": {
        "id": "5TT2TkASTTy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first create multiple environments based on the validation dataset."
      ],
      "metadata": {
        "id": "F0CwO8WVfJIB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6ezETbFuItP"
      },
      "outputs": [],
      "source": [
        "env_kwargs = { \"hmax\": 500, \"initial_amount\": 1000000, \"transaction_cost_pct\": transaction_cost, \"state_space\": state_space,  \"stock_dim\": stock_dimension,  \"tech_indicator_list\": ti_abbreviations,\n",
        "    \"action_space\": stock_dimension,  \"reward_scaling\": 0, 'initial_weights': [1/stock_dimension]*stock_dimension}\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_ti , **env_kwargs)\n",
        "env_a2c_ti, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['a2c_ti'] = copy.copy(env_a2c_ti)\n",
        "DynaCAAST_Obs['a2c_ti'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_ti, **env_kwargs)\n",
        "env_ppo_ti, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ppo_ti'] = copy.copy(env_ppo_ti)\n",
        "DynaCAAST_Obs['ppo_ti'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_ti, **env_kwargs)\n",
        "env_ddpg_ti, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ddpg_ti'] = copy.copy(env_ddpg_ti)\n",
        "DynaCAAST_Obs['ddpg_ti'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_ti, **env_kwargs)\n",
        "env_sac_ti, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['sac_ti'] = copy.copy(env_sac_ti)\n",
        "DynaCAAST_Obs['sac_ti'] = copy.copy(obs_trade)\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_ti, **env_kwargs)\n",
        "env_td3_ti, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['td3_ti'] = copy.copy(env_td3_ti)\n",
        "DynaCAAST_Obs['td3_ti'] = obs_trade.copy()\n",
        "\n",
        "env_kwargs = { \"hmax\": 500, \"initial_amount\": 1000000, \"transaction_cost_pct\": transaction_cost, \"state_space\": state_space,  \"stock_dim\": stock_dimension,  \"tech_indicator_list\": return_lags,\n",
        "    \"action_space\": stock_dimension,  \"reward_scaling\": 0, 'initial_weights': [1/stock_dimension]*stock_dimension}\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_ret , **env_kwargs)\n",
        "env_a2c_ret, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['a2c_ret'] = copy.copy(env_a2c_ret)\n",
        "DynaCAAST_Obs['a2c_ret'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_ret, **env_kwargs)\n",
        "env_ppo_ret, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ppo_ret'] = copy.copy(env_ppo_ret)\n",
        "DynaCAAST_Obs['ppo_ret'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_ret, **env_kwargs)\n",
        "env_ddpg_ret, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ddpg_ret'] = copy.copy(env_ddpg_ret)\n",
        "DynaCAAST_Obs['ddpg_ret'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_ret, **env_kwargs)\n",
        "env_sac_ret, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['sac_ret'] = copy.copy(env_sac_ret)\n",
        "DynaCAAST_Obs['sac_ret'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_ret, **env_kwargs)\n",
        "env_td3_ret, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['td3_ret'] = copy.copy(env_td3_ret)\n",
        "DynaCAAST_Obs['td3_ret'] = obs_trade.copy()\n",
        "\n",
        "env_kwargs = { \"hmax\": 500, \"initial_amount\": 1000000, \"transaction_cost_pct\": transaction_cost, \"state_space\": state_space,  \"stock_dim\": stock_dimension,  \"tech_indicator_list\": lstm_fcst,\n",
        "    \"action_space\": stock_dimension,  \"reward_scaling\": 0, 'initial_weights': [1/stock_dimension]*stock_dimension}\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_lstm , **env_kwargs)\n",
        "env_a2c_lstm, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['a2c_lstm'] = copy.copy(env_a2c_lstm)\n",
        "DynaCAAST_Obs['a2c_lstm'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_lstm, **env_kwargs)\n",
        "env_ppo_lstm, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ppo_lstm'] = copy.copy(env_ppo_lstm)\n",
        "DynaCAAST_Obs['ppo_lstm'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_lstm, **env_kwargs)\n",
        "env_ddpg_lstm, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ddpg_lstm'] = copy.copy(env_ddpg_lstm)\n",
        "DynaCAAST_Obs['ddpg_lstm'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_lstm, **env_kwargs)\n",
        "env_sac_lstm, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['sac_lstm'] = copy.copy(env_sac_lstm)\n",
        "DynaCAAST_Obs['sac_lstm'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_lstm, **env_kwargs)\n",
        "env_td3_lstm, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['td3_lstm'] = copy.copy(env_td3_lstm)\n",
        "DynaCAAST_Obs['td3_lstm'] = obs_trade.copy()\n",
        "\n",
        "env_kwargs = { \"hmax\": 500, \"initial_amount\": 1000000, \"transaction_cost_pct\": transaction_cost, \"state_space\": state_space,  \"stock_dim\": stock_dimension,  \"tech_indicator_list\": transformer_fcst,\n",
        "    \"action_space\": stock_dimension,  \"reward_scaling\": 0, 'initial_weights': [1/stock_dimension]*stock_dimension}\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_transformer , **env_kwargs)\n",
        "env_a2c_transformer, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['a2c_transformer'] = copy.copy(env_a2c_transformer)\n",
        "DynaCAAST_Obs['a2c_transformer'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_transformer, **env_kwargs)\n",
        "env_ppo_transformer, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ppo_transformer'] = copy.copy(env_ppo_transformer)\n",
        "DynaCAAST_Obs['ppo_transformer'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_transformer, **env_kwargs)\n",
        "env_ddpg_transformer, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['ddpg_transformer'] = copy.copy(env_ddpg_transformer)\n",
        "DynaCAAST_Obs['ddpg_transformer'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_transformer, **env_kwargs)\n",
        "env_sac_transformer, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['sac_transformer'] = copy.copy(env_sac_transformer)\n",
        "DynaCAAST_Obs['sac_transformer'] = obs_trade.copy()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = valid_data_transformer, **env_kwargs)\n",
        "env_td3_transformer, obs_trade = e_trade_gym.get_sb_env()\n",
        "DynaCAAST_Env['td3_transformer'] = copy.copy(env_td3_transformer)\n",
        "DynaCAAST_Obs['td3_transformer'] = obs_trade.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL_BXzPOx7uT"
      },
      "source": [
        "DynaCAAST Framework is applied on validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3SmP_prx8Ls"
      },
      "outputs": [],
      "source": [
        "dyna_portfolio_weights = [np.array([1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27,1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27, 1/27])]\n",
        "dyna_portfolio_values  = [100]\n",
        "dyna_portfolio_returns = [0]\n",
        "reset_iter = 0\n",
        "last_data_values = np.array([0, 0, 0])\n",
        "\n",
        "for i in range(len(valid_data_lstm.index.unique())):\n",
        "  max_rewards = []\n",
        "  max_weights = []\n",
        "  data_values = 0\n",
        "  arg_max = 0\n",
        "\n",
        "  for model, env, obs in zip(list(DynaCAAST_Model.values()), list(DynaCAAST_Env.values()), list(DynaCAAST_Obs.values())):\n",
        "    if reset_iter == 0:\n",
        "      env.reset()\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, dones, info = env.step(action)\n",
        "    max_rewards.append(rewards)\n",
        "    weights = env.env_method(method_name=\"getWeights\")\n",
        "    max_weights.append(weights)\n",
        "\n",
        "  reset_iter = 1\n",
        "\n",
        "  data_values = np.squeeze(env.env_method(method_name=\"getDataCloseValues\"))\n",
        "\n",
        "  prev_portfolio_value = dyna_portfolio_values[-1]\n",
        "\n",
        "  arg_max = np.argmax(np.array(max_rewards))\n",
        "\n",
        "  curr_weights = max_weights[arg_max]\n",
        "\n",
        "  dyna_portfolio_weights.append(curr_weights)\n",
        "\n",
        "  if last_data_values.all() == 0:\n",
        "    new_portfolio_value = prev_portfolio_value\n",
        "    last_data_values = data_values.copy()\n",
        "  else:\n",
        "    new_portfolio_value = np.sum((data_values/last_data_values) * np.array(dyna_portfolio_weights[-1])) * prev_portfolio_value\n",
        "    trans_cost = np.sum(np.absolute((data_values/last_data_values) * (np.array(dyna_portfolio_weights[-1]) -  np.array(dyna_portfolio_weights[-2]))))*transaction_cost\n",
        "    new_portfolio_value = new_portfolio_value - abs(trans_cost)\n",
        "    last_data_values = data_values.copy()\n",
        "\n",
        "  portfolio_return = new_portfolio_value/prev_portfolio_value -1\n",
        "  dyna_portfolio_values.append(new_portfolio_value)\n",
        "  dyna_portfolio_returns.append(portfolio_return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qE4KGszWyCh9"
      },
      "outputs": [],
      "source": [
        "valid_data_dyna = pd.DataFrame({'daily_return':dyna_portfolio_returns[:-1],\n",
        "                               'Date':list(valid_data_lstm.date.unique()) })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OiIErW8yJQC"
      },
      "outputs": [],
      "source": [
        "valid_data_dyna.set_index(['Date'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We visualize the performance below."
      ],
      "metadata": {
        "id": "lICf_cBAfY8g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDBGQ33GyKGt"
      },
      "outputs": [],
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "dyna_valid_cum_returns = []\n",
        "\n",
        "for i in range(1, len(valid_data_dyna)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = valid_data_dyna['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "    dyna_valid_cum_returns.append(capital)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(valid_data_dyna.index[1:], portfolio_values, label=\"DynaCAAST Portfolio\", color=\"green\")\n",
        "plt.title(\"Portfolio Performance based on DynaCAAST Framework - Validation Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_valid_dyna = capital\n",
        "total_return_valid_dyna = final_value_valid_dyna - initial_capital\n",
        "sharpe_ratio_valid_dyna = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_valid_dyna = (final_value_valid_dyna / initial_capital) ** (1 / (len(valid_data_dyna) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_valid_dyna = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_valid_dyna:.2f}\")\n",
        "print(f\"Total Return: {total_return_valid_dyna:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_valid_dyna * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_valid_dyna:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_valid_dyna:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QqPSk3KyTEv"
      },
      "source": [
        "### **Buy and Hold Strategy on validation data**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we evaluate the performance of a buy and hold strategy on validation dataset."
      ],
      "metadata": {
        "id": "4-zyo_1hf5Ls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RE6q96_MyT2r"
      },
      "outputs": [],
      "source": [
        "orig_data_values = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "prev_portfolio_value = 100\n",
        "orig_portfolio_value = 100\n",
        "buyNhold_values = []\n",
        "buyNhold_returns = []\n",
        "shares = np.array([.1, .1, .1])\n",
        "\n",
        "for i in range(len(prices_valid_data)):\n",
        "\n",
        "    if i == 0:\n",
        "      orig_data_values = np.array(prices_valid_data[tickers_wo_cash].iloc[i,:].copy())\n",
        "      shares = np.array((1/orig_data_values) * orig_portfolio_value)\n",
        "    else:\n",
        "      data_values = np.array(prices_valid_data[tickers_wo_cash].iloc[i,:].copy())\n",
        "      new_portfolio_value = np.sum(data_values * shares)\n",
        "      portfolio_return = new_portfolio_value/prev_portfolio_value -1\n",
        "      prev_portfolio_value = new_portfolio_value\n",
        "      buyNhold_values.append(new_portfolio_value)\n",
        "      buyNhold_returns.append(portfolio_return)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data_buyNhold = pd.DataFrame({'daily_return':buyNhold_returns[:],\n",
        "                               'Date':list(valid_data_lstm.date.unique()) })"
      ],
      "metadata": {
        "id": "h54wM4w9ViYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data_buyNhold.set_index(['Date'], inplace=True)"
      ],
      "metadata": {
        "id": "tx0gxQiEVoN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We visualize the performance of buy and hold strategy on validation data."
      ],
      "metadata": {
        "id": "jipUmSDYsMv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "capital = initial_capital\n",
        "portfolio_values = []\n",
        "portfolio_returns = []\n",
        "BuyNhold_valid_cum_returns = []\n",
        "\n",
        "for i in range(1, len(valid_data_buyNhold)):\n",
        "    # Calculate portfolio returns based on the weighted sum of security returns\n",
        "    portfolio_return = valid_data_buyNhold['daily_return'].iloc[i]\n",
        "    capital *= (1 + portfolio_return)\n",
        "    portfolio_values.append(capital)\n",
        "    portfolio_returns.append(portfolio_return)\n",
        "    BuyNhold_valid_cum_returns.append(capital)\n",
        "\n",
        "# Plot the portfolio value over time\n",
        "plt.figure(figsize=(21, 9))\n",
        "plt.plot(valid_data_dyna.index[1:], portfolio_values, label=\"Buy and Hold Portfolio on Validation Data\", color=\"red\")\n",
        "plt.title(\"Portfolio Performance based on Buy and Hold - Validation Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Portfolio Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_value_valid_buyNhold = capital\n",
        "total_return_valid_buyNhold = final_value_valid_buyNhold - initial_capital\n",
        "sharpe_ratio_valid_buyNhold = np.mean(portfolio_returns) / np.std(portfolio_returns)*np.sqrt(252)\n",
        "annualized_return_valid_buyNhold = (final_value_valid_buyNhold / initial_capital) ** (1 / (len(valid_data_buyNhold) / 252)) - 1  # Assuming daily returns (252 trading days)\n",
        "maxdraw_valid_buyNhold = getMaxDrawdown(pd.DataFrame(portfolio_values), 252)[1].min().values[0]*100\n",
        "\n",
        "print(f\"Final Portfolio Value: {final_value_valid_buyNhold:.2f}\")\n",
        "print(f\"Total Return: {total_return_valid_buyNhold:.2f}\")\n",
        "print(f\"Annualized Return: {annualized_return_valid_buyNhold * 100:.2f}%\")\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio_valid_buyNhold:.4f}\")\n",
        "print(f\"Maximum draw down(%): {maxdraw_valid_buyNhold:.4f}\")"
      ],
      "metadata": {
        "id": "RW-PsDMZsNPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparison of buy and hold versus DynaCAAST Framework"
      ],
      "metadata": {
        "id": "WbRPGXu7muDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We finally compare the buy and hold and DynaCAAST on validation dataset."
      ],
      "metadata": {
        "id": "hI_ponxdgDzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dyna_valid_cum_returnsDF = pd.DataFrame({\"DynaCAAST Framework\": dyna_valid_cum_returns}, index = valid_data_dyna[1:].index)\n",
        "BuyNhold_valid_cum_returnsDF = pd.DataFrame({\"Buy and Hold Strategy\" : BuyNhold_valid_cum_returns}, index = valid_data_dyna[1:].index)"
      ],
      "metadata": {
        "id": "wSh2cPxBm220"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "# Plot the culmulative returns of the portfolios\n",
        "fig, ax = plt.subplots(figsize=(21,9))\n",
        "BuyNhold_valid_cum_returnsDF.plot(ax=ax, color='red', alpha=.4)\n",
        "dyna_valid_cum_returnsDF.plot(ax=ax, color='green', alpha=0.4)\n",
        "\n",
        "plt.legend(loc=\"best\");\n",
        "plt.grid(True);\n",
        "ax.set_ylabel(\"Cumulative return\");\n",
        "ax.set_title(\"DynaCAAST Framework versus Buy and Hold Strategy - Validation Data\", fontsize=14);"
      ],
      "metadata": {
        "id": "7Bsy5BmJnE7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S_TitiFKehB"
      },
      "source": [
        "# **End of Capstone Project (MScFE690)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e3gRHLxKxxx"
      },
      "source": [
        "<hr style='border:2px solid black'>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "230.906px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}